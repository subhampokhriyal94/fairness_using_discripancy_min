{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column names to data set\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "           'relationship', 'race','sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "# Read in train data\n",
    "adult_train = pd.read_csv('../input/adult/adult_train_data.csv', header=None, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_train = adult_train.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Read in test data\n",
    "adult_test = pd.read_csv('../input/adult/adult_test_data.csv', header=None, skiprows=1, names=columns, skipinitialspace=True)\n",
    "\n",
    "# Drop the fnlwgt column which is useless for later analysis\n",
    "adult_test = adult_test.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Remove '.' in income column\n",
    "adult_test['income'] = adult_test['income'].apply(lambda x: '>50k' if x=='>50k.'  else '<=50k')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561 16280\n"
     ]
    }
   ],
   "source": [
    "print(adult_train.shape[0],adult_test.shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing the missing value:\n",
      "Training set has 30162 samples.\n",
      "Testing set has 15059 samples.\n"
     ]
    }
   ],
   "source": [
    "# Convert '?' to NaNs and remove the entries with NaN value\n",
    "# Check missing value code and convert to NaNs\n",
    "object_col = adult_train.select_dtypes(include=object).columns.tolist()\n",
    "for col in object_col:\n",
    "    adult_train.loc[adult_train[col]=='?', col] = np.nan\n",
    "    adult_test.loc[adult_test[col]=='?', col] = np.nan\n",
    "\n",
    "# Perform an mssing assessment in each column of the dataset.\n",
    "col_missing_pct = adult_train.isna().sum()/adult_train.shape[0]\n",
    "col_missing_pct.sort_values(ascending=False)\n",
    "\n",
    "# Remove data entries with missing value\n",
    "adult_train = adult_train.dropna(axis=0, how='any')\n",
    "adult_test = adult_test.dropna(axis=0, how='any')\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"After removing the missing value:\")\n",
    "print(\"Training set has {} samples.\".format(adult_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(adult_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private             0.738877\n",
      "self-emp-not-inc    0.082853\n",
      "local-gov           0.068530\n",
      "state-gov           0.042404\n",
      "self-emp-inc        0.035608\n",
      "federal-gov         0.031265\n",
      "without-pay         0.000464\n",
      "Name: workclass, dtype: float64 \n",
      "\n",
      "hs-grad         0.326238\n",
      "some-college    0.221404\n",
      "bachelors       0.167230\n",
      "masters         0.053942\n",
      "assoc-voc       0.043333\n",
      "11th            0.034746\n",
      "assoc-acdm      0.033420\n",
      "10th            0.027187\n",
      "7th-8th         0.018467\n",
      "prof-school     0.017970\n",
      "9th             0.015085\n",
      "12th            0.012499\n",
      "doctorate       0.012433\n",
      "5th-6th         0.009548\n",
      "1st-4th         0.005006\n",
      "preschool       0.001492\n",
      "Name: education, dtype: float64 \n",
      "\n",
      "married-civ-spouse       0.466315\n",
      "never-married            0.322459\n",
      "divorced                 0.139712\n",
      "separated                0.031132\n",
      "widowed                  0.027419\n",
      "married-spouse-absent    0.012267\n",
      "married-af-spouse        0.000696\n",
      "Name: marital-status, dtype: float64 \n",
      "\n",
      "prof-specialty       0.133877\n",
      "craft-repair         0.133612\n",
      "exec-managerial      0.132352\n",
      "adm-clerical         0.123367\n",
      "sales                0.118825\n",
      "other-service        0.106492\n",
      "machine-op-inspct    0.065181\n",
      "transport-moving     0.052119\n",
      "handlers-cleaners    0.044758\n",
      "farming-fishing      0.032790\n",
      "tech-support         0.030237\n",
      "protective-serv      0.021351\n",
      "priv-house-serv      0.004741\n",
      "armed-forces         0.000298\n",
      "Name: occupation, dtype: float64 \n",
      "\n",
      "husband           0.413202\n",
      "not-in-family     0.256150\n",
      "own-child         0.148067\n",
      "unmarried         0.106492\n",
      "wife              0.046615\n",
      "other-relative    0.029474\n",
      "Name: relationship, dtype: float64 \n",
      "\n",
      "white                 0.859790\n",
      "black                 0.093396\n",
      "asian-pac-islander    0.029673\n",
      "amer-indian-eskimo    0.009482\n",
      "other                 0.007659\n",
      "Name: race, dtype: float64 \n",
      "\n",
      "male      0.675685\n",
      "female    0.324315\n",
      "Name: sex, dtype: float64 \n",
      "\n",
      "united-states                 0.911876\n",
      "mexico                        0.020224\n",
      "philippines                   0.006233\n",
      "germany                       0.004244\n",
      "puerto-rico                   0.003614\n",
      "canada                        0.003548\n",
      "india                         0.003315\n",
      "el-salvador                   0.003315\n",
      "cuba                          0.003050\n",
      "england                       0.002851\n",
      "jamaica                       0.002652\n",
      "south                         0.002354\n",
      "italy                         0.002254\n",
      "china                         0.002254\n",
      "dominican-republic            0.002221\n",
      "vietnam                       0.002122\n",
      "guatemala                     0.002089\n",
      "japan                         0.001956\n",
      "poland                        0.001857\n",
      "columbia                      0.001857\n",
      "haiti                         0.001392\n",
      "iran                          0.001392\n",
      "taiwan                        0.001392\n",
      "portugal                      0.001127\n",
      "nicaragua                     0.001094\n",
      "peru                          0.000995\n",
      "greece                        0.000961\n",
      "ecuador                       0.000895\n",
      "france                        0.000895\n",
      "ireland                       0.000796\n",
      "hong                          0.000630\n",
      "cambodia                      0.000597\n",
      "trinadad&tobago               0.000597\n",
      "laos                          0.000564\n",
      "thailand                      0.000564\n",
      "yugoslavia                    0.000530\n",
      "outlying-us(guam-usvi-etc)    0.000464\n",
      "hungary                       0.000431\n",
      "honduras                      0.000398\n",
      "scotland                      0.000365\n",
      "holand-netherlands            0.000033\n",
      "Name: native-country, dtype: float64 \n",
      "\n",
      "<=50k    0.751078\n",
      ">50k     0.248922\n",
      "Name: income, dtype: float64 \n",
      "\n",
      "   age         workclass  education  education-num      marital-status  \\\n",
      "0   39         state-gov  bachelors             13       never-married   \n",
      "1   50  self-emp-not-inc  bachelors             13  married-civ-spouse   \n",
      "2   38           private    hs-grad              9            divorced   \n",
      "3   53           private       11th              7  married-civ-spouse   \n",
      "4   28           private  bachelors             13  married-civ-spouse   \n",
      "\n",
      "          occupation   relationship   race     sex  capital-gain  \\\n",
      "0       adm-clerical  not-in-family  white    male          2174   \n",
      "1    exec-managerial        husband  white    male             0   \n",
      "2  handlers-cleaners  not-in-family  white    male             0   \n",
      "3  handlers-cleaners        husband  black    male             0   \n",
      "4     prof-specialty           wife  black  female             0   \n",
      "\n",
      "   capital-loss  hours-per-week native-country income  \n",
      "0             0              40  united-states  <=50k  \n",
      "1             0              13  united-states  <=50k  \n",
      "2             0              40  united-states  <=50k  \n",
      "3             0              40  united-states  <=50k  \n",
      "4             0              40           cuba  <=50k  \n",
      "   age         workclass     education  education-num      marital-status  \\\n",
      "0   38           private       hs-grad              9  married-civ-spouse   \n",
      "1   28         local-gov    assoc-acdm             12  married-civ-spouse   \n",
      "2   44           private  some-college             10  married-civ-spouse   \n",
      "4   34           private          10th              6       never-married   \n",
      "6   63  self-emp-not-inc   prof-school             15  married-civ-spouse   \n",
      "\n",
      "          occupation   relationship   race   sex  capital-gain  capital-loss  \\\n",
      "0    farming-fishing        husband  white  male             0             0   \n",
      "1    protective-serv        husband  white  male             0             0   \n",
      "2  machine-op-inspct        husband  black  male          7688             0   \n",
      "4      other-service  not-in-family  white  male             0             0   \n",
      "6     prof-specialty        husband  white  male          3103             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              50  united-states  <=50k  \n",
      "1              40  united-states   >50k  \n",
      "2              40  united-states   >50k  \n",
      "4              30  united-states  <=50k  \n",
      "6              32  united-states   >50k  \n"
     ]
    }
   ],
   "source": [
    " for col in object_col:\n",
    "    print(adult_train[col].value_counts(dropna=False)/adult_train.shape[0],'\\n')\n",
    "print(adult_train.head())\n",
    "print(adult_test.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass    education  education-num      marital-status  \\\n",
      "0   39         state-gov    bachelors             13       never-married   \n",
      "1   50  self-emp-not-inc    bachelors             13  married-civ-spouse   \n",
      "2   38           private      hs-grad              9            divorced   \n",
      "3   53           private  high-school              7  married-civ-spouse   \n",
      "4   28           private    bachelors             13  married-civ-spouse   \n",
      "\n",
      "          occupation   relationship   race     sex  capital-gain  \\\n",
      "0       adm-clerical  not-in-family  white    male          2174   \n",
      "1    exec-managerial        husband  white    male             0   \n",
      "2  handlers-cleaners  not-in-family  white    male             0   \n",
      "3  handlers-cleaners        husband  black    male             0   \n",
      "4     prof-specialty           wife  black  female             0   \n",
      "\n",
      "   capital-loss  hours-per-week     native-country income  \n",
      "0             0              40      united-states      0  \n",
      "1             0              13      united-states      0  \n",
      "2             0              40      united-states      0  \n",
      "3             0              40      united-states      0  \n",
      "4             0              40  non-united-stated      0  \n",
      "   age         workclass     education  education-num      marital-status  \\\n",
      "0   38           private       hs-grad              9  married-civ-spouse   \n",
      "1   28         local-gov    assoc-acdm             12  married-civ-spouse   \n",
      "2   44           private  some-college             10  married-civ-spouse   \n",
      "3   34           private   high-school              6       never-married   \n",
      "4   63  self-emp-not-inc   prof-school             15  married-civ-spouse   \n",
      "\n",
      "          occupation   relationship   race   sex  capital-gain  capital-loss  \\\n",
      "0    farming-fishing        husband  white  male             0             0   \n",
      "1    protective-serv        husband  white  male             0             0   \n",
      "2  machine-op-inspct        husband  black  male          7688             0   \n",
      "3      other-service  not-in-family  white  male             0             0   \n",
      "4     prof-specialty        husband  white  male          3103             0   \n",
      "\n",
      "   hours-per-week native-country income  \n",
      "0              50  united-states      0  \n",
      "1              40  united-states      1  \n",
      "2              40  united-states      1  \n",
      "3              30  united-states      0  \n",
      "4              32  united-states      1  \n"
     ]
    }
   ],
   "source": [
    "adult_train.reset_index(drop=True, inplace=True)\n",
    "adult_test.reset_index(drop=True, inplace=True)\n",
    "p=adult_train.shape[0]\n",
    "q =adult_test.shape[0]\n",
    "# reducing dimensionality of some very sparse features\n",
    "for i in range(0,p):\n",
    "    if adult_train.loc[i,'native-country'] not in [\"united-states\"] :\n",
    "               adult_train.loc[i,\"native-country\"] = \"non-united-stated\"        \n",
    "    if adult_train.loc[i,\"education\"] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "               adult_train.loc[i,\"education\"] = \"prim-middle-school\"\n",
    "    elif adult_train.loc[i,\"education\"] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "               adult_train.loc[i,\"education\"] = \"high-school\"   \n",
    "    if adult_train.loc[i,'income'] in [\">50k\"] :\n",
    "               adult_train.loc[i,\"income\"] = 1 \n",
    "    else: \n",
    "               adult_train.loc[i,\"income\"] = 0         \n",
    "#reducing dimensionality of some very sparse features\n",
    "for i in range(0,q):                \n",
    "    if adult_test.loc[i,'native-country'] not in [\"united-states\"]:\n",
    "               adult_test.loc[i,'native-country'] = \"Non-United-Stated\"\n",
    "    if adult_test.loc[i,'education'] in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "               adult_test.loc[i,'education'] = \"prim-middle-school\"\n",
    "    elif adult_test.loc[i,'education'] in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "               adult_test.loc[i,'education'] = \"high-school\"   \n",
    "    if adult_test.loc[i,'native-country'] not in [\"united-states\"] :\n",
    "               adult_train.loc[i,\"native-country\"] = \"non-united-stated\"\n",
    "    if adult_test.loc[i,'income'] in [\">50k\"] :\n",
    "               adult_test.loc[i,\"income\"] = 1 \n",
    "    else: \n",
    "               adult_test.loc[i,\"income\"] = 0            \n",
    "print(adult_train.head())\n",
    "print(adult_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>state-gov</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>never-married</td>\n",
       "      <td>adm-clerical</td>\n",
       "      <td>not-in-family</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>self-emp-not-inc</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>exec-managerial</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>private</td>\n",
       "      <td>hs-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>divorced</td>\n",
       "      <td>handlers-cleaners</td>\n",
       "      <td>not-in-family</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>private</td>\n",
       "      <td>high-school</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>handlers-cleaners</td>\n",
       "      <td>husband</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>private</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>prof-specialty</td>\n",
       "      <td>wife</td>\n",
       "      <td>black</td>\n",
       "      <td>female</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>non-united-stated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age         workclass    education  education-num      marital-status  \\\n",
       "0  0.301370         state-gov    bachelors       0.800000       never-married   \n",
       "1  0.452055  self-emp-not-inc    bachelors       0.800000  married-civ-spouse   \n",
       "2  0.287671           private      hs-grad       0.533333            divorced   \n",
       "3  0.493151           private  high-school       0.400000  married-civ-spouse   \n",
       "4  0.150685           private    bachelors       0.800000  married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital-gain  \\\n",
       "0       adm-clerical  not-in-family  white    male       0.02174   \n",
       "1    exec-managerial        husband  white    male       0.00000   \n",
       "2  handlers-cleaners  not-in-family  white    male       0.00000   \n",
       "3  handlers-cleaners        husband  black    male       0.00000   \n",
       "4     prof-specialty           wife  black  female       0.00000   \n",
       "\n",
       "   capital-loss  hours-per-week     native-country income  \n",
       "0           0.0        0.397959      united-states      0  \n",
       "1           0.0        0.122449      united-states      0  \n",
       "2           0.0        0.397959      united-states      0  \n",
       "3           0.0        0.397959      united-states      0  \n",
       "4           0.0        0.397959  non-united-stated      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>private</td>\n",
       "      <td>hs-grad</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>farming-fishing</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>local-gov</td>\n",
       "      <td>assoc-acdm</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>protective-serv</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>united-states</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.369863</td>\n",
       "      <td>private</td>\n",
       "      <td>some-college</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>machine-op-inspct</td>\n",
       "      <td>husband</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>0.076881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>united-states</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.232877</td>\n",
       "      <td>private</td>\n",
       "      <td>high-school</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>never-married</td>\n",
       "      <td>other-service</td>\n",
       "      <td>not-in-family</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630137</td>\n",
       "      <td>self-emp-not-inc</td>\n",
       "      <td>prof-school</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>prof-specialty</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0.031030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316327</td>\n",
       "      <td>united-states</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age         workclass     education  education-num  \\\n",
       "0  0.287671           private       hs-grad       0.533333   \n",
       "1  0.150685         local-gov    assoc-acdm       0.733333   \n",
       "2  0.369863           private  some-college       0.600000   \n",
       "3  0.232877           private   high-school       0.333333   \n",
       "4  0.630137  self-emp-not-inc   prof-school       0.933333   \n",
       "\n",
       "       marital-status         occupation   relationship   race   sex  \\\n",
       "0  married-civ-spouse    farming-fishing        husband  white  male   \n",
       "1  married-civ-spouse    protective-serv        husband  white  male   \n",
       "2  married-civ-spouse  machine-op-inspct        husband  black  male   \n",
       "3       never-married      other-service  not-in-family  white  male   \n",
       "4  married-civ-spouse     prof-specialty        husband  white  male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0      0.000000           0.0        0.500000  united-states      0  \n",
       "1      0.000000           0.0        0.397959  united-states      1  \n",
       "2      0.076881           0.0        0.397959  united-states      1  \n",
       "3      0.000000           0.0        0.295918  united-states      0  \n",
       "4      0.031030           0.0        0.316327  united-states      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "num_col = adult_train.dtypes[adult_train.dtypes != 'object'].index\n",
    "features_log_minmax_transform = pd.DataFrame(data = adult_train)\n",
    "features_log_minmax_transform[num_col] = scaler.fit_transform(features_log_minmax_transform[num_col])\n",
    "\n",
    "# Transform the test data set\n",
    "features_log_minmax_transform_test = pd.DataFrame(data = adult_test)\n",
    "features_log_minmax_transform_test[num_col] = scaler.transform(features_log_minmax_transform_test[num_col])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_log_minmax_transform.head())\n",
    "display(features_log_minmax_transform_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "58\n",
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "15054    False\n",
      "15055    False\n",
      "15056    False\n",
      "15057    False\n",
      "15058    False\n",
      "Name: INC, Length: 15059, dtype: bool\n",
      "object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Data_train = pd.get_dummies(features_log_minmax_transform, columns=['workclass','education','marital-status','occupation','relationship','native-country','race'], prefix =['work','edu','ms','occ','rls','nc','r'])\n",
    "Data_train['INC'] = Data_train.loc[:,'income']\n",
    "Data_train=Data_train.drop(columns=['income','sex'])\n",
    "\n",
    "Data_test = pd.get_dummies(features_log_minmax_transform_test, columns=['workclass','education','marital-status','occupation','relationship','native-country','race'], prefix =['work','edu','ms','occ','rls','nc','r'])\n",
    "Data_test['INC'] = Data_test.loc[:,'income']\n",
    "Data_test=Data_test.drop(columns=['income','sex'])\n",
    "\n",
    "m=Data_train.shape[1]\n",
    "\n",
    "X_train=Data_train.iloc[:,0:m-1]\n",
    "Y_train=Data_train.iloc[:,m-1]\n",
    "print(m)\n",
    "\n",
    "m=Data_test.shape[1]\n",
    "X_test=Data_test.iloc[:,0:m-1]\n",
    "Y_test=Data_test.iloc[:,m-1]\n",
    "\n",
    "\n",
    "print(m)\n",
    "sensitive_attr_train=adult_train.drop(columns=['age','workclass','education','education-num','marital-status','occupation','relationship','capital-gain','capital-loss','hours-per-week','native-country','income','race'])\n",
    "sensitive_attr_train = pd.get_dummies(sensitive_attr_train, columns=['sex'], prefix =['s'])\n",
    "#print(sensitive_attr_train.head())\n",
    "sensitive_attr_test=adult_test.drop(columns=['age','workclass','education','education-num','marital-status','occupation','relationship','capital-gain','capital-loss','hours-per-week','native-country','income','race'])\n",
    "sensitive_attr_test = pd.get_dummies(sensitive_attr_test, columns=['sex'], prefix =['s'])\n",
    "#print(sensitive_attr_train.head())\n",
    "\n",
    "\n",
    "# display(X_train.head())\n",
    "# display(X_test.head())\n",
    "# display(Y_train.head())\n",
    "# display(Y_test.head())\n",
    "\n",
    "\n",
    "print(Y_test.isin(['>50k'])) \n",
    "\n",
    "\n",
    "\n",
    "print(Y_test.dtype)\n",
    "Y_test=Y_test.astype('int')\n",
    "Y_train=Y_train.astype('int')\n",
    "\n",
    "print(Y_test.dtype)\n",
    "# print(X_train.shape[0])\n",
    "# print(X_test.shape[0])\n",
    "# print(Y_train.shape[0])\n",
    "# print(Y_test.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['uniform', 'randint', 'shuffle', 'time', 'random', 'choice', 'sample', 'seed', 'triangular']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "#SVM \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def Adult_svm(X_train,X_test,Y_train,Y_test):\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0,shuffle=False) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "\n",
    "    #Scaling data\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    #sc = StandardScaler(with_mean=False)\n",
    "    \n",
    "    \n",
    "    #sc.fit(X_train)\n",
    "    #X_train_std = sc.transform(X_train)\n",
    "    #X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.1, C=10.0)\n",
    "    svm.fit(X_train, Y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test, Y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    Y_train_pred=svm.predict(X_train)\n",
    "    #print(y_1)\n",
    "    Y_test_pred=svm.predict(X_test)\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "\n",
    "\n",
    "    print('####Change to colors###############################################')\n",
    "        \n",
    "    \n",
    "    return Y_train_pred,Y_train,Y_test_pred,Y_test\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adult_rf(X_train,X_test,Y_train,Y_test):   \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rf = RandomForestClassifier(n_estimators= 100, random_state=42)\n",
    "    # Extract the two most important features\n",
    "    \n",
    "    \n",
    "    # Train the random forest\n",
    "    rf.fit(X_train, Y_train)\n",
    "    # Make predictions and determine the error\n",
    "    Y_train_pred = rf.predict(X_train)\n",
    "    Y_test_pred = rf.predict(X_test)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(rf.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(rf.score(X_test, Y_test)))\n",
    "    \n",
    "    return Y_train_pred,Y_train,Y_test_pred,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adult_mlp(X_train,X_test,Y_train,Y_test):   \n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    mlp = MLPClassifier(solver='adam', hidden_layer_sizes=(53, 2),alpha=1e-5, random_state=42)\n",
    "    # Extract the two most important features\n",
    "    \n",
    "    \n",
    "    # Train the random forest\n",
    "    mlp.fit(X_train, Y_train)\n",
    "    # Make predictions and determine the error\n",
    "    Y_train_pred = mlp.predict(X_train)\n",
    "    Y_test_pred = mlp.predict(X_test)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(mlp.score(X_train, Y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(mlp.score(X_test, Y_test)))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return Y_train_pred,Y_train,Y_test_pred,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table1 for Adult\n",
    "\n",
    "import time\n",
    "import pulp as p \n",
    "def min_max_lp_all(data1,gamma,eps,r):\n",
    "    \n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "   \n",
    "    \n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1\n",
    "                \n",
    "        sizes[i]=count\n",
    "  \n",
    "\n",
    "    for i in range(n):\n",
    "        var1=str(i)\n",
    "        \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "       \n",
    "        \n",
    "    X[n] =  p.LpVariable(\"z1\",lowBound=0)\n",
    "\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob += X[n]\n",
    "\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)])\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) >= (2*gamma-1)*sizes[i]\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) <= ((2*gamma-1)+eps)*sizes[i]\n",
    "            \n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*data1[i-m][j] for j in range(n)])\n",
    "            \n",
    "         \n",
    " \n",
    "    #n is the number of elements in sensitive attribute \n",
    "           \n",
    "       \n",
    "    Lp_prob += X[n] <= 42000\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "   # The solution status \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table1 for Adult\n",
    "\n",
    "import time\n",
    "import pulp as p \n",
    "def min_max_lp_all2(data1,gam,eps,r,delta):\n",
    "    \n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "   \n",
    "    \n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1\n",
    "                \n",
    "        sizes[i]=count\n",
    "  \n",
    "\n",
    "    for i in range(n):\n",
    "        var1=str(i)\n",
    "        \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "    \n",
    "    #########################\n",
    "    gamma=np.zeros(2,dtype=int)\n",
    "    gamma[0]=0.5\n",
    "    gamma[1]=0.05\n",
    "        \n",
    "    X[n]=  p.LpVariable(\"z1\",lowBound=0)\n",
    "    #X[n+1]=  p.LpVariable(\"z2\",lowBound=0)\n",
    "\n",
    "     \n",
    "    #########objective function#####################\n",
    "    Lp_prob += X[n] \n",
    "    #Lp_prob += 1 \n",
    "\n",
    "    \n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)])\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) >= (2*gamma[i]-1)*sizes[i]\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) <= ((2*gamma[i]-1)+eps)*sizes[i]\n",
    "            \n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*data1[i-m][j] for j in range(n)])\n",
    "            #Lp_prob += X[n+1] >= p.lpSum([-1*2*(X[j]-0.5)+r[j] for j in range(n)]) \n",
    "#     Lp_prob += X[n+1] >= p.lpSum([2*(X[j]-0.5)-r[j] for j in range(n)])\n",
    "#     Lp_prob += X[n+1] >= p.lpSum([-1*2*(X[j]-0.5)+r[j] for j in range(n)])       \n",
    "         \n",
    "    Lp_prob += p.lpSum([2*(X[i]-0.5)*r[i] for i in range(n)])>=delta*n\n",
    "    #n is the number of elements in sensitive attribute \n",
    "           \n",
    "       \n",
    "    Lp_prob += X[n] <= 42000\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "   # The solution status \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_female</th>\n",
       "      <th>s_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15054</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15055</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15056</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15057</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15058</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15059 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       s_female  s_male\n",
       "0             0       1\n",
       "1             0       1\n",
       "2             0       1\n",
       "3             0       1\n",
       "4             0       1\n",
       "...         ...     ...\n",
       "15054         0       1\n",
       "15055         1       0\n",
       "15056         0       1\n",
       "15057         0       1\n",
       "15058         0       1\n",
       "\n",
       "[15059 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sensitive_attr_test)\n",
    "sens_train=sensitive_attr_train.transpose()\n",
    "sens_test=sensitive_attr_test.transpose()\n",
    "#gamma=0.1\n",
    "#eps=0.1\n",
    "#min_max_lp_all(sens_test,gamma,eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30162 samples in the training set and 15059 samples in the test set\n",
      "The accuracy of the SVM classifier on training data is 0.86\n",
      "The accuracy of the SVM classifier on test data is 0.85\n",
      "####Train prediction Label###############################################\n",
      "####Actual Train Label###############################################\n",
      "####Change to colors###############################################\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred,Y_train,Y_test_pred,Y_test=Adult_svm(X_train,X_test,Y_train,Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred,Y_train,Y_test_pred,Y_test=Adult_rf(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred,Y_train,Y_test_pred,Y_test=Adult_mlp(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Feldman----nonwhite white female male \n",
    "\n",
    "#data1=sens_test\n",
    "\n",
    "# min_max_lp_all(data1,gamma,eps,r):\n",
    "\n",
    "rows=Y_test.shape[0]   \n",
    "\n",
    "###############################################33       \n",
    "r = np.zeros(rows, dtype = int)\n",
    "for i in range(rows):\n",
    "    if Y_test.iloc[i]==0 :\n",
    "        r[i]=-1\n",
    "    else :\n",
    "        r[i]= 1  \n",
    "r2 = np.zeros(rows, dtype = int)        \n",
    "        \n",
    "for i in range(rows):\n",
    "    if Y_test_pred[i]==0 :\n",
    "        r2[i]=-1\n",
    "    else :\n",
    "        r2[i]= 1        \n",
    "        \n",
    "data = np.zeros((4, rows), dtype = float)\n",
    "\n",
    "a=0\n",
    "b=0\n",
    "c=0\n",
    "d=0\n",
    "\n",
    "acc1=0\n",
    "acc2=0\n",
    "acc3=0\n",
    "acc4=0\n",
    "\n",
    "\n",
    "for i in range(rows):\n",
    "    if (sensitive_attr_test.iloc[i,0]==1 or sensitive_attr_test.iloc[i,1]==1 or sensitive_attr_test.iloc[i,2]==1 or sensitive_attr_test.iloc[i,3]==1):\n",
    "            if(sensitive_attr_test.iloc[i,5]==1):\n",
    "                data[0][i]= 1\n",
    "                a=a+1\n",
    "                if r[i]==1:\n",
    "                    acc1=acc1+1\n",
    "    elif sensitive_attr_test.iloc[i,4]==1:\n",
    "            if(sensitive_attr_test.iloc[i,5]==1):\n",
    "                data[1][i]= 1\n",
    "                b=b+1\n",
    "                if r[i]==1:\n",
    "                    acc2=acc2+1\n",
    "    if (sensitive_attr_test.iloc[i,0]==1 or sensitive_attr_test.iloc[i,1]==1 or sensitive_attr_test.iloc[i,2]==1 or sensitive_attr_test.iloc[i,3]==1):\n",
    "           if(sensitive_attr_test.iloc[i,6]==1):\n",
    "                data[2][i]= 1\n",
    "                c=c+1\n",
    "                if r[i]==1:\n",
    "                    acc3=acc3+1\n",
    "    elif sensitive_attr_test.iloc[i,4]==1:\n",
    "           if(sensitive_attr_test.iloc[i,6]==1):\n",
    "                data[3][i]= 1\n",
    "                d=d+1\n",
    "                if r[i]==1:\n",
    "                    acc4=acc4+1   \n",
    "print(a,b,c,d)              \n",
    "print(acc1,acc2,acc3,acc4)\n",
    "a1=float(acc1/a)\n",
    "b1=float(acc2/b)\n",
    "c1=float(acc3/c)\n",
    "d1=float(acc4/d)\n",
    "\n",
    "\n",
    "print(a1,b1,c1,d1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "\n",
    "\n",
    "# for gamma in np.arange(0.15,0.5,.05):\n",
    "#     for eps in np.arange(0.05,0.02,-.01): \n",
    "gamma=0.16\n",
    "eps=0.06\n",
    "for gamma in np.arange(.05,.28,0.05):\n",
    "    acc1=0\n",
    "    acc2=0\n",
    "    acc3=0\n",
    "    acc4=0\n",
    "   \n",
    "\n",
    "\n",
    "    u1,u2=min_max_lp_all(data,gamma,eps,r)\n",
    "\n",
    "    #######################Disp_impact#######################  \n",
    "\n",
    "    for i in range(rows):\n",
    "            if data[0][i]== 1 and u1[i]==1:\n",
    "                    acc1=acc1+1\n",
    "            elif data[1][i]== 1 and u1[i]==1:\n",
    "                    acc2=acc2+1  \n",
    "            elif data[2][i]== 1 and u1[i]==1:\n",
    "                    acc3=acc3+1 \n",
    "            elif data[3][i]== 1 and u1[i]==1:\n",
    "                    acc4=acc4+1                \n",
    "\n",
    "    a1=float(acc1/a)\n",
    "    b1=float(acc2/b)\n",
    "    c1=float(acc3/c)\n",
    "    d1=float(acc4/d)\n",
    "#    print(acc1,acc2,acc3,acc4)\n",
    "#    print(a1,b1,c1,d1)\n",
    "\n",
    "#     count1=0\n",
    "#     count2=0\n",
    "#     for j in range(r.shape[0]):\n",
    "#             if(r[j]==u1[j]):\n",
    "#                 count1+=1\n",
    "#     acc1=float(count1/r.shape[0])        \n",
    "\n",
    "#     for j in range(r.shape[0]):\n",
    "#             if(r[j]==u2[j]):\n",
    "#                 count2+=1\n",
    "#     acc2=float(count2/r.shape[0]) \n",
    "#     print(acc1)\n",
    "#     print(acc2)\n",
    "#     print(gamma)\n",
    "#     print(eps)\n",
    "    \n",
    "#     acc2_l.append(acc2)\n",
    "#     acc1_l.append(acc1)\n",
    "\n",
    "\n",
    "#     print(\"Accuracy::\")    \n",
    "#     print(acc1_l)     \n",
    "#     print(acc2_l)\n",
    "\n",
    "#     ###########################\n",
    "#     a_acc=0\n",
    "#     b_acc=0\n",
    "\n",
    "    fi= np.zeros(rows,dtype=int) \n",
    "    count=0\n",
    "    acc=0\n",
    "    ci=[]\n",
    "    for alpha in np.arange(0,1.05,0.05):\n",
    "        f_acc=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "        acc3=0\n",
    "        acc4=0\n",
    "       \n",
    "        for i in range(rows):\n",
    "\n",
    "            z=random()\n",
    "            if z < alpha:\n",
    "                    fi[i]= u1[i] \n",
    "                    count=count+1\n",
    "            else:\n",
    "                   fi[i]= r2[i]\n",
    "\n",
    "        for i in range(rows):\n",
    "             if fi[i] == r[i]:\n",
    "                    f_acc=f_acc+1\n",
    "\n",
    "\n",
    "        f_acc_percent=f_acc/rows\n",
    "        ci.append(f_acc_percent)\n",
    "\n",
    "        for i in range(rows):\n",
    "            if data[0][i]== 1 and fi[i]==1:\n",
    "                    acc1=acc1+1\n",
    "            elif data[1][i]== 1 and fi[i]==1:\n",
    "                    acc2=acc2+1  \n",
    "            elif data[2][i]== 1 and fi[i]==1:\n",
    "                    acc3=acc3+1 \n",
    "            elif data[3][i]== 1 and fi[i]==1:\n",
    "                    acc4=acc4+1         \n",
    "            \n",
    "\n",
    "\n",
    "        a1=float(acc1/a)\n",
    "        b1=float(acc2/b)\n",
    "        c1=float(acc3/c)\n",
    "        d1=float(acc4/d)\n",
    "       \n",
    "        print(acc1,acc2,acc3,acc4)\n",
    "        print(a1,b1,c1,d1)\n",
    "    print(ci)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4913 10146\n",
      "557 3143\n",
      "0.11337268471402402 0.3097772521190617\n",
      "dimension of data\n",
      "2 15059\n",
      "Optimal\n",
      "discripency is:\n",
      "8118.0\n",
      "0.08406269082027275 0.25231618371772124\n",
      "0.08406269082027275 0.2431500098561009\n",
      "0.08406269082027275 0.23447664104080426\n",
      "0.08406269082027275 0.22807017543859648\n",
      "0.08406269082027275 0.22343780800315396\n",
      "0.08406269082027275 0.21584861028976937\n",
      "0.08406269082027275 0.20451409422432484\n",
      "0.08406269082027275 0.1995860437610881\n",
      "0.08406269082027275 0.19317957815888034\n",
      "0.08406269082027275 0.1803666469544648\n",
      "0.08406269082027275 0.17819830475064063\n",
      "0.08406269082027275 0.16794795978710822\n",
      "0.08406269082027275 0.1608515671200473\n",
      "0.08406269082027275 0.15799329785137\n",
      "0.08406269082027275 0.1407451212300414\n",
      "0.08406269082027275 0.14094224324857085\n",
      "0.08406269082027275 0.12842499507194954\n",
      "0.08406269082027275 0.1263552138773901\n",
      "0.08406269082027275 0.11738616203429923\n",
      "0.08406269082027275 0.10546027991326631\n",
      "0.08406269082027275 0.09994086339444117\n",
      "[0.8462713327578193, 0.8387675144431901, 0.8337206985855634, 0.8298027757487217, 0.8226973902649578, 0.8169201142174115, 0.8110100272262435, 0.8046351019323992, 0.794475064745335, 0.7891626270004648, 0.7831861345374859, 0.7754830998074241, 0.7699050401753105, 0.765854306394847, 0.7575536224184873, 0.7543661597715652, 0.7454014210770967, 0.7402881997476592, 0.7342453018128694, 0.7256789959492662, 0.7206321800916395]\n",
      "[0.1682534928974485, 0.15908731903582818, 0.1504139502205315, 0.14400748461832374, 0.1393751171828812, 0.13178591946949664, 0.1204514034040521, 0.11552335294081535, 0.1091168873386076, 0.09630395613419206, 0.09413561393036789, 0.08388526896683547, 0.07678887629977456, 0.07393060703109726, 0.056682430409768655, 0.056879552428298105, 0.044362304251676796, 0.04229252305711735, 0.033323471214026484, 0.021397589092993566, 0.015878172574168417]\n",
      "[0.33316408635253414, 0.3457235756232215, 0.3585120054907471, 0.3685825674427344, 0.376224111628799, 0.3894520826769348, 0.411036174006018, 0.42118521533949993, 0.43515309237882005, 0.46606560713797124, 0.47173675943721644, 0.5005282048488775, 0.5226103315333869, 0.5320649164457188, 0.5972689503238706, 0.5964336091346065, 0.6545664321277722, 0.6652886591751072, 0.7161209580709381, 0.7971028608060629, 0.841124320574445]\n"
     ]
    }
   ],
   "source": [
    "########Bilalzafar  (race-5) + (gender-2)\n",
    "\n",
    "#data1=sens_test\n",
    "\n",
    "# min_max_lp_all(data1,gamma,eps,r):\n",
    "\n",
    "rows=Y_test.shape[0]   \n",
    "\n",
    "###############################################33       \n",
    "r = np.zeros(rows, dtype = int)\n",
    "for i in range(rows):\n",
    "    if Y_test.iloc[i]==0 :\n",
    "        r[i]=-1\n",
    "    else :\n",
    "        r[i]= 1  \n",
    "r2 = np.zeros(rows, dtype = int)        \n",
    "        \n",
    "for i in range(rows):\n",
    "    if Y_test_pred[i]==0 :\n",
    "        r2[i]=-1\n",
    "    else :\n",
    "        r2[i]= 1        \n",
    "        \n",
    "data = np.zeros((2, rows), dtype = float)\n",
    "\n",
    "a=0\n",
    "b=0\n",
    "\n",
    "\n",
    "acc1=0\n",
    "acc2=0\n",
    "\n",
    "\n",
    "\n",
    "for i in range(rows):\n",
    "    if (sensitive_attr_test.iloc[i,0]==1):\n",
    "                data[0][i]= 1\n",
    "                a=a+1\n",
    "                if r[i]==1:\n",
    "                    acc1=acc1+1\n",
    "    elif (sensitive_attr_test.iloc[i,1]==1):\n",
    "                data[1][i]= 1\n",
    "                b=b+1\n",
    "                if r[i]==1:\n",
    "                    acc2=acc2+1              \n",
    "print(a,b)              \n",
    "print(acc1,acc2)\n",
    "a1=float(acc1/a)\n",
    "b1=float(acc2/b)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(a1,b1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "#madaras=\n",
    "\n",
    "\n",
    "# for gamma in np.arange(0.15,0.5,.05):\n",
    "# for eps in np.arange(0.05,0.02,-.01): \n",
    "#gamma=0.16\n",
    "eps=.20\n",
    "delta=.500\n",
    "for gamma in np.arange(.05,.06,0.05):\n",
    "    a1=0\n",
    "    b1=0\n",
    "  \n",
    "   \n",
    "\n",
    "\n",
    "    u1,u2=min_max_lp_all2(data,gamma,eps,r2,delta)\n",
    "\n",
    "    #######################Disp_impact#######################  \n",
    "\n",
    "    for i in range(rows):\n",
    "            if data[0][i]== 1 and u1[i]==1:\n",
    "                    acc1=acc1+1\n",
    "            elif data[1][i]== 1 and u1[i]==1:\n",
    "                    acc2=acc2+1  \n",
    "                 \n",
    "\n",
    "    a1=float(acc1/a)\n",
    "    b1=float(acc2/b)\n",
    "    \n",
    "#    print(acc1,acc2,acc3,acc4)\n",
    "#    print(a1,b1,c1,d1)\n",
    "\n",
    "#     count1=0\n",
    "#     count2=0\n",
    "#     for j in range(r.shape[0]):\n",
    "#             if(r[j]==u1[j]):\n",
    "#                 count1+=1\n",
    "#     acc1=float(count1/r.shape[0])        \n",
    "\n",
    "#     for j in range(r.shape[0]):\n",
    "#             if(r[j]==u2[j]):\n",
    "#                 count2+=1\n",
    "#     acc2=float(count2/r.shape[0]) \n",
    "#     print(acc1)\n",
    "#     print(acc2)\n",
    "#     print(gamma)\n",
    "#     print(eps)\n",
    "    \n",
    "#     acc2_l.append(acc2)\n",
    "#     acc1_l.append(acc1)\n",
    "\n",
    "\n",
    "#     print(\"Accuracy::\")    \n",
    "#     print(acc1_l)     \n",
    "#     print(acc2_l)\n",
    "\n",
    "#     ###########################\n",
    "#     a_acc=0\n",
    "#     b_acc=0\n",
    "\n",
    "    fi= np.zeros(rows,dtype=int) \n",
    "    count=0\n",
    "    acc=0\n",
    "    ci=[]\n",
    "    k=0\n",
    "    di= [] \n",
    "    di2=[]\n",
    "    for alpha in np.arange(0,1.05,0.05):\n",
    "        f_acc=0\n",
    "        acc1=0\n",
    "        acc2=0\n",
    "       \n",
    "        for i in range(rows):\n",
    "\n",
    "            z=random()\n",
    "            if z < alpha:\n",
    "                    fi[i]= u1[i] \n",
    "                    count=count+1\n",
    "            else:\n",
    "                   fi[i]= r2[i]\n",
    "\n",
    "        for i in range(rows):\n",
    "             if fi[i] == r[i]:\n",
    "                    f_acc=f_acc+1\n",
    "\n",
    "\n",
    "        f_acc_percent=f_acc/rows\n",
    "        ci.append(f_acc_percent)\n",
    "\n",
    "        for i in range(rows):\n",
    "            if data[0][i]== 1 and fi[i]==1:\n",
    "                    acc1=acc1+1\n",
    "            elif data[1][i]== 1 and fi[i]==1:\n",
    "                    acc2=acc2+1  \n",
    "              \n",
    "\n",
    "\n",
    "        a1=float(acc1/a)\n",
    "        b1=float(acc2/b)\n",
    "        print(a1,b1)\n",
    "        #print(acc1,acc2,acc3,acc4,acc4,acc6,acc7)\n",
    "        #print(a1,b1,c1,d1,e1,f1,g1)\n",
    "        k2=min(a1,b1)/max(a1,b1)\n",
    "        k=max(a1,b1)-min(a1,b1)\n",
    "        di.append(k)\n",
    "        di2.append(k2)\n",
    "    print(ci)\n",
    "    print(di)\n",
    "    print(di2)\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
