{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prepare_adult_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1a3de3962e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprepare_adult_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_adult_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../../fair_classification/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the code for fair classification is in this directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prepare_adult_data'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os,sys\n",
    "import numpy as np\n",
    "from prepare_adult_data import load_adult_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.insert(0, '../../fair_classification/') # the code for fair classification is in this directory\n",
    "\n",
    "\n",
    "import stats_pref_fairness as compute_stats\n",
    "#from linear_clf_pref_fairness import linearclf\n",
    "\n",
    "import linear_clf_pref_fairness as l\n",
    "\n",
    "def print_stats_and_plots(x,y,x_sensitive, clf):\n",
    "\n",
    "    dist_arr, dist_dict = clf.get_distance_boundary(x, x_sensitive)\n",
    "    acc, _, acc_stats = compute_stats.get_clf_stats(dist_arr, dist_dict, y, x_sensitive, print_stats=true)\n",
    "\n",
    "\n",
    "def test_adult_data():\n",
    "    \n",
    "    \"\"\" load data \"\"\"\n",
    "    x, y, x_sensitive = load_adult_data(10000) # set plot_data to false to skip the data plot\n",
    "    x = compute_stats.add_intercept(x)\n",
    "\n",
    "    \"\"\" split the data into train and test \"\"\"\n",
    "    test_fold_size = 0.3\n",
    "    x_train, x_test, y_train, y_test, x_sensitive_train, x_sensitive_test =  train_test_split(x, y, x_sensitive, test_size=test_fold_size, random_state=1234, shuffle=false)\n",
    "    compute_stats.scale_data(x_train, x_test)\n",
    "    \n",
    "\n",
    "\n",
    "    # classifier parameters \n",
    "    loss_function = \"logreg\" # perform the experiments with logistic regression\n",
    "    eps = 1e-3\n",
    "\n",
    "    \"\"\" unconstrained classifier \"\"\"\n",
    "\n",
    "\n",
    "    cons_params = {}\n",
    "    cons_params[\"eps\"] = eps\n",
    "    cons_params[\"cons_type\"] = -1 # no constraint\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n\\n== unconstrained classifier ==\")\n",
    "    # train a classifier for each sensitive feature group separately optimizing accuracy for the respective group    \n",
    "    clf_group = {}\n",
    "    lam = {0:1e-5, 1:1e-5} # the regularization parameter -- we set small values here, in the paper, we cross validate all of regularization parameters\n",
    "    for s_attr_val in set(x_sensitive_train):\n",
    "        idx = x_sensitive_train==s_attr_val # the index for the current sensitive feature group\n",
    "        clf = l.linearclf(loss_function, lam=lam[s_attr_val], train_multiple=false)\n",
    "        clf.fit(x_train[idx], y_train[idx], x_sensitive_train[idx], cons_params)\n",
    "        clf_group[s_attr_val] = clf\n",
    "\n",
    "    # for simplicity of computing stats, we merge the two trained classifiers\n",
    "    clf_merged = l.linearclf(loss_function, lam=lam, train_multiple=true) \n",
    "    clf_merged.w = {0:none, 1:none}\n",
    "    for s_attr_val in set(x_sensitive_train):\n",
    "        clf_merged.w[s_attr_val] = clf_group[s_attr_val].w\n",
    "\n",
    "    print_stats_and_plots(x_test, y_test, x_sensitive_test, clf_merged)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"\\n\\n== parity classifier ==\")\n",
    "    cons_params[\"cons_type\"] = 0\n",
    "    clf = l.linearclf(loss_function, lam=1e-5, train_multiple=false)\n",
    "    clf.fit(x_train, y_train, x_sensitive_train, cons_params)\n",
    "    print_stats_and_plots(x_test, y_test, x_sensitive_test, clf)\n",
    "\n",
    "    # compute the proxy value, will need this for the preferential classifiers\n",
    "    dist_arr,dist_dict=clf.get_distance_boundary(x_train, x_sensitive_train)\n",
    "    s_val_to_cons_sum_di = compute_stats.get_sensitive_attr_cov(dist_dict)\n",
    "    \n",
    "\n",
    "\n",
    "  \n",
    "    print(\"\\n\\n\\n\\n== preferred impact classifier ==\")\n",
    "\n",
    "    # not all values of the lambda satisfy the constraints empirically (in terms of acceptace rates)\n",
    "    # this is because the scale (or norm) of the group-conditional classifiers can be very different from the baseline parity classifier, and from each other. this affects the distance from boundary (w.x) used in the constraints.\n",
    "    # we use a hold out set with different regaularizer values to validate the norms that satisfy the constraints. check the appendix of our nips paper for more details. \n",
    "\n",
    "\n",
    "    cons_params[\"cons_type\"] = 1\n",
    "    cons_params[\"tau\"] = 0.1\n",
    "    cons_params[\"s_val_to_cons_sum\"] = s_val_to_cons_sum_di\n",
    "    lam = {0:1e-3, 1:1e-5} \n",
    "    clf = l.linearclf(loss_function, lam=lam, train_multiple=true)\n",
    "    clf.fit(x_train, y_train, x_sensitive_train, cons_params)\n",
    "    print_stats_and_plots(x_test, y_test, x_sensitive_test, clf)    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    print(\"\\n\\n\\n\\n== preferred treatment and preferred impact classifier ==\")\n",
    "    cons_params[\"cons_type\"] = 3\n",
    "    cons_params[\"s_val_to_cons_sum\"] = s_val_to_cons_sum_di\n",
    "    lam = {0:1e-3, 1:2e-3} \n",
    "    clf = l.linearclf(loss_function, lam=lam, train_multiple=true)\n",
    "    clf.fit(x_train, y_train, x_sensitive_train, cons_params)\n",
    "    print_stats_and_plots(x_test, y_test, x_sensitive_test, clf)    \n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    test_adult_data()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import urllib3\n",
    "import numpy as np\n",
    "from random import seed, shuffle\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "\n",
    "SEED = 1122\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\"\"\"\n",
    "    The adult dataset can be obtained from: http://archive.ics.uci.edu/ml/datasets/Adult\n",
    "    The code will look for the data files (adult.data, adult.test) in the present directory, if they are not found, it will download them from UCI archive.\n",
    "\"\"\"\n",
    "\n",
    "def check_data_file(fname):\n",
    "    files = os.listdir(\".\") # get the current directory listing\n",
    "    print(\"Looking for file '%s' in the current directory...\" % fname)\n",
    "\n",
    "    if fname not in files:\n",
    "        print (\"'%s' not found! Downloading from UCI Archive...\" % fname)\n",
    "        addr = \"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/%s\" % fname\n",
    "       # response = urllib2.urlopen(addr)\n",
    "       \n",
    "        http = urllib3.PoolManager()\n",
    "        response = http.request('GET', addr)\n",
    "        \n",
    "\n",
    "        data = response.read()\n",
    "\n",
    "        fileOut = open(fname, \"wb\")\n",
    "        fileOut.write(data)\n",
    "        fileOut.close()\n",
    "        print(\"'%s' download and saved locally..\" % fname)\n",
    "    else:\n",
    "        print (\"File found in current directory..\")\n",
    "    \n",
    "    print\n",
    "    return\n",
    "\n",
    "        \n",
    "def load_adult_data(load_data_size=None):\n",
    "\n",
    "    \"\"\"\n",
    "        if load_data_size is set to None (or if no argument is provided), then we load and return the whole data\n",
    "        if it is a number, say 10000, then we will return randomly selected 10K examples\n",
    "    \"\"\"\n",
    "\n",
    "    attrs = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country'] # all attributes\n",
    "    int_attrs = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week'] # attributes with integer values -- the rest are categorical\n",
    "    sensitive_attrs = ['sex'] # the fairness constraints will be used for this feature\n",
    "    attrs_to_ignore = ['race', 'sex' ,'fnlwgt'] # sex is the sensitive feature so we will not use it in classification, we will not consider fnlwght for classification since its computed externally and it highly predictive for the class (for details, see documentation of the adult data)\n",
    "    attrs_for_classification = set(attrs) - set(attrs_to_ignore)\n",
    "\n",
    "    # adult data comes in two different files, one for training and one for testing, however, we will combine data from both the files\n",
    "    data_files = [\"adult.data\", \"adult.test\"]\n",
    "\n",
    "\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    x_control = {}\n",
    "\n",
    "    attrs_to_vals = {} # will store the values for each attribute for all users\n",
    "    for k in attrs:\n",
    "        if k in sensitive_attrs:\n",
    "            x_control[k] = []\n",
    "        elif k in attrs_to_ignore:\n",
    "            pass\n",
    "        else:\n",
    "            attrs_to_vals[k] = []\n",
    "\n",
    "    for f in data_files:\n",
    "        check_data_file(f)\n",
    "\n",
    "        for line in open(f):\n",
    "            line = line.strip()\n",
    "            if line == \"\": continue # skip empty lines\n",
    "            line = line.split(\", \")\n",
    "            if len(line) != 15 or \"?\" in line: # if a line has missing attributes, ignore it\n",
    "                continue\n",
    "\n",
    "            class_label = line[-1]\n",
    "            if class_label in [\"<=50K.\", \"<=50K\"]:\n",
    "                class_label = -1\n",
    "            elif class_label in [\">50K.\", \">50K\"]:\n",
    "                class_label = +1\n",
    "            else:\n",
    "                raise Exception(\"Invalid class label value\")\n",
    "\n",
    "            y.append(class_label)\n",
    "\n",
    "\n",
    "            for i in range(0,len(line)-1):\n",
    "                attr_name = attrs[i]\n",
    "                attr_val = line[i]\n",
    "                # reducing dimensionality of some very sparse features\n",
    "                if attr_name == \"native_country\":\n",
    "                    if attr_val!=\"United-States\":\n",
    "                        attr_val = \"Non-United-Stated\"\n",
    "                elif attr_name == \"education\":\n",
    "                    if attr_val in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "                        attr_val = \"prim-middle-school\"\n",
    "                    elif attr_val in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "                        attr_val = \"high-school\"\n",
    "\n",
    "                if attr_name in sensitive_attrs:\n",
    "                    x_control[attr_name].append(attr_val)\n",
    "                elif attr_name in attrs_to_ignore:\n",
    "                    pass\n",
    "                else:\n",
    "                    attrs_to_vals[attr_name].append(attr_val)\n",
    "\n",
    "    def convert_attrs_to_ints(d): # discretize the string attributes\n",
    "        for attr_name, attr_vals in d.items():\n",
    "            if attr_name in int_attrs: continue\n",
    "            uniq_vals = sorted(list(set(attr_vals))) # get unique values\n",
    "\n",
    "            # compute integer codes for the unique values\n",
    "            val_dict = {}\n",
    "            for i in range(0,len(uniq_vals)):\n",
    "                val_dict[uniq_vals[i]] = i\n",
    "\n",
    "            # replace the values with their integer encoding\n",
    "            for i in range(0,len(attr_vals)):\n",
    "                attr_vals[i] = val_dict[attr_vals[i]]\n",
    "            d[attr_name] = attr_vals\n",
    "\n",
    "    \n",
    "    # convert the discrete values to their integer representations\n",
    "    convert_attrs_to_ints(x_control)\n",
    "    convert_attrs_to_ints(attrs_to_vals)\n",
    "\n",
    "\n",
    "    # if the integer vals are not binary, we need to get one-hot encoding for them\n",
    "\n",
    "    for attr_name in attrs_for_classification:\n",
    "\n",
    "        attr_vals = attrs_to_vals[attr_name]\n",
    "\n",
    "        if attr_name in int_attrs or attr_name == \"native_country\": # the way we encoded native country, its binary now so no need to apply one hot encoding on it\n",
    "            X.append(attr_vals)\n",
    "            \n",
    "        else:\n",
    "            lb = preprocessing.LabelBinarizer()\n",
    "            attr_vals = lb.fit_transform(attr_vals).T.tolist()\n",
    "            for bin_val_arr in attr_vals: # each binarized array of size n (n = num examples in the dataset)\n",
    "                X.append(bin_val_arr)\n",
    "            \n",
    "\n",
    "    # convert to numpy arrays for easy handline\n",
    "    X = np.array(X, dtype=float).T\n",
    "    y = np.array(y, dtype = float)\n",
    "    for k, v in x_control.items(): x_control[k] = np.array(v, dtype=float)\n",
    "        \n",
    "    # shuffle the data\n",
    "    perm = range(0,len(y)) # shuffle the data before creating each fold\n",
    "    shuffle(perm)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    for k in x_control.keys():\n",
    "        x_control[k] = x_control[k][perm]\n",
    "\n",
    "    # see if we need to subsample the data\n",
    "    if load_data_size is not None:\n",
    "        print (\"Loading only %d examples from the data\" % load_data_size)\n",
    "        X = X[:load_data_size]\n",
    "        y = y[:load_data_size]\n",
    "        for k in x_control.keys():\n",
    "            x_control[k] = x_control[k][:load_data_size]\n",
    "\n",
    "    x_sensitive = x_control[\"sex\"]\n",
    "    # np.savez(\"adult\", X, y, x_sensitive)\n",
    "    return X, y, x_sensitive\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import traceback\n",
    "\n",
    "sys.path.insert(0, \"/home/mzafar/libraries/dccp\") # we will store the latest version of DCCP here.\n",
    "from cvxpy import *\n",
    "import dccp\n",
    "from dccp.problem import is_dccp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LinearClf():\n",
    "\n",
    "\n",
    "    def __init__(self, loss_function, lam=None, train_multiple=False, random_state=1234):\n",
    "\n",
    "        \"\"\"\n",
    "            Model can be logistic regression or linear SVM in primal form\n",
    "\n",
    "            We will define the lam parameter once and for all for a single object.\n",
    "            For cross validating multiple models, we will write a function for doing that.\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        \"\"\" Setting default lam val and Making sure that lam is provided for each group \"\"\"\n",
    "        if lam is None:\n",
    "            if train_multiple == False: \n",
    "                lam = 0.0\n",
    "            else: \n",
    "                lam = {0:0.0, 1:0.0}\n",
    "                \n",
    "        else:\n",
    "            if train_multiple == True:\n",
    "                assert(isinstance(lam, dict))\n",
    "        \n",
    "\n",
    "        self.loss_function = loss_function\n",
    "        self.lam = lam\n",
    "        self.train_multiple = train_multiple\n",
    "\n",
    "\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "\n",
    "    def fit(self, X, y, x_sensitive, cons_params=None):\n",
    "\n",
    "        \"\"\"\n",
    "            X: n x d array\n",
    "            y: n length vector\n",
    "            x_sensitive: n length vector\n",
    "\n",
    "\n",
    "            cons_params will be a dictionary\n",
    "            cons_params[\"tau\"], cons_params[\"mu\"] and cons_params[\"EPS\"] are the solver related parameters. Check DCCP documentation for details\n",
    "            cons_params[\"cons_type\"] specified which type of constraint to apply\n",
    "                - cons_type = -1: No constraint\n",
    "                - cons_type = 0: Parity\n",
    "                - cons_type = 1: Preferred impact\n",
    "                - cons_type = 2: Preferred treatment\n",
    "                - cons_type = 3: Preferred both\n",
    "\n",
    "            cons_params[\"s_val_to_cons_sum\"]: The ramp approximation -- only needed for cons_type 1 and 3\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            Setting up the initial variables\n",
    "        \"\"\"\n",
    "\n",
    "        max_iters = 100 # for CVXPY convex solver\n",
    "        max_iter_dccp = 50  # for the dccp. notice that DCCP hauristic runs the convex program iteratively until arriving at the solution\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \"\"\" \n",
    "            Construct the optimization variables \n",
    "        \"\"\"\n",
    "\n",
    "        constraints = []\n",
    "\n",
    "        np.random.seed(1234) # set the seed before initializing the values of w\n",
    "        if self.train_multiple == True:\n",
    "            w = {}\n",
    "            for k in set(x_sensitive):\n",
    "                w[k] = Variable(X.shape[1]) # this is the weight vector\n",
    "                w[k].value = np.random.rand(X.shape[1]) # initialize the value of w -- uniform distribution over [0,1]\n",
    "        else:\n",
    "            w = Variable(X.shape[1]) # this is the weight vector\n",
    "            w.value = np.random.rand(X.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\" \n",
    "            Solve the optimization problem here \n",
    "        \"\"\"\n",
    "\n",
    "        num_all = X.shape[0] # set of all data points\n",
    "\n",
    "        if self.train_multiple == True:\n",
    "            \n",
    "            obj = 0\n",
    "            for k in set(x_sensitive):\n",
    "                idx = x_sensitive==k\n",
    "                X_k = X[idx]\n",
    "                y_k = y[idx]\n",
    "                obj += sum_squares(w[k][1:]) * self.lam[k] # first term in w is the intercept, so no need to regularize that\n",
    "\n",
    "                if self.loss_function == \"logreg\":\n",
    "                    obj += sum(  logistic( multiply(-y_k, X_k*w[k]) )  ) / num_all # notice that we are dividing by the length of the whole dataset, and not just of this sensitive group. this way, the group that has more people contributes more to the loss\n",
    "                    \n",
    "                elif self.loss_function == \"svm_linear\":\n",
    "                    obj += sum ( maximum (0, 1 - multiply ( y_k,  X_k*w[k])) ) / num_all\n",
    "                    \n",
    "                else:\n",
    "                    raise Exception(\"Invalid loss function\")\n",
    "\n",
    "        else:\n",
    "\n",
    "            obj = 0\n",
    "            obj += sum_squares(w[1:]) * self.lam # regularizer -- first term in w is the intercept, so no need to regularize that\n",
    "            if self.loss_function == \"logreg\":\n",
    "                obj += sum(  logistic( multiply(-y, X*w) )  ) / num_all\n",
    "            elif self.loss_function == \"svm_linear\":\n",
    "                obj += sum ( maximum(0, 1 - multiply ( y,  X*w)) ) / num_all\n",
    "            else:\n",
    "                raise Exception(\"Invalid loss function\")\n",
    "\n",
    "\n",
    "        \"\"\" \n",
    "            Constraints here \n",
    "        \"\"\"\n",
    "        if cons_params is not None:\n",
    "            \n",
    "            cons_type = cons_params[\"cons_type\"]\n",
    "            if cons_type == -1: # no constraint\n",
    "                pass\n",
    "            elif cons_type == 0: # disp imp with single boundary\n",
    "                cov_thresh = np.abs(0.) # perfect fairness -- see our AISTATS paper for details\n",
    "                constraints += self.get_di_cons_single_boundary(X, y, x_sensitive, w, cov_thresh)\n",
    "            elif cons_type in [1,3]: # preferred imp, pref imp + pref treat\n",
    "                constraints += self.get_preferred_cons(X, x_sensitive, w, cons_type, cons_params[\"s_val_to_cons_sum\"])\n",
    "            elif cons_type == 2:\n",
    "                constraints += self.get_preferred_cons(X, x_sensitive, w, cons_type)\n",
    "            else:\n",
    "                raise Exception(\"Wrong constraint type\")\n",
    "\n",
    "        \n",
    "\n",
    "        prob = Problem(Minimize(obj), constraints)\n",
    "        # print \"Problem is DCP (disciplined convex program):\", prob.is_dcp()\n",
    "        # print \"Problem is DCCP (disciplined convex-concave program):\", is_dccp(prob)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            Solving the problem\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "\n",
    "            tau, mu, EPS = 0.5, 1.2, 1e-4 # default dccp parameters, need to be varied per dataset\n",
    "            if cons_params is not None: # in case we passed these parameters as a part of dccp constraints\n",
    "                if cons_params.get(\"tau\") is not None: tau = cons_params[\"tau\"]\n",
    "                if cons_params.get(\"mu\") is not None: mu = cons_params[\"mu\"]\n",
    "                if cons_params.get(\"EPS\") is not None: EPS = cons_params[\"EPS\"]\n",
    "\n",
    "            prob.solve(method='dccp', tau=tau, mu=mu, tau_max=1e10,\n",
    "                verbose=False, \n",
    "                feastol=EPS, abstol=EPS, reltol=EPS,feastol_inacc=EPS, abstol_inacc=EPS, reltol_inacc=EPS,\n",
    "                max_iters=max_iters, max_iter=max_iter_dccp)\n",
    "\n",
    "            \n",
    "            # print \"Optimization done, problem status:\", prob.status\n",
    "            assert(prob.status == \"Converged\" or prob.status == \"optimal\")\n",
    "            \n",
    "\n",
    "            # check that the fairness constraint is satisfied\n",
    "            for f_c in constraints:\n",
    "                try:\n",
    "                    assert(f_c.value == True)\n",
    "                except:\n",
    "                    print (\"Assertion failed. Fairness constraints not satisfied.\")\n",
    "                    print (traceback.print_exc())\n",
    "                    sys.stdout.flush()\n",
    "                    return\n",
    "                    # sys.exit(1)\n",
    "\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            sys.stdout.flush()\n",
    "            # sys.exit(1)\n",
    "            return\n",
    "\n",
    "\n",
    "        \"\"\" \n",
    "            Storing the results \n",
    "        \"\"\"\n",
    "\n",
    "        if self.train_multiple == True:\n",
    "            self.w = {}\n",
    "            for k in set(x_sensitive):\n",
    "                self.w[k] = np.array(w[k].value).flatten() # flatten converts it to a 1d array\n",
    "        else:\n",
    "            self.w = np.array(w.value).flatten() # flatten converts it to a 1d array\n",
    "        \n",
    "        \n",
    "        return self.w\n",
    "\n",
    "\n",
    "    def decision_function(self, X, k=None):\n",
    "        \"\"\" Predicts labels for all samples in X\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape = [n_samples, n_features]\n",
    "            The input samples.\n",
    "        Returns\n",
    "\n",
    "        k: the group whose decision boundary should be used.\n",
    "        k = None means that we trained one clf for the whole dataset\n",
    "        -------\n",
    "        y : array of shape = [n_samples]\n",
    "        \"\"\"\n",
    "        \n",
    "        if k is None:\n",
    "            ret = np.dot(X, self.w)\n",
    "        else:\n",
    "            ret = np.dot(X, self.w[k])\n",
    "        \n",
    "        return ret\n",
    "\n",
    "\n",
    "    def get_distance_boundary(self, X, x_sensitive):\n",
    "\n",
    "        \"\"\"\n",
    "            returns two vals\n",
    "            \n",
    "            distance_boundary_arr: \n",
    "                arr with distance to boundary, each groups owns w is applied on it\n",
    "            distance_boundary_dict:\n",
    "                dict of the form s_attr_group (points from group 0/1) -> w_group (boundary of group 0/1) -> distances for this group with this boundary\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        distances_boundary_dict = {} # s_attr_group (0/1) -> w_group (0/1) -> distances\n",
    "        \n",
    "\n",
    "        if not isinstance(self.w, dict): # we have one model for the whole data\n",
    "            distance_boundary_arr = self.decision_function(X)\n",
    "\n",
    "            for attr in set(x_sensitive): # there is only one boundary, so the results with this_group and other_group boundaries are the same\n",
    "\n",
    "                distances_boundary_dict[attr] = {}\n",
    "                idx = x_sensitive == attr\n",
    "\n",
    "                for k in set(x_sensitive):\n",
    "                    distances_boundary_dict[attr][k] = self.decision_function(X[idx]) # apply same decision function for all the sensitive attrs because same w is trained for everyone\n",
    "\n",
    "            \n",
    "        else: # w is a dict\n",
    "            distance_boundary_arr = np.zeros(X.shape[0])\n",
    "\n",
    "\n",
    "            for attr in set(x_sensitive):\n",
    "\n",
    "                distances_boundary_dict[attr] = {}\n",
    "                idx = x_sensitive == attr\n",
    "                X_g = X[idx]\n",
    "\n",
    "                distance_boundary_arr[idx] = self.decision_function(X_g, attr) # each group gets decision with their own boundary\n",
    "\n",
    "                for k in self.w.keys(): \n",
    "                    distances_boundary_dict[attr][k] = self.decision_function(X_g, k) # each group gets a decision with both boundaries\n",
    "\n",
    "        return distance_boundary_arr, distances_boundary_dict\n",
    "\n",
    "\n",
    "    def get_di_cons_single_boundary(self, X, y, x_sensitive, w, cov_thresh):\n",
    "\n",
    "        \"\"\"\n",
    "        Parity impact constraint\n",
    "        \"\"\"\n",
    "\n",
    "        assert(self.train_multiple == False) # di cons is just for a single boundary clf\n",
    "        assert(cov_thresh >= 0) # covariance thresh has to be a small positive number\n",
    "\n",
    "        constraints = []\n",
    "        z_i_z_bar = x_sensitive - np.mean(x_sensitive)\n",
    "\n",
    "        fx = X*w\n",
    "        prod = sum( multiply(z_i_z_bar, fx) ) / X.shape[0]\n",
    "        \n",
    "\n",
    "        constraints.append( prod <=  cov_thresh )\n",
    "        constraints.append( prod >= -cov_thresh )\n",
    "\n",
    "        return constraints\n",
    "\n",
    "\n",
    "    def get_preferred_cons(self, X, x_sensitive, w, cons_type, s_val_to_cons_sum=None):\n",
    "\n",
    "        \"\"\"\n",
    "            No need to pass s_val_to_cons_sum for preferred treatment (envy free) constraints\n",
    "\n",
    "            For details on cons_type, see the documentation of fit() function\n",
    "        \"\"\"\n",
    "\n",
    "        constraints = []\n",
    "\n",
    "        if cons_type in [1,2,3]: # 1 - pref imp, 2 - EF, 3 - pref imp & EF\n",
    "\n",
    "            prod_dict = {0:{}, 1:{}} # s_attr_group (0/1) -> w_group (0/1) -> val\n",
    "            for val in set(x_sensitive):\n",
    "                idx = x_sensitive == val\n",
    "                X_g = X[idx]\n",
    "                num_g = X_g.shape[0]\n",
    "\n",
    "                for k in w.keys(): # get the distance with each group's w\n",
    "                    prod_dict[val][k] = sum(  maximum(0, X_g*w[k])   ) / num_g\n",
    "\n",
    "                    \n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Invalid constraint type\")\n",
    "\n",
    "\n",
    "        if cons_type == 1 or cons_type == 3: # 1 for preferred impact -- 3 for preferred impact and envy free\n",
    "            \n",
    "            constraints.append( prod_dict[0][0] >= s_val_to_cons_sum[0][0] )\n",
    "            constraints.append( prod_dict[1][1] >= s_val_to_cons_sum[1][1] )\n",
    "           \n",
    "\n",
    "\n",
    "        if cons_type == 2 or cons_type == 3: # envy free\n",
    "            constraints.append( prod_dict[0][0] >= prod_dict[0][1] )\n",
    "            constraints.append( prod_dict[1][1] >= prod_dict[1][0] )\n",
    "                \n",
    "        return constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler # normalize data with 0 and 1 as min/max absolute vals\n",
    "import scipy\n",
    "from multiprocessing import Pool, Process, Queue\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import traceback\n",
    "\n",
    "\n",
    "def get_acc_all(dist_arr, y):\n",
    "    \"\"\"\n",
    "    Get accuracy for all data points\n",
    "    Each group gets the prediction based on their own boundary\n",
    "    \"\"\"\n",
    "    return np.sum(sign_bin_clf(dist_arr) == y) / y.shape[0]\n",
    "\n",
    "def get_clf_stats(dist_arr, dist_dict, y, x_sensitive, print_stats=False):\n",
    "\n",
    "\n",
    "    # compute the class labels\n",
    "    all_class_labels_assigned = sign_bin_clf(dist_arr)\n",
    "    \n",
    "    \n",
    "    s_val_to_cons_sum = {}\n",
    "        \n",
    "\n",
    "    acc = get_acc_all(dist_arr,y)\n",
    "\n",
    "    if print_stats:\n",
    "        print (\"\\n\\n\\nAccuracy: %0.3f\\n\" %acc)\n",
    "\n",
    "        \n",
    "    acc_stats = get_acc_stats(dist_dict, y, x_sensitive, print_stats)\n",
    "    s_val_to_cons_sum = get_sensitive_attr_cov(dist_dict) \n",
    "\n",
    "    return acc, s_val_to_cons_sum, acc_stats\n",
    "\n",
    "\n",
    "def get_fp_fn_tp_tn(y_true, y_pred):\n",
    "    \n",
    "\n",
    "    def check_labels_bin(arr):\n",
    "\n",
    "        \"\"\" Can only have -1 and 1\"\"\"\n",
    "        try:\n",
    "            if len(set(arr)) == 1:\n",
    "                elem = list(set(arr))[0]\n",
    "                assert(elem==1 or elem==-1)\n",
    "            else:\n",
    "                assert(len(set(arr)) == 2)\n",
    "                assert( sorted(list(set(arr)))[0] == -1 and sorted(list(set(arr)))[1] == 1 )\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            raise Exception(\"Class labels (both true and predicted) can only take values -1 and 1... Exiting...\")\n",
    "            \n",
    "    \n",
    "    check_labels_bin(y_true)\n",
    "    check_labels_bin(y_pred)\n",
    "\n",
    "\n",
    "    \n",
    "    acc = float(sum(y_true==y_pred)) / len(y_true)\n",
    "\n",
    "    fp = sum(np.logical_and(y_true == -1.0, y_pred == +1.0)) # something which is -ve but is misclassified as +ve\n",
    "    fn = sum(np.logical_and(y_true == +1.0, y_pred == -1.0)) # something which is +ve but is misclassified as -ve\n",
    "    tp = sum(np.logical_and(y_true == +1.0, y_pred == +1.0)) # something which is +ve AND is correctly classified as +ve\n",
    "    tn = sum(np.logical_and(y_true == -1.0, y_pred == -1.0)) # something which is -ve AND is correctly classified as -ve\n",
    "\n",
    "    fpr = float(fp) / float(fp + tn)\n",
    "    fnr = float(fn) / float(fn + tp)\n",
    "    tpr = float(tp) / float(tp + fn)\n",
    "    tnr = float(tn) / float(tn + fp)\n",
    "    frac_pos = (tp + fp) / (tp + tn + fp + fn) # fraction classified as positive\n",
    "\n",
    "    out_dict = {\"fpr\": fpr, \"fnr\": fnr, \"acc\": acc, \"frac_pos\": frac_pos}\n",
    "\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_acc_stats(dist_dict, y, x_sensitive, verbose = False):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    output dict form: s_attr_group (0/1) -> w_group (0/1) -> fpr/fnr/acc/frac_pos\n",
    "    \"\"\"\n",
    "\n",
    "    acc_stats = {}\n",
    "\n",
    "    try:            \n",
    "        assert(len(set(x_sensitive)) == 2)        \n",
    "    except:\n",
    "        raise Exception(\"Fill the constraint code for categorical sensitive features... Exiting...\")\n",
    "\n",
    "    try:\n",
    "        assert( sorted(list(set(x_sensitive)))[0] == 0 and sorted(list(set(x_sensitive)))[1] == 1 )\n",
    "    except:\n",
    "        raise Exception(\"Sensitive feature can only take values 0 and 1... Exiting...\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    if verbose == True:\n",
    "        print (\"||  s  ||   frac_pos  ||\")\n",
    "\n",
    "\n",
    "    for s_val in set(x_sensitive):\n",
    "        idx = x_sensitive == s_val\n",
    "        other_val = np.abs(1-s_val) \n",
    "        acc_stats[s_val] = {}\n",
    "\n",
    "\n",
    "        y_true_local = y[idx]\n",
    "        y_pred_local = sign_bin_clf(dist_dict[s_val][s_val]) # predictions with this classifier\n",
    "        y_pred_local_other = sign_bin_clf(dist_dict[s_val][other_val])  # predictions with other group's classifier\n",
    "\n",
    "        \n",
    "        assert(y_true_local.shape[0] == y_pred_local.shape[0] and y_true_local.shape[0] == y_pred_local_other.shape[0])\n",
    "\n",
    "\n",
    "        acc_stats[s_val][s_val] = get_fp_fn_tp_tn(y_true_local, y_pred_local)\n",
    "        acc_stats[s_val][other_val] = get_fp_fn_tp_tn(y_true_local, y_pred_local_other)\n",
    "\n",
    "\n",
    "        if verbose == True:\n",
    "            if isinstance(s_val, float): # print the int value of the sensitive attr val\n",
    "                s_val = int(s_val)\n",
    "\n",
    "\n",
    "            print (\"||  %s  || %0.2f (%0.2f) ||\" % (s_val, acc_stats[s_val][s_val][\"frac_pos\"], acc_stats[s_val][other_val][\"frac_pos\"]))\n",
    "                \n",
    "\n",
    "\n",
    "    return acc_stats            \n",
    "\n",
    "\n",
    "\n",
    "def sign_bin_clf(arr):\n",
    "    \"\"\"\n",
    "        prediction for a linear classifier. np.sign gives 0 for sing(0), we want 1\n",
    "\n",
    "        if arr[i] >= 0, arr[i] = +1\n",
    "        else arr[i] = -1\n",
    "        \n",
    "    \"\"\"\n",
    "    arr = np.sign(arr)\n",
    "    arr[arr==0] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_sensitive_attr_cov(dist_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    computes the ramp function for each group to estimate the acceptance rate\n",
    "    \"\"\"    \n",
    "\n",
    "    s_val_to_cons_sum = {0:{}, 1:{}} # s_attr_group (0/1) -> w_group (0/1) -> ramp approx\n",
    "    \n",
    "    for s_val in dist_dict.keys():\n",
    "        for w_group in dist_dict[s_val].keys():\n",
    "            fx = dist_dict[s_val][w_group]            \n",
    "            s_val_to_cons_sum[s_val][w_group] = np.sum( np.maximum(0, fx) ) / fx.shape[0]\n",
    "            \n",
    "\n",
    "    return s_val_to_cons_sum\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_intercept(x):\n",
    "\n",
    "    \"\"\" Add intercept to the data before linear classification \"\"\"\n",
    "    m,n = x.shape\n",
    "    intercept = np.ones(m).reshape(m, 1) # the constant b\n",
    "    return np.concatenate((intercept, x), axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "def scale_data(x_train, x_test):\n",
    "\n",
    "    \"\"\"\n",
    "        We only scale the continuous features. No need to scale binary features\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    idx_binary = [] # columns with boolean values\n",
    "    for k in range(x_train.shape[1]):\n",
    "        idx_binary.append( np.array_equal(x_train[:,k], x_train[:,k].astype(bool)) ) # checking if a column is binary\n",
    "    idx_cont = np.logical_not(idx_binary)\n",
    "\n",
    "\n",
    "    sc = MaxAbsScaler()\n",
    "    sc.fit(x_train[:, idx_cont])\n",
    "    \n",
    "    x_train[:, idx_cont] = sc.transform(x_train[:, idx_cont])\n",
    "    x_test[:, idx_cont] = sc.transform(x_test[:, idx_cont])\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e4a301129b0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdccp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdccp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_dccp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mSEED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1122334455\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os,sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "from random import seed, shuffle\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from cvxpy import *\n",
    "import dccp\n",
    "from dccp.problem import is_dccp\n",
    "import utils as ut\n",
    "\n",
    "SEED = 1122334455\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "def train_model_disp_mist(x, y, x_control, loss_function, EPS, cons_params=None):\n",
    "\n",
    "    # cons_type, sensitive_attrs_to_cov_thresh, take_initial_sol, gamma, tau, mu, EPS, cons_type\n",
    "    \"\"\"\n",
    "\n",
    "    Function that trains the model subject to various fairness constraints.\n",
    "    If no constraints are given, then simply trains an unaltered classifier.\n",
    "    Example usage in: \"disparate_mistreatment/synthetic_data_demo/decision_boundary_demo.py\"\n",
    "\n",
    "    ----\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "    X: (n) x (d+1) numpy array -- n = number of examples, d = number of features, one feature is the intercept\n",
    "    y: 1-d numpy array (n entries)\n",
    "    x_control: dictionary of the type {\"s\": [...]}, key \"s\" is the sensitive feature name, and the value is a 1-d list with n elements holding the sensitive feature values\n",
    "    loss_function: the loss function that we want to optimize -- for now we have implementation of logistic loss, but other functions like hinge loss can also be added\n",
    "    EPS: stopping criteria for the convex solver. check the CVXPY documentation for details. default for CVXPY is 1e-6\n",
    "\n",
    "    cons_params: is None when we do not want to apply any constraints\n",
    "    otherwise: cons_params is a dict with keys as follows:\n",
    "        - cons_type: \n",
    "            - 0 for all misclassifications \n",
    "            - 1 for FPR\n",
    "            - 2 for FNR\n",
    "            - 4 for both FPR and FNR\n",
    "        - tau: DCCP parameter, controls how much weight to put on the constraints, if the constraints are not satisfied, then increase tau -- default is DCCP val 0.005\n",
    "        - mu: DCCP parameter, controls the multiplicative factor by which the tau increases in each DCCP iteration -- default is the DCCP val 1.2\n",
    "        - take_initial_sol: whether the starting point for DCCP should be the solution for the original (unconstrained) classifier -- default value is True\n",
    "        - sensitive_attrs_to_cov_thresh: covariance threshold for each cons_type, eg, key 1 contains the FPR covariance\n",
    "    ----\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "    w: the learned weight vector for the classifier\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    max_iters = 100 # for the convex program\n",
    "    max_iter_dccp = 50  # for the dccp algo\n",
    "\n",
    "    \n",
    "    num_points, num_features = x.shape\n",
    "    w = Variable(num_features) # this is the weight vector\n",
    "\n",
    "    # initialize a random value of w\n",
    "    np.random.seed(112233)\n",
    "    w.value = np.random.rand(x.shape[1])\n",
    "\n",
    "    if cons_params is None: # just train a simple classifier, no fairness constraints\n",
    "        constraints = []\n",
    "    else:\n",
    "        constraints = get_constraint_list_cov(x, y, x_control, cons_params[\"sensitive_attrs_to_cov_thresh\"], cons_params[\"cons_type\"], w)\n",
    "\n",
    "\n",
    "    if loss_function == \"logreg\":\n",
    "        # constructing the logistic loss problem\n",
    "        loss = sum_entries(  logistic( mul_elemwise(-y, x*w) )  ) / num_points # we are converting y to a diagonal matrix for consistent\n",
    "\n",
    "\n",
    "    # sometimes, its a good idea to give a starting point to the constrained solver\n",
    "    # this starting point for us is the solution to the unconstrained optimization problem\n",
    "    # another option of starting point could be any feasible solution\n",
    "    if cons_params is not None:\n",
    "        if cons_params.get(\"take_initial_sol\") is None: # true by default\n",
    "            take_initial_sol = True\n",
    "        elif cons_params[\"take_initial_sol\"] == False:\n",
    "            take_initial_sol = False\n",
    "\n",
    "        if take_initial_sol == True: # get the initial solution\n",
    "            p = Problem(Minimize(loss), [])\n",
    "            p.solve()\n",
    "\n",
    "\n",
    "    # construct the cvxpy problem\n",
    "    prob = Problem(Minimize(loss), constraints)\n",
    "\n",
    "    # print \"\\n\\n\"\n",
    "    # print \"Problem is DCP (disciplined convex program):\", prob.is_dcp()\n",
    "    # print \"Problem is DCCP (disciplined convex-concave program):\", is_dccp(prob)\n",
    "\n",
    "    try:\n",
    "\n",
    "        tau, mu = 0.005, 1.2 # default dccp parameters, need to be varied per dataset\n",
    "        if cons_params is not None: # in case we passed these parameters as a part of dccp constraints\n",
    "            if cons_params.get(\"tau\") is not None: tau = cons_params[\"tau\"]\n",
    "            if cons_params.get(\"mu\") is not None: mu = cons_params[\"mu\"]\n",
    "\n",
    "        prob.solve(method='dccp', tau=tau, mu=mu, tau_max=1e10,\n",
    "            solver=ECOS, verbose=False, \n",
    "            feastol=EPS, abstol=EPS, reltol=EPS,feastol_inacc=EPS, abstol_inacc=EPS, reltol_inacc=EPS,\n",
    "            max_iters=max_iters, max_iter=max_iter_dccp)\n",
    "\n",
    "        \n",
    "        assert(prob.status == \"Converged\" or prob.status == \"optimal\")\n",
    "        # print \"Optimization done, problem status:\", prob.status\n",
    "\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    # check that the fairness constraint is satisfied\n",
    "    for f_c in constraints:\n",
    "        assert(f_c.value == True) # can comment this out if the solver fails too often, but make sure that the constraints are satisfied empirically. alternatively, consider increasing tau parameter\n",
    "        pass\n",
    "        \n",
    "\n",
    "    w = np.array(w.value).flatten() # flatten converts it to a 1d array\n",
    "\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def get_clf_stats(w, x_train, y_train, x_control_train, x_test, y_test, x_control_test, sensitive_attrs):\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    assert(len(sensitive_attrs) == 1) # ensure that we have just one sensitive attribute\n",
    "    s_attr = sensitive_attrs[0] # for now, lets compute the accuracy for just one sensitive attr\n",
    "\n",
    "\n",
    "    # compute distance from boundary\n",
    "    distances_boundary_train = get_distance_boundary(w, x_train, x_control_train[s_attr])\n",
    "    distances_boundary_test = get_distance_boundary(w, x_test, x_control_test[s_attr])\n",
    "\n",
    "    # compute the class labels\n",
    "    all_class_labels_assigned_train = np.sign(distances_boundary_train)\n",
    "    all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "\n",
    "\n",
    "    train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(None, x_train, y_train, x_test, y_test, all_class_labels_assigned_train, all_class_labels_assigned_test)\n",
    "\n",
    "    \n",
    "    cov_all_train = {}\n",
    "    cov_all_test = {}\n",
    "    for s_attr in sensitive_attrs:\n",
    "        \n",
    "        \n",
    "        print_stats = False # we arent printing the stats for the train set to avoid clutter\n",
    "\n",
    "        # uncomment these lines to print stats for the train fold\n",
    "        # print \"*** Train ***\"\n",
    "        # print \"Accuracy: %0.3f\" % (train_score)\n",
    "        # print_stats = True\n",
    "        s_attr_to_fp_fn_train = get_fpr_fnr_sensitive_features(y_train, all_class_labels_assigned_train, x_control_train, sensitive_attrs, print_stats)\n",
    "        cov_all_train[s_attr] = get_sensitive_attr_constraint_fpr_fnr_cov(None, x_train, y_train, distances_boundary_train, x_control_train[s_attr]) \n",
    "        \n",
    "\n",
    "        print( \"\\n\")\n",
    "        print (\"Accuracy: %0.3f\" % (test_score))\n",
    "        print_stats = True # only print stats for the test fold\n",
    "        s_attr_to_fp_fn_test = get_fpr_fnr_sensitive_features(y_test, all_class_labels_assigned_test, x_control_test, sensitive_attrs, print_stats)\n",
    "        cov_all_test[s_attr] = get_sensitive_attr_constraint_fpr_fnr_cov(None, x_test, y_test, distances_boundary_test, x_control_test[s_attr]) \n",
    "        print (\"\\n\")\n",
    "\n",
    "    return train_score, test_score, cov_all_train, cov_all_test, s_attr_to_fp_fn_train, s_attr_to_fp_fn_test\n",
    "\n",
    "def get_distance_boundary(w, x, s_attr_arr):\n",
    "\n",
    "    \"\"\"\n",
    "        if we have boundaries per group, then use those separate boundaries for each sensitive group\n",
    "        else, use the same weight vector for everything\n",
    "    \"\"\"\n",
    "\n",
    "    distances_boundary = np.zeros(x.shape[0])\n",
    "    if isinstance(w, dict): # if we have separate weight vectors per group\n",
    "        for k in w.keys(): # for each w corresponding to each sensitive group\n",
    "            d = np.dot(x, w[k])\n",
    "            distances_boundary[s_attr_arr == k] = d[s_attr_arr == k] # set this distance only for people with this sensitive attr val\n",
    "    else: # we just learn one w for everyone else\n",
    "        distances_boundary = np.dot(x, w)\n",
    "    return distances_boundary\n",
    "\n",
    "\n",
    "def get_constraint_list_cov(x_train, y_train, x_control_train, sensitive_attrs_to_cov_thresh, cons_type, w):\n",
    "\n",
    "    \"\"\"\n",
    "    get the list of constraints to be fed to the minimizer\n",
    "\n",
    "    cons_type == 0: means the whole combined misclassification constraint (without FNR or FPR)\n",
    "    cons_type == 1: FPR constraint\n",
    "    cons_type == 2: FNR constraint\n",
    "    cons_type == 4: both FPR as well as FNR constraints\n",
    "\n",
    "    sensitive_attrs_to_cov_thresh: is a dict like {s: {cov_type: val}}\n",
    "    s is the sensitive attr\n",
    "    cov_type is the covariance type. contains the covariance for all misclassifications, FPR and for FNR etc\n",
    "    \"\"\"\n",
    "\n",
    "    constraints = []\n",
    "    for attr in sensitive_attrs_to_cov_thresh.keys():\n",
    "\n",
    "        attr_arr = x_control_train[attr]\n",
    "        attr_arr_transformed, index_dict = ut.get_one_hot_encoding(attr_arr)\n",
    "                \n",
    "        if index_dict is None: # binary attribute, in this case, the attr_arr_transformed is the same as the attr_arr\n",
    "\n",
    "            s_val_to_total = {ct:{} for ct in [0,1,2]} # constrain type -> sens_attr_val -> total number\n",
    "            s_val_to_avg = {ct:{} for ct in [0,1,2]}\n",
    "            cons_sum_dict = {ct:{} for ct in [0,1,2]} # sum of entities (females and males) in constraints are stored here\n",
    "\n",
    "            for v in set(attr_arr):\n",
    "                s_val_to_total[0][v] = sum(x_control_train[attr] == v)\n",
    "                s_val_to_total[1][v] = sum(np.logical_and(x_control_train[attr] == v, y_train == -1)) # FPR constraint so we only consider the ground truth negative dataset for computing the covariance\n",
    "                s_val_to_total[2][v] = sum(np.logical_and(x_control_train[attr] == v, y_train == +1))\n",
    "\n",
    "\n",
    "            for ct in [0,1,2]:\n",
    "                s_val_to_avg[ct][0] = s_val_to_total[ct][1] / float(s_val_to_total[ct][0] + s_val_to_total[ct][1]) # N1/N in our formulation, differs from one constraint type to another\n",
    "                s_val_to_avg[ct][1] = 1.0 - s_val_to_avg[ct][0] # N0/N\n",
    "\n",
    "            \n",
    "            for v in set(attr_arr):\n",
    "\n",
    "                idx = x_control_train[attr] == v                \n",
    "\n",
    "\n",
    "                #################################################################\n",
    "                # #DCCP constraints\n",
    "                dist_bound_prod = mul_elemwise(y_train[idx], x_train[idx] * w) # y.f(x)\n",
    "                \n",
    "                cons_sum_dict[0][v] = sum_entries( min_elemwise(0, dist_bound_prod) ) * (s_val_to_avg[0][v] / len(x_train)) # avg misclassification distance from boundary\n",
    "                cons_sum_dict[1][v] = sum_entries( min_elemwise(0, mul_elemwise( (1 - y_train[idx])/2.0, dist_bound_prod) ) ) * (s_val_to_avg[1][v] / sum(y_train == -1)) # avg false positive distance from boundary (only operates on the ground truth neg dataset)\n",
    "                cons_sum_dict[2][v] = sum_entries( min_elemwise(0, mul_elemwise( (1 + y_train[idx])/2.0, dist_bound_prod) ) ) * (s_val_to_avg[2][v] / sum(y_train == +1)) # avg false negative distance from boundary\n",
    "                #################################################################\n",
    "\n",
    "                \n",
    "            if cons_type == 4:\n",
    "                cts = [1,2]\n",
    "            elif cons_type in [0,1,2]:\n",
    "                cts = [cons_type]\n",
    "            \n",
    "            else:\n",
    "                raise Exception(\"Invalid constraint type\")\n",
    "\n",
    "\n",
    "            #################################################################\n",
    "            #DCCP constraints\n",
    "            for ct in cts:\n",
    "                thresh = abs(sensitive_attrs_to_cov_thresh[attr][ct][1] - sensitive_attrs_to_cov_thresh[attr][ct][0])\n",
    "                constraints.append( cons_sum_dict[ct][1] <= cons_sum_dict[ct][0]  + thresh )\n",
    "                constraints.append( cons_sum_dict[ct][1] >= cons_sum_dict[ct][0]  - thresh )\n",
    "\n",
    "            #################################################################\n",
    "\n",
    "\n",
    "            \n",
    "        else: # otherwise, its a categorical attribute, so we need to set the cov thresh for each value separately\n",
    "            # need to fill up this part\n",
    "            raise Exception(\"Fill the constraint code for categorical sensitive features... Exiting...\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "\n",
    "    return constraints\n",
    "\n",
    "\n",
    "def get_fpr_fnr_sensitive_features(y_true, y_pred, x_control, sensitive_attrs, verbose = False):\n",
    "\n",
    "\n",
    "\n",
    "    # we will make some changes to x_control in this function, so make a copy in order to preserve the origianl referenced object\n",
    "    x_control_internal = deepcopy(x_control)\n",
    "\n",
    "    s_attr_to_fp_fn = {}\n",
    "    \n",
    "    for s in sensitive_attrs:\n",
    "        s_attr_to_fp_fn[s] = {}\n",
    "        s_attr_vals = x_control_internal[s]\n",
    "        if verbose == True:\n",
    "            print (\"||  s  || FPR. || FNR. ||\")\n",
    "        for s_val in sorted(list(set(s_attr_vals))):\n",
    "            s_attr_to_fp_fn[s][s_val] = {}\n",
    "            y_true_local = y_true[s_attr_vals==s_val]\n",
    "            y_pred_local = y_pred[s_attr_vals==s_val]\n",
    "\n",
    "            \n",
    "\n",
    "            acc = float(sum(y_true_local==y_pred_local)) / len(y_true_local)\n",
    "\n",
    "            fp = sum(np.logical_and(y_true_local == -1.0, y_pred_local == +1.0)) # something which is -ve but is misclassified as +ve\n",
    "            fn = sum(np.logical_and(y_true_local == +1.0, y_pred_local == -1.0)) # something which is +ve but is misclassified as -ve\n",
    "            tp = sum(np.logical_and(y_true_local == +1.0, y_pred_local == +1.0)) # something which is +ve AND is correctly classified as +ve\n",
    "            tn = sum(np.logical_and(y_true_local == -1.0, y_pred_local == -1.0)) # something which is -ve AND is correctly classified as -ve\n",
    "\n",
    "            all_neg = sum(y_true_local == -1.0)\n",
    "            all_pos = sum(y_true_local == +1.0)\n",
    "\n",
    "            fpr = float(fp) / float(fp + tn)\n",
    "            fnr = float(fn) / float(fn + tp)\n",
    "            tpr = float(tp) / float(tp + fn)\n",
    "            tnr = float(tn) / float(tn + fp)\n",
    "\n",
    "\n",
    "            s_attr_to_fp_fn[s][s_val][\"fp\"] = fp\n",
    "            s_attr_to_fp_fn[s][s_val][\"fn\"] = fn\n",
    "            s_attr_to_fp_fn[s][s_val][\"fpr\"] = fpr\n",
    "            s_attr_to_fp_fn[s][s_val][\"fnr\"] = fnr\n",
    "\n",
    "            s_attr_to_fp_fn[s][s_val][\"acc\"] = (tp + tn) / (tp + tn + fp + fn)\n",
    "            if verbose == True:\n",
    "                if isinstance(s_val, float): # print the int value of the sensitive attr val\n",
    "                    s_val = int(s_val)\n",
    "                print (\"||  %s  || %0.2f || %0.2f ||\" % (s_val, fpr, fnr))\n",
    "\n",
    "        \n",
    "        return s_attr_to_fp_fn\n",
    "\n",
    "\n",
    "def get_sensitive_attr_constraint_fpr_fnr_cov(model, x_arr, y_arr_true, y_arr_dist_boundary, x_control_arr, verbose=False):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we compute the covariance between sensitive attr val and ONLY misclassification distances from boundary for False-positives\n",
    "    (-N_1 / N) sum_0(min(0, y.f(x))) + (N_0 / N) sum_1(min(0, y.f(x))) for all misclassifications\n",
    "    (-N_1 / N) sum_0(min(0, (1-y)/2 . y.f(x))) + (N_0 / N) sum_1(min(0,  (1-y)/2. y.f(x))) for FPR\n",
    "\n",
    "    y_arr_true are the true class labels\n",
    "    y_arr_dist_boundary are the predicted distances from the decision boundary\n",
    "\n",
    "    If the model is None, we assume that the y_arr_dist_boundary contains the distace from the decision boundary\n",
    "    If the model is not None, we just compute a dot product or model and x_arr\n",
    "    for the case of SVM, we pass the distace from bounday becase the intercept in internalized for the class\n",
    "    and we have compute the distance using the project function\n",
    "\n",
    "\n",
    "    this function will return -1 if the constraint specified by thresh parameter is not satifsified\n",
    "    otherwise it will reutrn +1\n",
    "    if the return value is >=0, then the constraint is satisfied\n",
    "    \"\"\"\n",
    "\n",
    "        \n",
    "    assert(x_arr.shape[0] == x_control_arr.shape[0])\n",
    "    if len(x_control_arr.shape) > 1: # make sure we just have one column in the array\n",
    "        assert(x_control_arr.shape[1] == 1)\n",
    "    if len(set(x_control_arr)) != 2: # non binary attr\n",
    "        raise Exception(\"Non binary attr, fix to handle non bin attrs\")\n",
    "\n",
    "    \n",
    "    arr = []\n",
    "    if model is None:\n",
    "        arr = y_arr_dist_boundary * y_arr_true # simply the output labels\n",
    "    else:\n",
    "        arr = np.dot(model, x_arr.T) * y_arr_true # the product with the weight vector -- the sign of this is the output label\n",
    "    arr = np.array(arr)\n",
    "\n",
    "    s_val_to_total = {ct:{} for ct in [0,1,2]}\n",
    "    s_val_to_avg = {ct:{} for ct in [0,1,2]}\n",
    "    cons_sum_dict = {ct:{} for ct in [0,1,2]} # sum of entities (females and males) in constraints are stored here\n",
    "\n",
    "    for v in set(x_control_arr):\n",
    "        s_val_to_total[0][v] = sum(x_control_arr == v)\n",
    "        s_val_to_total[1][v] = sum(np.logical_and(x_control_arr == v, y_arr_true == -1))\n",
    "        s_val_to_total[2][v] = sum(np.logical_and(x_control_arr == v, y_arr_true == +1))\n",
    "\n",
    "\n",
    "    for ct in [0,1,2]:\n",
    "        s_val_to_avg[ct][0] = s_val_to_total[ct][1] / float(s_val_to_total[ct][0] + s_val_to_total[ct][1]) # N1 / N\n",
    "        s_val_to_avg[ct][1] = 1.0 - s_val_to_avg[ct][0] # N0 / N\n",
    "\n",
    "    \n",
    "    for v in set(x_control_arr):\n",
    "        idx = x_control_arr == v\n",
    "        dist_bound_prod = arr[idx]\n",
    "\n",
    "        cons_sum_dict[0][v] = sum( np.minimum(0, dist_bound_prod) ) * (s_val_to_avg[0][v] / len(x_arr))\n",
    "        cons_sum_dict[1][v] = sum( np.minimum(0, ( (1 - y_arr_true[idx]) / 2 ) * dist_bound_prod) ) * (s_val_to_avg[1][v] / sum(y_arr_true == -1))\n",
    "        cons_sum_dict[2][v] = sum( np.minimum(0, ( (1 + y_arr_true[idx]) / 2 ) * dist_bound_prod) ) * (s_val_to_avg[2][v] / sum(y_arr_true == +1))\n",
    "        \n",
    "\n",
    "    cons_type_to_name = {0:\"ALL\", 1:\"FPR\", 2:\"FNR\"}\n",
    "    for cons_type in [0,1,2]:\n",
    "        cov_type_name = cons_type_to_name[cons_type]    \n",
    "        cov = cons_sum_dict[cons_type][1] - cons_sum_dict[cons_type][0]\n",
    "        if verbose == True:\n",
    "            print (\"Covariance for type '%s' is: %0.7f\" %(cov_type_name, cov))\n",
    "        \n",
    "    return cons_sum_dict\n",
    "    \n",
    "\n",
    "def plot_fairness_acc_tradeoff(x_all, y_all, x_control_all, loss_function, cons_type):\n",
    "\n",
    "\n",
    "    # very the covariance threshold using a range of decreasing multiplicative factors and see the tradeoffs between accuracy and fairness\n",
    "    it = 0.2\n",
    "    mult_range = np.arange(1.0, 0.0-it, -it).tolist()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    positive_class_label = 1 # positive class is +1\n",
    "    test_acc = []\n",
    "    \n",
    "\n",
    "    # first get the original values of covariance in the unconstrained classifier -- these original values are not needed for reverse constraint    \n",
    "    test_acc_arr, train_acc_arr, correlation_dict_test_arr, correlation_dict_train_arr, cov_dict_test_arr, cov_dict_train_arr = compute_cross_validation_error(x_all, y_all, x_control_all, num_folds, loss_function, 0, apply_accuracy_constraint, sep_constraint, sensitive_attrs, [{} for i in range(0,num_folds)], 0)\n",
    "\n",
    "    for c in cov_range:\n",
    "        print (\"LOG: testing for multiplicative factor: %0.2f\" % c)\n",
    "        sensitive_attrs_to_cov_original_arr_multiplied = []\n",
    "        for sensitive_attrs_to_cov_original in cov_dict_train_arr:\n",
    "            sensitive_attrs_to_cov_thresh = deepcopy(sensitive_attrs_to_cov_original)\n",
    "            for k in sensitive_attrs_to_cov_thresh.keys():\n",
    "                v = sensitive_attrs_to_cov_thresh[k]\n",
    "                if type(v) == type({}):\n",
    "                    for k1 in v.keys():\n",
    "                        v[k1] = v[k1] * c\n",
    "                else:\n",
    "                    sensitive_attrs_to_cov_thresh[k] = v * c\n",
    "            sensitive_attrs_to_cov_original_arr_multiplied.append(sensitive_attrs_to_cov_thresh)\n",
    "\n",
    "\n",
    "        test_acc_arr, train_acc_arr, correlation_dict_test_arr, correlation_dict_train_arr, cov_dict_test_arr, cov_dict_train_arr  = compute_cross_validation_error(x_all, y_all, x_control_all, num_folds, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_original_arr_multiplied, c)\n",
    "        test_acc.append(np.mean(test_acc_arr))\n",
    "\n",
    "\n",
    "        correlation_dict_train = get_avg_correlation_dict(correlation_dict_train_arr)\n",
    "        correlation_dict_test = get_avg_correlation_dict(correlation_dict_test_arr)\n",
    "        \n",
    "        # just plot the correlations for the first sensitive attr, the plotting can be extended for the other values, but as a proof of concept, we will jsut show for one\n",
    "        s = sensitive_attrs[0]    \n",
    "        \n",
    "        for k,v in correlation_dict_test[s].items():\n",
    "            if v.get(positive_class_label) is None:\n",
    "                positive_per_category[k].append(0.0)\n",
    "            else:\n",
    "                positive_per_category[k].append(v[positive_class_label])\n",
    "    \n",
    "    positive_per_category = dict(positive_per_category)\n",
    "    \n",
    "    p_rule_arr = (np.array(positive_per_category[0]) / np.array(positive_per_category[1])) * 100.0\n",
    "    \n",
    "\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    plt.plot(cov_range, positive_per_category[0], \"-o\" , color=\"green\", label = \"Protected\")\n",
    "    plt.plot(cov_range, positive_per_category[1], \"-o\", color=\"blue\", label = \"Non-protected\")\n",
    "    ax.set_xlim([min(cov_range), max(cov_range)])\n",
    "    plt.xlabel('Multiplicative loss factor')\n",
    "    plt.ylabel('Perc. in positive class')\n",
    "    if apply_accuracy_constraint == False:\n",
    "        plt.gca().invert_xaxis()\n",
    "        plt.xlabel('Multiplicative covariance factor (c)')\n",
    "    ax.legend()\n",
    "\n",
    "    ax = plt.subplot(2,1,2)\n",
    "    plt.scatter(p_rule_arr, test_acc, color=\"red\")\n",
    "    ax.set_xlim([min(p_rule_arr), max(max(p_rule_arr), 100)])\n",
    "    plt.xlabel('P% rule')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.5)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "from collections import defaultdict\n",
    "import traceback\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "def _hinge_loss(w, X, y):\n",
    "\n",
    "    \n",
    "    yz = y * np.dot(X,w) # y * (x.w)\n",
    "    yz = np.maximum(np.zeros_like(yz), (1-yz)) # hinge function\n",
    "    \n",
    "    return sum(yz)\n",
    "\n",
    "def _logistic_loss(w, X, y, return_arr=None):\n",
    "\t\"\"\"Computes the logistic loss.\n",
    "\n",
    "\tThis function is used from scikit-learn source code\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tw : ndarray, shape (n_features,) or (n_features + 1,)\n",
    "\t    Coefficient vector.\n",
    "\n",
    "\tX : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "\t    Training data.\n",
    "\n",
    "\ty : ndarray, shape (n_samples,)\n",
    "\t    Array of labels.\n",
    "\n",
    "\t\"\"\"\n",
    "\t\n",
    "\n",
    "\tyz = y * np.dot(X,w)\n",
    "\t# Logistic loss is the negative of the log of the logistic function.\n",
    "\tif return_arr == True:\n",
    "\t\tout = -(log_logistic(yz))\n",
    "\telse:\n",
    "\t\tout = -np.sum(log_logistic(yz))\n",
    "\treturn out\n",
    "\n",
    "def _logistic_loss_l2_reg(w, X, y, lam=None):\n",
    "\n",
    "\tif lam is None:\n",
    "\t\tlam = 1.0\n",
    "\n",
    "\tyz = y * np.dot(X,w)\n",
    "\t# Logistic loss is the negative of the log of the logistic function.\n",
    "\tlogistic_loss = -np.sum(log_logistic(yz))\n",
    "\tl2_reg = (float(lam)/2.0) * np.sum([elem*elem for elem in w])\n",
    "\tout = logistic_loss + l2_reg\n",
    "\treturn out\n",
    "\n",
    "\n",
    "def log_logistic(X):\n",
    "\n",
    "\t\"\"\" This function is used from scikit-learn source code. Source link below \"\"\"\n",
    "\n",
    "\t\"\"\"Compute the log of the logistic function, ``log(1 / (1 + e ** -x))``.\n",
    "\tThis implementation is numerically stable because it splits positive and\n",
    "\tnegative values::\n",
    "\t    -log(1 + exp(-x_i))     if x_i > 0\n",
    "\t    x_i - log(1 + exp(x_i)) if x_i <= 0\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tX: array-like, shape (M, N)\n",
    "\t    Argument to the logistic function\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tout: array, shape (M, N)\n",
    "\t    Log of the logistic function evaluated at every point in x\n",
    "\tNotes\n",
    "\t-----\n",
    "\tSource code at:\n",
    "\thttps://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/extmath.py\n",
    "\t-----\n",
    "\n",
    "\tSee the blog post describing this implementation:\n",
    "\thttp://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/\n",
    "\t\"\"\"\n",
    "\tif X.ndim > 1: raise Exception(\"Array of samples cannot be more than 1-D!\")\n",
    "\tout = np.empty_like(X) # same dimensions and data types\n",
    "\n",
    "\tidx = X>0\n",
    "\tout[idx] = -np.log(1.0 + np.exp(-X[idx]))\n",
    "\tout[~idx] = X[~idx] - np.log(1.0 + np.exp(X[~idx]))\n",
    "\treturn out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-df15e71d075a>, line 241)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-df15e71d075a>\"\u001b[0;36m, line \u001b[0;32m241\u001b[0m\n\u001b[0;31m    print \"Accuracy: %0.2f\" % (np.mean(acc_arr))\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import seed, shuffle\n",
    "import loss_funcs as lf # our implementation of loss funcs\n",
    "from scipy.optimize import minimize # for loss func minimization\n",
    "from multiprocessing import Pool, Process, Queue\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt # for plotting stuff\n",
    "import sys\n",
    "\n",
    "SEED = 1122334455\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(x, y, x_control, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma=None):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Function that trains the model subject to various fairness constraints.\n",
    "    If no constraints are given, then simply trains an unaltered classifier.\n",
    "    Example usage in: \"synthetic_data_demo/decision_boundary_demo.py\"\n",
    "\n",
    "    ----\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "    X: (n) x (d+1) numpy array -- n = number of examples, d = number of features, one feature is the intercept\n",
    "    y: 1-d numpy array (n entries)\n",
    "    x_control: dictionary of the type {\"s\": [...]}, key \"s\" is the sensitive feature name, and the value is a 1-d list with n elements holding the sensitive feature values\n",
    "    loss_function: the loss function that we want to optimize -- for now we have implementation of logistic loss, but other functions like hinge loss can also be added\n",
    "    apply_fairness_constraints: optimize accuracy subject to fairness constraint (0/1 values)\n",
    "    apply_accuracy_constraint: optimize fairness subject to accuracy constraint (0/1 values)\n",
    "    sep_constraint: apply the fine grained accuracy constraint\n",
    "        for details, see Section 3.3 of arxiv.org/abs/1507.05259v3\n",
    "        For examples on how to apply these constraints, see \"synthetic_data_demo/decision_boundary_demo.py\"\n",
    "    Note: both apply_fairness_constraints and apply_accuracy_constraint cannot be 1 at the same time\n",
    "    sensitive_attrs: [\"s1\", \"s2\", ...], list of sensitive features for which to apply fairness constraint, all of these sensitive features should have a corresponding array in x_control\n",
    "    sensitive_attrs_to_cov_thresh: the covariance threshold that the classifier should achieve (this is only needed when apply_fairness_constraints=1, not needed for the other two constraints)\n",
    "    gamma: controls the loss in accuracy we are willing to incur when using apply_accuracy_constraint and sep_constraint\n",
    "\n",
    "    ----\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "    w: the learned weight vector for the classifier\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    assert((apply_accuracy_constraint == 1 and apply_fairness_constraints == 1) == False) # both constraints cannot be applied at the same time\n",
    "\n",
    "    max_iter = 100000 # maximum number of iterations for the minimization algorithm\n",
    "\n",
    "    if apply_fairness_constraints == 0:\n",
    "        constraints = []\n",
    "    else:\n",
    "        constraints = get_constraint_list_cov(x, y, x_control, sensitive_attrs, sensitive_attrs_to_cov_thresh)      \n",
    "\n",
    "    if apply_accuracy_constraint == 0: #its not the reverse problem, just train w with cross cov constraints\n",
    "\n",
    "        f_args=(x, y)\n",
    "        w = minimize(fun = loss_function,\n",
    "            x0 = np.random.rand(x.shape[1],),\n",
    "            args = f_args,\n",
    "            method = 'SLSQP',\n",
    "            options = {\"maxiter\":max_iter},\n",
    "            constraints = constraints\n",
    "            )\n",
    "\n",
    "    else:\n",
    "\n",
    "        # train on just the loss function\n",
    "        w = minimize(fun = loss_function,\n",
    "            x0 = np.random.rand(x.shape[1],),\n",
    "            args = (x, y),\n",
    "            method = 'SLSQP',\n",
    "            options = {\"maxiter\":max_iter},\n",
    "            constraints = []\n",
    "            )\n",
    "\n",
    "        old_w = deepcopy(w.x)\n",
    "        \n",
    "\n",
    "        def constraint_gamma_all(w, x, y,  initial_loss_arr):\n",
    "            \n",
    "            gamma_arr = np.ones_like(y) * gamma # set gamma for everyone\n",
    "            new_loss = loss_function(w, x, y)\n",
    "            old_loss = sum(initial_loss_arr)\n",
    "            return ((1.0 + gamma) * old_loss) - new_loss\n",
    "\n",
    "        def constraint_protected_people(w,x,y): # dont confuse the protected here with the sensitive feature protected/non-protected values -- protected here means that these points should not be misclassified to negative class\n",
    "            return np.dot(w, x.T) # if this is positive, the constraint is satisfied\n",
    "        def constraint_unprotected_people(w,ind,old_loss,x,y):\n",
    "            \n",
    "            new_loss = loss_function(w, np.array([x]), np.array(y))\n",
    "            return ((1.0 + gamma) * old_loss) - new_loss\n",
    "\n",
    "        constraints = []\n",
    "        predicted_labels = np.sign(np.dot(w.x, x.T))\n",
    "        unconstrained_loss_arr = loss_function(w.x, x, y, return_arr=True)\n",
    "\n",
    "        if sep_constraint == True: # separate gemma for different people\n",
    "            for i in range(0, len(predicted_labels)):\n",
    "                if predicted_labels[i] == 1.0 and x_control[sensitive_attrs[0]][i] == 1.0: # for now we are assuming just one sensitive attr for reverse constraint, later, extend the code to take into account multiple sensitive attrs\n",
    "                    c = ({'type': 'ineq', 'fun': constraint_protected_people, 'args':(x[i], y[i])}) # this constraint makes sure that these people stay in the positive class even in the modified classifier             \n",
    "                    constraints.append(c)\n",
    "                else:\n",
    "                    c = ({'type': 'ineq', 'fun': constraint_unprotected_people, 'args':(i, unconstrained_loss_arr[i], x[i], y[i])})                \n",
    "                    constraints.append(c)\n",
    "        else: # same gamma for everyone\n",
    "            c = ({'type': 'ineq', 'fun': constraint_gamma_all, 'args':(x,y,unconstrained_loss_arr)})\n",
    "            constraints.append(c)\n",
    "\n",
    "        def cross_cov_abs_optm_func(weight_vec, x_in, x_control_in_arr):\n",
    "            cross_cov = (x_control_in_arr - np.mean(x_control_in_arr)) * np.dot(weight_vec, x_in.T)\n",
    "            return float(abs(sum(cross_cov))) / float(x_in.shape[0])\n",
    "\n",
    "\n",
    "        w = minimize(fun = cross_cov_abs_optm_func,\n",
    "            x0 = old_w,\n",
    "            args = (x, x_control[sensitive_attrs[0]]),\n",
    "            method = 'SLSQP',\n",
    "            options = {\"maxiter\":100000},\n",
    "            constraints = constraints\n",
    "            )\n",
    "\n",
    "    try:\n",
    "        assert(w.success == True)\n",
    "    except:\n",
    "        print (\"Optimization problem did not converge.. Check the solution returned by the optimizer.\")\n",
    "        print (\"Returned solution is:\")\n",
    "        print (w)\n",
    "\n",
    "\n",
    "\n",
    "    return w.x\n",
    "\n",
    "\n",
    "def compute_cross_validation_error(x_all, y_all, x_control_all, num_folds, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh_arr, gamma=None):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the cross validation error for the classifier subject to various fairness constraints\n",
    "    This function is just a wrapper of \"train_model(...)\", all inputs (except for num_folds) are the same. See the specifications of train_model(...) for more info.\n",
    "\n",
    "    Returns lists of train/test accuracy (with each list holding values for all folds), the fractions of various sensitive groups in positive class (for train and test sets), and covariance between sensitive feature and distance from decision boundary (again, for both train and test folds).\n",
    "    \"\"\"\n",
    "\n",
    "    train_folds = []\n",
    "    test_folds = []\n",
    "    n_samples = len(y_all)\n",
    "    train_fold_size = 0.7 # the rest of 0.3 is for testing\n",
    "\n",
    "    # split the data into folds for cross-validation\n",
    "    for i in range(0,num_folds):\n",
    "        perm = range(0,n_samples) # shuffle the data before creating each fold\n",
    "        shuffle(perm)\n",
    "        x_all_perm = x_all[perm]\n",
    "        y_all_perm = y_all[perm]\n",
    "        x_control_all_perm = {}\n",
    "        for k in x_control_all.keys():\n",
    "            x_control_all_perm[k] = np.array(x_control_all[k])[perm]\n",
    "\n",
    "\n",
    "        x_all_train, y_all_train, x_control_all_train, x_all_test, y_all_test, x_control_all_test = split_into_train_test(x_all_perm, y_all_perm, x_control_all_perm, train_fold_size)\n",
    "\n",
    "        train_folds.append([x_all_train, y_all_train, x_control_all_train])\n",
    "        test_folds.append([x_all_test, y_all_test, x_control_all_test])\n",
    "\n",
    "    def train_test_single_fold(train_data, test_data, fold_num, output_folds, sensitive_attrs_to_cov_thresh):\n",
    "\n",
    "        x_train, y_train, x_control_train = train_data\n",
    "        x_test, y_test, x_control_test = test_data\n",
    "\n",
    "        w = train_model(x_train, y_train, x_control_train, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_thresh, gamma)\n",
    "        train_score, test_score, correct_answers_train, correct_answers_test = check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "        \n",
    "        distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "        all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "        correlation_dict_test = get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "        cov_dict_test = print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "\n",
    "        distances_boundary_train = (np.dot(x_train, w)).tolist()\n",
    "        all_class_labels_assigned_train = np.sign(distances_boundary_train)\n",
    "        correlation_dict_train = get_correlations(None, None, all_class_labels_assigned_train, x_control_train, sensitive_attrs)\n",
    "        cov_dict_train = print_covariance_sensitive_attrs(None, x_train, distances_boundary_train, x_control_train, sensitive_attrs)\n",
    "\n",
    "        output_folds.put([fold_num, test_score, train_score, correlation_dict_test, correlation_dict_train, cov_dict_test, cov_dict_train])\n",
    "\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    output_folds = Queue()\n",
    "    processes = [Process(target=train_test_single_fold, args=(train_folds[x], test_folds[x], x, output_folds, sensitive_attrs_to_cov_thresh_arr[x])) for x in range(num_folds)]\n",
    "\n",
    "    # Run processes\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "\n",
    "\n",
    "    # Get the reuslts\n",
    "    results = [output_folds.get() for p in processes]\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    \n",
    "    test_acc_arr = []\n",
    "    train_acc_arr = []\n",
    "    correlation_dict_test_arr = []\n",
    "    correlation_dict_train_arr = []\n",
    "    cov_dict_test_arr = []\n",
    "    cov_dict_train_arr = []\n",
    "\n",
    "    results = sorted(results, key = lambda x : x[0]) # sort w.r.t fold num\n",
    "    for res in results:\n",
    "        fold_num, test_score, train_score, correlation_dict_test, correlation_dict_train, cov_dict_test, cov_dict_train = res\n",
    "\n",
    "        test_acc_arr.append(test_score)\n",
    "        train_acc_arr.append(train_score)\n",
    "        correlation_dict_test_arr.append(correlation_dict_test)\n",
    "        correlation_dict_train_arr.append(correlation_dict_train)\n",
    "        cov_dict_test_arr.append(cov_dict_test)\n",
    "        cov_dict_train_arr.append(cov_dict_train)\n",
    "\n",
    "    \n",
    "    return test_acc_arr, train_acc_arr, correlation_dict_test_arr, correlation_dict_train_arr, cov_dict_test_arr, cov_dict_train_arr\n",
    "\n",
    "\n",
    "\n",
    "def print_classifier_fairness_stats(acc_arr, correlation_dict_arr, cov_dict_arr, s_attr_name):\n",
    "    \n",
    "    correlation_dict = get_avg_correlation_dict(correlation_dict_arr)\n",
    "    non_prot_pos = correlation_dict[s_attr_name][1][1]\n",
    "    prot_pos = correlation_dict[s_attr_name][0][1]\n",
    "    p_rule = (prot_pos / non_prot_pos) * 100.0\n",
    "    \n",
    "    print \"Accuracy: %0.2f\" % (np.mean(acc_arr))\n",
    "    print \"Protected/non-protected in +ve class: %0.0f%% / %0.0f%%\" % (prot_pos, non_prot_pos)\n",
    "    print \"P-rule achieved: %0.0f%%\" % (p_rule)\n",
    "    print \"Covariance between sensitive feature and decision from distance boundary : %0.3f\" % (np.mean([v[s_attr_name] for v in cov_dict_arr]))\n",
    "    print\n",
    "    return p_rule\n",
    "\n",
    "def compute_p_rule(x_control, class_labels):\n",
    "\n",
    "    \"\"\" Compute the p-rule based on Doctrine of disparate impact \"\"\"\n",
    "\n",
    "    non_prot_all = sum(x_control == 1.0) # non-protected group\n",
    "    prot_all = sum(x_control == 0.0) # protected group\n",
    "    non_prot_pos = sum(class_labels[x_control == 1.0] == 1.0) # non_protected in positive class\n",
    "    prot_pos = sum(class_labels[x_control == 0.0] == 1.0) # protected in positive class\n",
    "    frac_non_prot_pos = float(non_prot_pos) / float(non_prot_all)\n",
    "    frac_prot_pos = float(prot_pos) / float(prot_all)\n",
    "    p_rule = (frac_prot_pos / frac_non_prot_pos) * 100.0\n",
    "    print\n",
    "    print \"Total data points: %d\" % (len(x_control))\n",
    "    print \"# non-protected examples: %d\" % (non_prot_all)\n",
    "    print \"# protected examples: %d\" % (prot_all)\n",
    "    print \"Non-protected in positive class: %d (%0.0f%%)\" % (non_prot_pos, non_prot_pos * 100.0 / non_prot_all)\n",
    "    print \"Protected in positive class: %d (%0.0f%%)\" % (prot_pos, prot_pos * 100.0 / prot_all)\n",
    "    print \"P-rule is: %0.0f%%\" % ( p_rule )\n",
    "    return p_rule\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_intercept(x):\n",
    "\n",
    "    \"\"\" Add intercept to the data before linear classification \"\"\"\n",
    "    m,n = x.shape\n",
    "    intercept = np.ones(m).reshape(m, 1) # the constant b\n",
    "    return np.concatenate((intercept, x), axis = 1)\n",
    "\n",
    "def check_binary(arr):\n",
    "    \"give an array of values, see if the values are only 0 and 1\"\n",
    "    s = sorted(set(arr))\n",
    "    if s[0] == 0 and s[1] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_one_hot_encoding(in_arr):\n",
    "    \"\"\"\n",
    "        input: 1-D arr with int vals -- if not int vals, will raise an error\n",
    "        output: m (ndarray): one-hot encoded matrix\n",
    "                d (dict): also returns a dictionary original_val -> column in encoded matrix\n",
    "    \"\"\"\n",
    "\n",
    "    for k in in_arr:\n",
    "        if str(type(k)) != \"<type 'numpy.float64'>\" and type(k) != int and type(k) != np.int64:\n",
    "            print str(type(k))\n",
    "            print \"************* ERROR: Input arr does not have integer types\"\n",
    "            return None\n",
    "        \n",
    "    in_arr = np.array(in_arr, dtype=int)\n",
    "    assert(len(in_arr.shape)==1) # no column, means it was a 1-D arr\n",
    "    attr_vals_uniq_sorted = sorted(list(set(in_arr)))\n",
    "    num_uniq_vals = len(attr_vals_uniq_sorted)\n",
    "    if (num_uniq_vals == 2) and (attr_vals_uniq_sorted[0] == 0 and attr_vals_uniq_sorted[1] == 1):\n",
    "        return in_arr, None\n",
    "\n",
    "    \n",
    "    index_dict = {} # value to the column number\n",
    "    for i in range(0,len(attr_vals_uniq_sorted)):\n",
    "        val = attr_vals_uniq_sorted[i]\n",
    "        index_dict[val] = i\n",
    "\n",
    "    out_arr = []    \n",
    "    for i in range(0,len(in_arr)):\n",
    "        tup = np.zeros(num_uniq_vals)\n",
    "        val = in_arr[i]\n",
    "        ind = index_dict[val]\n",
    "        tup[ind] = 1 # set that value of tuple to 1\n",
    "        out_arr.append(tup)\n",
    "\n",
    "    return np.array(out_arr), index_dict\n",
    "\n",
    "def check_accuracy(model, x_train, y_train, x_test, y_test, y_train_predicted, y_test_predicted):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    returns the train/test accuracy of the model\n",
    "    we either pass the model (w)\n",
    "    else we pass y_predicted\n",
    "    \"\"\"\n",
    "    if model is not None and y_test_predicted is not None:\n",
    "        print \"Either the model (w) or the predicted labels should be None\"\n",
    "        raise Exception(\"Either the model (w) or the predicted labels should be None\")\n",
    "\n",
    "    if model is not None:\n",
    "        y_test_predicted = np.sign(np.dot(x_test, model))\n",
    "        y_train_predicted = np.sign(np.dot(x_train, model))\n",
    "\n",
    "    def get_accuracy(y, Y_predicted):\n",
    "        correct_answers = (Y_predicted == y).astype(int) # will have 1 when the prediction and the actual label match\n",
    "        accuracy = float(sum(correct_answers)) / float(len(correct_answers))\n",
    "        return accuracy, sum(correct_answers)\n",
    "\n",
    "    train_score, correct_answers_train = get_accuracy(y_train, y_train_predicted)\n",
    "    test_score, correct_answers_test = get_accuracy(y_test, y_test_predicted)\n",
    "\n",
    "    return train_score, test_score, correct_answers_train, correct_answers_test\n",
    "\n",
    "def test_sensitive_attr_constraint_cov(model, x_arr, y_arr_dist_boundary, x_control, thresh, verbose):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    The covariance is computed b/w the sensitive attr val and the distance from the boundary\n",
    "    If the model is None, we assume that the y_arr_dist_boundary contains the distace from the decision boundary\n",
    "    If the model is not None, we just compute a dot product or model and x_arr\n",
    "    for the case of SVM, we pass the distace from bounday becase the intercept in internalized for the class\n",
    "    and we have compute the distance using the project function\n",
    "\n",
    "    this function will return -1 if the constraint specified by thresh parameter is not satifsified\n",
    "    otherwise it will reutrn +1\n",
    "    if the return value is >=0, then the constraint is satisfied\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    assert(x_arr.shape[0] == x_control.shape[0])\n",
    "    if len(x_control.shape) > 1: # make sure we just have one column in the array\n",
    "        assert(x_control.shape[1] == 1)\n",
    "    \n",
    "    arr = []\n",
    "    if model is None:\n",
    "        arr = y_arr_dist_boundary # simply the output labels\n",
    "    else:\n",
    "        arr = np.dot(model, x_arr.T) # the product with the weight vector -- the sign of this is the output label\n",
    "    \n",
    "    arr = np.array(arr, dtype=np.float64)\n",
    "\n",
    "\n",
    "    cov = np.dot(x_control - np.mean(x_control), arr ) / float(len(x_control))\n",
    "\n",
    "        \n",
    "    ans = thresh - abs(cov) # will be <0 if the covariance is greater than thresh -- that is, the condition is not satisfied\n",
    "    # ans = thresh - cov # will be <0 if the covariance is greater than thresh -- that is, the condition is not satisfied\n",
    "    if verbose is True:\n",
    "        print \"Covariance is\", cov\n",
    "        print \"Diff is:\", ans\n",
    "        print\n",
    "    return ans\n",
    "\n",
    "def print_covariance_sensitive_attrs(model, x_arr, y_arr_dist_boundary, x_control, sensitive_attrs):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    reutrns the covariance between sensitive features and distance from decision boundary\n",
    "    \"\"\"\n",
    "\n",
    "    arr = []\n",
    "    if model is None:\n",
    "        arr = y_arr_dist_boundary # simplt the output labels\n",
    "    else:\n",
    "        arr = np.dot(model, x_arr.T) # the product with the weight vector -- the sign of this is the output label\n",
    "    \n",
    "\n",
    "    sensitive_attrs_to_cov_original = {}\n",
    "    for attr in sensitive_attrs:\n",
    "\n",
    "        attr_arr = x_control[attr]\n",
    "\n",
    "\n",
    "        bin_attr = check_binary(attr_arr) # check if the attribute is binary (0/1), or has more than 2 vals\n",
    "        if bin_attr == False: # if its a non-binary sensitive feature, then perform one-hot-encoding\n",
    "            attr_arr_transformed, index_dict = get_one_hot_encoding(attr_arr)\n",
    "\n",
    "        thresh = 0\n",
    "\n",
    "        if bin_attr:\n",
    "            cov = thresh - test_sensitive_attr_constraint_cov(None, x_arr, arr, np.array(attr_arr), thresh, False)\n",
    "            sensitive_attrs_to_cov_original[attr] = cov\n",
    "        else: # sensitive feature has more than 2 categorical values            \n",
    "            \n",
    "            cov_arr = []\n",
    "            sensitive_attrs_to_cov_original[attr] = {}\n",
    "            for attr_val, ind in index_dict.items():\n",
    "                t = attr_arr_transformed[:,ind]\n",
    "                cov = thresh - test_sensitive_attr_constraint_cov(None, x_arr, arr, t, thresh, False)\n",
    "                sensitive_attrs_to_cov_original[attr][attr_val] = cov\n",
    "                cov_arr.append(abs(cov))\n",
    "\n",
    "            cov = max(cov_arr)\n",
    "            \n",
    "    return sensitive_attrs_to_cov_original\n",
    "\n",
    "\n",
    "def get_correlations(model, x_test, y_predicted, x_control_test, sensitive_attrs):\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    returns the fraction in positive class for sensitive feature values\n",
    "    \"\"\"\n",
    "\n",
    "    if model is not None:\n",
    "        y_predicted = np.sign(np.dot(x_test, model))\n",
    "        \n",
    "    y_predicted = np.array(y_predicted)\n",
    "    \n",
    "    out_dict = {}\n",
    "    for attr in sensitive_attrs:\n",
    "\n",
    "        attr_val = []\n",
    "        for v in x_control_test[attr]: attr_val.append(v)\n",
    "        assert(len(attr_val) == len(y_predicted))\n",
    "\n",
    "\n",
    "        total_per_val = defaultdict(int)\n",
    "        attr_to_class_labels_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        for i in range(0, len(y_predicted)):\n",
    "            val = attr_val[i]\n",
    "            label = y_predicted[i]\n",
    "\n",
    "            # val = attr_val_int_mapping_dict_reversed[val] # change values from intgers to actual names\n",
    "            total_per_val[val] += 1\n",
    "            attr_to_class_labels_dict[val][label] += 1\n",
    "\n",
    "        class_labels = set(y_predicted.tolist())\n",
    "\n",
    "        local_dict_1 = {}\n",
    "        for k1,v1 in attr_to_class_labels_dict.items():\n",
    "            total_this_val = total_per_val[k1]\n",
    "\n",
    "            local_dict_2 = {}\n",
    "            for k2 in class_labels: # the order should be the same for printing\n",
    "                v2 = v1[k2]\n",
    "\n",
    "                f = float(v2) * 100.0 / float(total_this_val)\n",
    "\n",
    "\n",
    "                local_dict_2[k2] = f\n",
    "            local_dict_1[k1] = local_dict_2\n",
    "        out_dict[attr] = local_dict_1\n",
    "\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_constraint_list_cov(x_train, y_train, x_control_train, sensitive_attrs, sensitive_attrs_to_cov_thresh):\n",
    "\n",
    "    \"\"\"\n",
    "    get the list of constraints to be fed to the minimizer\n",
    "    \"\"\"\n",
    "\n",
    "    constraints = []\n",
    "\n",
    "\n",
    "    for attr in sensitive_attrs:\n",
    "\n",
    "\n",
    "        attr_arr = x_control_train[attr]\n",
    "        attr_arr_transformed, index_dict = get_one_hot_encoding(attr_arr)\n",
    "                \n",
    "        if index_dict is None: # binary attribute\n",
    "            thresh = sensitive_attrs_to_cov_thresh[attr]\n",
    "            c = ({'type': 'ineq', 'fun': test_sensitive_attr_constraint_cov, 'args':(x_train, y_train, attr_arr_transformed,thresh, False)})\n",
    "            constraints.append(c)\n",
    "        else: # otherwise, its a categorical attribute, so we need to set the cov thresh for each value separately\n",
    "\n",
    "\n",
    "            for attr_val, ind in index_dict.items():\n",
    "                attr_name = attr_val                \n",
    "                thresh = sensitive_attrs_to_cov_thresh[attr][attr_name]\n",
    "                \n",
    "                t = attr_arr_transformed[:,ind]\n",
    "                c = ({'type': 'ineq', 'fun': test_sensitive_attr_constraint_cov, 'args':(x_train, y_train, t ,thresh, False)})\n",
    "                constraints.append(c)\n",
    "\n",
    "\n",
    "    return constraints\n",
    "\n",
    "\n",
    "\n",
    "def split_into_train_test(x_all, y_all, x_control_all, train_fold_size):\n",
    "\n",
    "    split_point = int(round(float(x_all.shape[0]) * train_fold_size))\n",
    "    x_all_train = x_all[:split_point]\n",
    "    x_all_test = x_all[split_point:]\n",
    "    y_all_train = y_all[:split_point]\n",
    "    y_all_test = y_all[split_point:]\n",
    "    x_control_all_train = {}\n",
    "    x_control_all_test = {}\n",
    "    for k in x_control_all.keys():\n",
    "        x_control_all_train[k] = x_control_all[k][:split_point]\n",
    "        x_control_all_test[k] = x_control_all[k][split_point:]\n",
    "\n",
    "    return x_all_train, y_all_train, x_control_all_train, x_all_test, y_all_test, x_control_all_test\n",
    "\n",
    "\n",
    "def get_avg_correlation_dict(correlation_dict_arr):\n",
    "    # make the structure for the correlation dict\n",
    "    correlation_dict_avg = {}\n",
    "    # print correlation_dict_arr\n",
    "    for k,v in correlation_dict_arr[0].items():\n",
    "        correlation_dict_avg[k] = {}\n",
    "        for feature_val, feature_dict in v.items():\n",
    "            correlation_dict_avg[k][feature_val] = {}\n",
    "            for class_label, frac_class in feature_dict.items():\n",
    "                correlation_dict_avg[k][feature_val][class_label] = []\n",
    "\n",
    "    # populate the correlation dict\n",
    "    for correlation_dict in correlation_dict_arr:\n",
    "        for k,v in correlation_dict.items():\n",
    "            for feature_val, feature_dict in v.items():\n",
    "                for class_label, frac_class in feature_dict.items():\n",
    "                    correlation_dict_avg[k][feature_val][class_label].append(frac_class)\n",
    "\n",
    "    # now take the averages\n",
    "    for k,v in correlation_dict_avg.items():\n",
    "        for feature_val, feature_dict in v.items():\n",
    "            for class_label, frac_class_arr in feature_dict.items():\n",
    "                correlation_dict_avg[k][feature_val][class_label] = np.mean(frac_class_arr)\n",
    "\n",
    "    return correlation_dict_avg\n",
    "\n",
    "\n",
    "\n",
    "def plot_cov_thresh_vs_acc_pos_ratio(x_all, y_all, x_control_all, num_folds, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs):\n",
    "\n",
    "\n",
    "    # very the covariance threshold using a range of decreasing multiplicative factors and see the tradeoffs between accuracy and fairness\n",
    "    it = 0.05\n",
    "    cov_range = np.arange(1.0, 0.0-it, -it).tolist()\n",
    "    if apply_accuracy_constraint == True:\n",
    "        if sep_constraint == False:\n",
    "            it = 0.1\n",
    "            cov_range = np.arange(0.0, 1.0 + it, it).tolist()\n",
    "        if sep_constraint == True:\n",
    "            cov_range =  [0,1,5,10,20,50,100,500,1000]\n",
    "\n",
    "    \n",
    "    positive_class_label = 1 # positive class is +1\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    positive_per_category = defaultdict(list) # for each category (male / female), the frac of positive\n",
    "\n",
    "    # first get the original values of covariance in the unconstrained classifier -- these original values are not needed for reverse constraint    \n",
    "    test_acc_arr, train_acc_arr, correlation_dict_test_arr, correlation_dict_train_arr, cov_dict_test_arr, cov_dict_train_arr = compute_cross_validation_error(x_all, y_all, x_control_all, num_folds, loss_function, 0, apply_accuracy_constraint, sep_constraint, sensitive_attrs, [{} for i in range(0,num_folds)], 0)\n",
    "\n",
    "    for c in cov_range:\n",
    "        print \"LOG: testing for multiplicative factor: %0.2f\" % c\n",
    "        sensitive_attrs_to_cov_original_arr_multiplied = []\n",
    "        for sensitive_attrs_to_cov_original in cov_dict_train_arr:\n",
    "            sensitive_attrs_to_cov_thresh = deepcopy(sensitive_attrs_to_cov_original)\n",
    "            for k in sensitive_attrs_to_cov_thresh.keys():\n",
    "                v = sensitive_attrs_to_cov_thresh[k]\n",
    "                if type(v) == type({}):\n",
    "                    for k1 in v.keys():\n",
    "                        v[k1] = v[k1] * c\n",
    "                else:\n",
    "                    sensitive_attrs_to_cov_thresh[k] = v * c\n",
    "            sensitive_attrs_to_cov_original_arr_multiplied.append(sensitive_attrs_to_cov_thresh)\n",
    "\n",
    "\n",
    "        test_acc_arr, train_acc_arr, correlation_dict_test_arr, correlation_dict_train_arr, cov_dict_test_arr, cov_dict_train_arr  = compute_cross_validation_error(x_all, y_all, x_control_all, num_folds, loss_function, apply_fairness_constraints, apply_accuracy_constraint, sep_constraint, sensitive_attrs, sensitive_attrs_to_cov_original_arr_multiplied, c)\n",
    "        test_acc.append(np.mean(test_acc_arr))\n",
    "\n",
    "\n",
    "        correlation_dict_train = get_avg_correlation_dict(correlation_dict_train_arr)\n",
    "        correlation_dict_test = get_avg_correlation_dict(correlation_dict_test_arr)\n",
    "        \n",
    "        # just plot the correlations for the first sensitive attr, the plotting can be extended for the other values, but as a proof of concept, we will jsut show for one\n",
    "        s = sensitive_attrs[0]    \n",
    "        \n",
    "        for k,v in correlation_dict_test[s].items():\n",
    "            if v.get(positive_class_label) is None:\n",
    "                positive_per_category[k].append(0.0)\n",
    "            else:\n",
    "                positive_per_category[k].append(v[positive_class_label])\n",
    "    \n",
    "    positive_per_category = dict(positive_per_category)\n",
    "    \n",
    "    p_rule_arr = (np.array(positive_per_category[0]) / np.array(positive_per_category[1])) * 100.0\n",
    "    \n",
    "\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    plt.plot(cov_range, positive_per_category[0], \"-o\" , color=\"green\", label = \"Protected\")\n",
    "    plt.plot(cov_range, positive_per_category[1], \"-o\", color=\"blue\", label = \"Non-protected\")\n",
    "    ax.set_xlim([min(cov_range), max(cov_range)])\n",
    "    plt.xlabel('Multiplicative loss factor')\n",
    "    plt.ylabel('Perc. in positive class')\n",
    "    if apply_accuracy_constraint == False:\n",
    "        plt.gca().invert_xaxis()\n",
    "        plt.xlabel('Multiplicative covariance factor (c)')\n",
    "    ax.legend()\n",
    "\n",
    "    ax = plt.subplot(2,1,2)\n",
    "    plt.scatter(p_rule_arr, test_acc, color=\"red\")\n",
    "    ax.set_xlim([min(p_rule_arr), max(max(p_rule_arr), 100)])\n",
    "    plt.xlabel('P% rule')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_line_coordinates(w, x1, x2):\n",
    "    y1 = (-w[0] - (w[1] * x1)) / w[2]\n",
    "    y2 = (-w[0] - (w[1] * x2)) / w[2]    \n",
    "    return y1,y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
