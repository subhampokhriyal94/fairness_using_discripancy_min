{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as lin\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#Assume the first r rows of a forms an orthonormal basis\n",
    "#Returns the projection of x onto the orthogonal complement of the rows of a\n",
    "#scaled to unit length\n",
    "def make_orthogonal(a,r,x):\n",
    "    if np.linalg.norm(x)<1e-8:\n",
    "        return None\n",
    "    if r==0:\n",
    "        return x/np.linalg.norm(x)\n",
    "    u = x\n",
    "    for j in range(0,int(r/100)):\n",
    "        u = u - a[range(j*100,(j+1)*100)].T @ (a[range(j*100,(j+1)*100)] @ u)\n",
    "    for j in range(int(r/100)*100,r):\n",
    "        u = u - np.inner(u,a[j]) * a[j]\n",
    "    norm = np.linalg.norm(u)\n",
    "    if norm < np.linalg.norm(x)/100:\n",
    "        return None\n",
    "    u = u/norm\n",
    "    return u\n",
    "\n",
    "def round_coloring(a,x,norm = np.inf, balanced=False):\n",
    "    start = time.time()\n",
    "    n = a.shape[1]\n",
    "    abs = np.absolute(x)\n",
    "    live = (abs < 1.0-1e-4)\n",
    "    #first sample each entry\n",
    "    samples = np.random.random_sample(n)\n",
    "    signs = np.ones(n)\n",
    "    signs[samples < (1.0-abs)/2.0] = -1\n",
    "    flipped = np.multiply(x,signs)\n",
    "    y = np.sign(flipped)\n",
    "    y[y==0]=1\n",
    "    #then try all assignments to the coordinates that were live\n",
    "    num_live = sum(live)\n",
    "    if num_live<=10:\n",
    "        live_indices = [i for i, x in enumerate(live) if x]\n",
    "        ay = a@y\n",
    "        sub_a = a[:,live_indices]\n",
    "        sub_y = y[live_indices]\n",
    "        sub_ay = sub_a @ sub_y\n",
    "        a_outside = ay - sub_ay\n",
    "        best_sub_y = sub_y\n",
    "        best_norm = np.linalg.norm(ay,ord=norm)\n",
    "        sign_flips = np.ones(num_live)\n",
    "        while True:\n",
    "            at = 0\n",
    "            while at<num_live and sign_flips[at]==-1:\n",
    "                sign_flips[at]=1\n",
    "                at = at+1\n",
    "            if at==num_live:\n",
    "                break\n",
    "            sign_flips[at]=-1\n",
    "            new_sub_y = np.multiply(sub_y,sign_flips)\n",
    "            new_sub_ay = sub_a @ new_sub_y\n",
    "            new_ay = a_outside + new_sub_ay\n",
    "            new_norm = np.linalg.norm(new_ay,ord=norm)\n",
    "            if new_norm < best_norm:\n",
    "                best_norm = new_norm\n",
    "                best_sub_y = new_sub_y\n",
    "        y[live_indices] = best_sub_y\n",
    "    #balance the vector in case we need to\n",
    "    if balanced:\n",
    "        while True:\n",
    "            toFlip = 1\n",
    "            if sum(y==1) < n/2:\n",
    "                toFlip = -1\n",
    "            ofToFlip = sum(y==toFlip)\n",
    "            needToFlip = int(ofToFlip-n/2)\n",
    "            if needToFlip==0:\n",
    "                break\n",
    "            listOfToFlip = [i for i, x in enumerate(y) if x==toFlip]\n",
    "            ay = a @ y\n",
    "            best_norm = 1e27\n",
    "            #try all single flips\n",
    "            best_to_flip = 0\n",
    "            for i in listOfToFlip:\n",
    "                col = a[:,i]\n",
    "                new_ay = ay - (2*col*y[i])\n",
    "                new_norm = np.linalg.norm(new_ay,ord=norm)\n",
    "                if new_norm < best_norm:\n",
    "                    best_norm = new_norm\n",
    "                    best_to_flip = i\n",
    "            y[best_to_flip] = -y[best_to_flip]\n",
    "    return y\n",
    "\n",
    "def to_square(a,x,balanced=False):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    if n<=m:\n",
    "        return x\n",
    "    live = n\n",
    "    orth = np.zeros((n,n))\n",
    "    is_live = np.ones(n)\n",
    "    num_orth = 0\n",
    "    for i in range(0,m):\n",
    "        p = make_orthogonal(orth,num_orth,a[i])\n",
    "        if not p is None:\n",
    "            orth[num_orth] = p\n",
    "            num_orth = num_orth + 1\n",
    "    if balanced:\n",
    "        all_ones = np.ones(n)\n",
    "        p = make_orthogonal(orth,num_orth,all_ones)\n",
    "        if np.linalg.norm(p) > 0.01:\n",
    "            orth[num_orth] = p\n",
    "            num_orth = num_orth + 1\n",
    "    while num_orth < n and sum(is_live) > 8:\n",
    "        #sample a random vector\n",
    "        g = np.random.randn(n)\n",
    "        #make it orthogonal to all in orth\n",
    "        gamma = make_orthogonal(orth,num_orth,g)\n",
    "        if gamma is None:\n",
    "            break\n",
    "        #set all that are not live to 0 for numerical stability\n",
    "        for i in range(0,n):\n",
    "            if not is_live[i]:\n",
    "                gamma[i] = 0\n",
    "        #find coord that freezes first\n",
    "        delta = 1e30\n",
    "        for i in range(0,n):\n",
    "            if is_live[i] and abs(gamma[i]) > 1e-7:\n",
    "                dist = 0\n",
    "                if gamma[i] * x[i] >= 0:\n",
    "                    dist = (1-abs(x[i]))/abs(gamma[i])\n",
    "                else:\n",
    "                    dist = (1+abs(x[i]))/abs(gamma[i])\n",
    "                if dist < delta:\n",
    "                    delta = dist\n",
    "        if delta > 1e25:\n",
    "            break\n",
    "        x = x + delta * gamma\n",
    "        for i in range(0,n):\n",
    "            if is_live[i] and abs(x[i]) >= 1-1e-6:\n",
    "                is_live[i] = 0\n",
    "                e = np.zeros(n)\n",
    "                e[i] = 1\n",
    "                p = make_orthogonal(orth,num_orth,e)\n",
    "                if not p is None:\n",
    "                    orth[num_orth] = p\n",
    "                    num_orth = num_orth+1\n",
    "                    if num_orth>=n:\n",
    "                        break\n",
    "    return x\n",
    "\n",
    "def partial_color(a,x,norm=np.inf,balanced=False):\n",
    "    if norm==np.inf:\n",
    "        return partial_infty_color(a,x,balanced)\n",
    "    if norm==2:\n",
    "        return partial_l2_color(a,x,balanced)\n",
    "\n",
    "def partial_l2_color(a, x, balanced=False):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    delta=1e-5\n",
    "\n",
    "    #count number of live coordinates\n",
    "    abs_x = np.absolute(x)\n",
    "    is_live = (abs_x < 1.0-delta)\n",
    "    initial_is_live = is_live.copy()\n",
    "    live = is_live.sum()\n",
    "    if live<8: \n",
    "        return True\n",
    "    initial_live=live\n",
    "    #extract the live coordinates and columns\n",
    "    y = x[initial_is_live]\n",
    "    b = a[:,initial_is_live]\n",
    "    #compute eigenvectors of bTb\n",
    "    bTb = b.T @ b\n",
    "    w, v = lin.eigh(bTb)\n",
    "    num_iters = 0\n",
    "    was_live = np.ones(initial_live,dtype=bool)\n",
    "    num_frozen = 0\n",
    "    orth = np.zeros((initial_live,initial_live))\n",
    "    num_orth = 0\n",
    "    to_add = v[:,range(initial_live-int(initial_live/2), initial_live)].T\n",
    "    orth[range(0,to_add.shape[0])] = to_add\n",
    "    num_orth = to_add.shape[0]\n",
    "    if balanced:\n",
    "        ones = np.ones(initial_live)\n",
    "        ones = make_orthogonal(orth,num_orth,ones)\n",
    "        if not ones is None:\n",
    "            orth[num_orth] = ones\n",
    "            num_orth = num_orth+1\n",
    "    while int((live*3/2)) > initial_live:\n",
    "        #will have at most 1/3 * initial_live that are frozen\n",
    "        abs_y = np.absolute(y)\n",
    "        #start by freezing new frozen coordinates\n",
    "        is_live = (abs_y < 1.0-delta)\n",
    "        diff = is_live!=was_live\n",
    "        num_diff = diff.sum()\n",
    "        if num_diff>0:\n",
    "            for i in range(0,initial_live):\n",
    "                if diff[i]:\n",
    "                    e = np.zeros(initial_live)\n",
    "                    e[i] = 1\n",
    "                    p = make_orthogonal(orth,num_orth,e)\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_frozen = num_frozen + 1\n",
    "            was_live = is_live\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        num_iters = num_iters+1\n",
    "        ax = a @ x\n",
    "        #sample a random vector\n",
    "        g = np.random.randn(initial_live)\n",
    "        #make it orthogonal to all in orth\n",
    "        gamma = make_orthogonal(orth,num_orth,g)\n",
    "        if gamma is None:\n",
    "            break\n",
    "        #set coords to zero where not live, due to numerical stability\n",
    "        for i in range(0,initial_live):\n",
    "            if not is_live[i]:\n",
    "                gamma[i] = 0\n",
    "        if np.linalg.norm(gamma,ord=np.inf)==0:\n",
    "            break\n",
    "        if np.inner(ax,b @ gamma) > 0:\n",
    "            gamma = -gamma\n",
    "        coord_mult = np.multiply(gamma,y)\n",
    "        val = np.where(coord_mult < 0, (1+abs(y))/(1e-27+abs(gamma)), (1-abs(y))/(1e-27 + abs(gamma)))\n",
    "        val = np.where(is_live, val, 1e27)\n",
    "        z = min(val)\n",
    "        y = y + z*gamma\n",
    "        x[initial_is_live] = y\n",
    "        new_abs_y = np.absolute(y)\n",
    "        is_live = (new_abs_y < 1.0-delta)\n",
    "        live = is_live.sum()\n",
    "    return False\n",
    "\n",
    "def partial_infty_color(a, x, balanced=False):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    delta=1e-5\n",
    "\n",
    "    #count number of live coordinates\n",
    "    abs_x = np.absolute(x)\n",
    "    is_live = (abs_x < 1.0-delta)\n",
    "    initial_is_live = is_live.copy()\n",
    "    live = is_live.sum()\n",
    "    if live<8: \n",
    "        return True\n",
    "    initial_live=live\n",
    "    #extract the live coordinates and columns\n",
    "    y = x[initial_is_live]\n",
    "    b = a[:,initial_is_live]\n",
    "    num_iters = 0\n",
    "    was_live = np.ones(initial_live,dtype=bool)\n",
    "    was_small = np.ones(m,dtype=bool)\n",
    "    orth = np.zeros((initial_live,initial_live))\n",
    "    num_orth = 0\n",
    "    if balanced:\n",
    "        ones = np.ones(initial_live)\n",
    "        ones = ones/np.sqrt(initial_live)\n",
    "        orth[0] = ones\n",
    "        num_orth = num_orth+1\n",
    "    num_frozen = 0\n",
    "    num_big = 0\n",
    "    num_initial = 0\n",
    "    while int((live*5)/4) > initial_live:\n",
    "        #will have at most 1/3 * initial_live that are frozen\n",
    "        #freeze up to 1/3 largest coords\n",
    "        abs_y = np.absolute(y)\n",
    "        #start by freezing new frozen coordinates\n",
    "        is_live = (abs_y < 1.0-delta)\n",
    "        diff = is_live!=was_live\n",
    "        num_diff = diff.sum()\n",
    "        if num_diff>0:\n",
    "            for i in range(0,initial_live):\n",
    "                if diff[i]:\n",
    "                    e = np.zeros(initial_live)\n",
    "                    e[i] = 1\n",
    "                    p = make_orthogonal(orth,num_orth,e)\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_frozen = num_frozen + 1\n",
    "            was_live = is_live\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        #may freeze same number of rows based on abs value\n",
    "        num_iters = num_iters+1\n",
    "        ax = a @ x\n",
    "        abs_ax = np.absolute(ax)\n",
    "        if num_initial < initial_live/4:\n",
    "            sorted_indices = np.argsort(-abs_ax)\n",
    "            for i in range(0, m):\n",
    "                if was_small[sorted_indices[i]]:\n",
    "                    p = make_orthogonal(orth,num_orth,b[sorted_indices[i]])\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_initial = num_initial + 1\n",
    "                    was_small[sorted_indices[i]] = False\n",
    "                    if num_initial >= initial_live/4:\n",
    "                        break\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        if num_big < num_frozen:\n",
    "            sorted_indices = np.argsort(-abs_ax)\n",
    "            for i in range(0,m):\n",
    "                if was_small[sorted_indices[i]]:\n",
    "                    p = make_orthogonal(orth,num_orth,b[sorted_indices[i]])\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_big = num_big + 1\n",
    "                    was_small[sorted_indices[i]] = False\n",
    "                    if num_big >= num_frozen:\n",
    "                        break\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        #sample a random vector\n",
    "        g = np.random.randn(initial_live)\n",
    "        #make it orthogonal to all in orth\n",
    "        gamma = make_orthogonal(orth,num_orth,g)\n",
    "        if gamma is None:\n",
    "            break\n",
    "        #set coords to zero where not live, due to numerical stability\n",
    "        for i in range(0,initial_live):\n",
    "            if not is_live[i]:\n",
    "                gamma[i] = 0\n",
    "        if np.linalg.norm(gamma,ord=np.inf)==0:\n",
    "            break\n",
    "        if np.inner(ax,b @ gamma) > 0:\n",
    "            gamma = -gamma\n",
    "        coord_mult = np.multiply(gamma,y)\n",
    "        val = np.where(coord_mult < 0, (1+abs(y))/(1e-27+abs(gamma)), (1-abs(y))/(1e-27 + abs(gamma)))\n",
    "        val = np.where(is_live, val, 1e27)\n",
    "        z = min(val)\n",
    "        y = y + z*gamma\n",
    "        x[initial_is_live] = y\n",
    "        new_abs_y = np.absolute(y)\n",
    "        is_live = (new_abs_y < 1.0-delta)\n",
    "        live = is_live.sum()\n",
    "    return False\n",
    "\n",
    "\n",
    "def local_improvements(a,x,time_limit,norm=np.inf, balanced=False):\n",
    "    ax = a @ x\n",
    "    best_norm = np.linalg.norm(ax,ord=norm)\n",
    "    start_time = time.time()\n",
    "    num_flip = min(7,len(x))\n",
    "    if balanced and num_flip%2==1:\n",
    "        num_flip = num_flip + 1\n",
    "    iters = 0\n",
    "    while True:\n",
    "        iters = iters+1\n",
    "        #Try flipping random coords\n",
    "        for iteration in range(0,a.shape[1]):\n",
    "            sampled_coords = np.random.randint(0,a.shape[1],num_flip)\n",
    "            sampled_coords = np.sort(sampled_coords)\n",
    "            allDistinct=True\n",
    "            for i in range(0,num_flip-1):\n",
    "                if sampled_coords[i]==sampled_coords[i+1]:\n",
    "                    allDistinct=False\n",
    "            if not allDistinct:\n",
    "                continue\n",
    "            if balanced:\n",
    "                #check equal num of +1 and -1\n",
    "                sum_is=0\n",
    "                for i in range(0,num_flip):\n",
    "                    sum_is = sum_is + x[sampled_coords[i]]\n",
    "                if sum_is!=0:\n",
    "                    continue\n",
    "            subcols = a[:,sampled_coords]\n",
    "            subx = [x[index] for index in sampled_coords]\n",
    "            bx = ax - 2*(subcols @ subx)\n",
    "            the_norm = np.linalg.norm(bx,ord=norm)\n",
    "            if the_norm<best_norm:\n",
    "                best_norm = the_norm\n",
    "                for i in sampled_coords:\n",
    "                    x[i] = -x[i]\n",
    "                ax = bx\n",
    "        if time.time()-start_time > time_limit:\n",
    "            break \n",
    "    return x\n",
    "\n",
    "def basic_local_search(a,x,norm,balanced=False):\n",
    "    ax = a@x\n",
    "    best_norm = np.linalg.norm(ax,ord=norm)\n",
    "    improved=True\n",
    "    while improved:\n",
    "        improved=False\n",
    "        #Try flipping single coords\n",
    "        for i in range(0,a.shape[1]):\n",
    "            flipped = ax - 2*x[i]*a[:,i]\n",
    "            if np.linalg.norm(flipped, ord=norm) < best_norm:\n",
    "                if balanced:\n",
    "                    #must find one to swap with\n",
    "                    for j in range(0,a.shape[1]):\n",
    "                        if x[i]==x[j]:\n",
    "                            continue\n",
    "                        final_flipped = flipped - 2*x[j]*a[:,j]\n",
    "                        if np.linalg.norm(final_flipped,ord=norm) < best_norm:\n",
    "                            ax = final_flipped\n",
    "                            x[i] = -x[i]\n",
    "                            x[j] = -x[j]\n",
    "                            best_norm = np.linalg.norm(final_flipped,ord=norm)\n",
    "                            improved=True\n",
    "                            break\n",
    "                else:\n",
    "                    ax = flipped\n",
    "                    x[i] = -x[i]\n",
    "                    best_norm = np.linalg.norm(flipped,ord=norm)\n",
    "                    improved=True\n",
    "    return x\n",
    "\n",
    "def greedy(a,norm,balanced=False):\n",
    "    x = np.zeros(a.shape[1])\n",
    "    if balanced:\n",
    "        so_far = np.zeros(a.shape[0])\n",
    "        for i in range(0,a.shape[1]):\n",
    "            if i%2==1:\n",
    "                continue\n",
    "            test = so_far + a[:,i]\n",
    "            test_minus = so_far - a[:,i]\n",
    "            if i<a.shape[1]-1:\n",
    "                test = test - a[:,i+1]\n",
    "                test_minus = test_minus + a[:,i+1]\n",
    "            if np.linalg.norm(test,ord=norm) < np.linalg.norm(test_minus,ord=norm):\n",
    "                x[i] = 1\n",
    "                if i<a.shape[1]-1:\n",
    "                    x[i+1]=-1\n",
    "            else:\n",
    "                x[i] = -1\n",
    "                if i<a.shape[1]-1:\n",
    "                    x[i+1] = 1\n",
    "    else:\n",
    "        x[0] = 1\n",
    "        so_far = a[:,0]\n",
    "        for i in range(1,a.shape[1]):\n",
    "            test = so_far + a[:,i]\n",
    "            test_minus = so_far - a[:,i]\n",
    "            if np.linalg.norm(test,ord=norm) <  np.linalg.norm(test_minus,ord=norm):\n",
    "                x[i] = 1\n",
    "            else:\n",
    "                x[i] = -1\n",
    "            so_far = so_far + x[i]*a[:,i]\n",
    "    return x\n",
    "\n",
    "def discrepancy_minimize(a, norm=np.inf, balanced=False, local_search=0.3):\n",
    "    n = a.shape[1]\n",
    "    x = np.zeros(n)\n",
    "    start_time = time.time()\n",
    "    x = to_square(a,x,balanced)\n",
    "    while not partial_color(a,x, norm, balanced):\n",
    "        pass\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    y = round_coloring(a,x,norm, balanced)\n",
    "    y = basic_local_search(a,y,norm,balanced)\n",
    "    #check if greedy approach is better\n",
    "    g = greedy(a,norm,balanced)\n",
    "    g = basic_local_search(a,g,norm,balanced)\n",
    "    if np.linalg.norm(a@g,ord=norm) < np.linalg.norm(a@y, ord=norm):\n",
    "        y = g\n",
    "    y = local_improvements(a,y, elapsed*local_search, norm, balanced)\n",
    "    y = basic_local_search(a,y,norm,balanced)\n",
    "    total_elapsed = time.time()-start_time\n",
    "    #make sure we return an int array, not floating\n",
    "    z = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if y[i]==-1:\n",
    "            z[i]=-1\n",
    "        else:\n",
    "            z[i]=1\n",
    "    return z\n",
    "\n",
    "def Com(a):\n",
    "    n = a.shape[0]\n",
    "    b = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if a[i] == 1:\n",
    "            b[i]= 0\n",
    "        else:\n",
    "            b[i]= 1\n",
    "    return b   \n",
    "\n",
    "#python\n",
    "\n",
    "def FindDisc(a, v):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    disc = 0\n",
    "    for i in range(m):\n",
    "        newdisc = 0\n",
    "        for j in range(n):\n",
    "            newdisc = newdisc + v[j]\n",
    "            #print(newdisc)\n",
    "        modisc = abs(newdisc)\n",
    "        if modisc >= disc:\n",
    "            disc = modisc\n",
    "    return disc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################3ALL Fair#################3\n",
    "from random import *\n",
    "def fair(x,a,b,alpha,R):\n",
    "    #x-actual a=kesper b=classifier\n",
    "    \n",
    "    a_acc=0\n",
    "    b_acc=0\n",
    "    f_acc=0\n",
    "    n= x.shape[0]\n",
    "    f= np.zeros(n) \n",
    "    count=0\n",
    "    acc=0\n",
    "    for i in range(n):\n",
    "        z=random()\n",
    "        if z < alpha:\n",
    "            f[i]= a[i] \n",
    "            count=count+1\n",
    "        else:\n",
    "            f[i]= b[i]\n",
    "                    \n",
    "        \n",
    "    for i in range(n):\n",
    "         if a[i] == x[i]:\n",
    "                a_acc=a_acc+1\n",
    "    for i in range(n):\n",
    "         if b[i] == x[i]:\n",
    "                b_acc=b_acc+1\n",
    "    for i in range(n):\n",
    "         if f[i] == x[i]:\n",
    "                f_acc=f_acc+1\n",
    "\n",
    "    a_acc_percent=a_acc/n            \n",
    "    b_acc_percent=b_acc/n  \n",
    "    f_acc_percent=f_acc/n  \n",
    "     \n",
    "    count1=0\n",
    "    count2=0\n",
    "    for i in range(R.shape[1]):\n",
    "        if(R[0,i]==1):\n",
    "            if f[i]==1:\n",
    "                  count1+=1\n",
    "        else:\n",
    "            if f[i]==1:\n",
    "                count2+=1\n",
    "            \n",
    "    ratio=float(count1/count2)  \n",
    "#############################################################\n",
    "    \n",
    "#     print(f)\n",
    "#     print(x)\n",
    "#     print(b)\n",
    "#     print(a_acc_percent,b_acc_percent)\n",
    "      \n",
    "   \n",
    "    #kasper svm final ratio\n",
    "    return a_acc_percent,b_acc_percent,f_acc_percent,ratio\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def ploting(y_train,u1,y_1,R):\n",
    "    alpha1_l=[]\n",
    "    c1_l=[]\n",
    "    ratio_l=[]\n",
    "    \n",
    "    ####### plot################   \n",
    "    for alpha in [0,0.1, 0.2, 0.3 ,0.4,0.5, 0.6,0.7,0.8,0.9,1]:\n",
    "        a,b,c,ratio  = fair(y_train,u1,y_1,alpha,R)\n",
    "        ratio_l.append(ratio)\n",
    "        alpha1_l.append(alpha)\n",
    "        c1_l.append(c)\n",
    "    print(c1_l)\n",
    "    plt.plot( alpha1_l, c1_l, 'ro')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('Fairness(Alpha)')\n",
    "    plt.ylabel('Train Accuracy')\n",
    "    plt.title('Accuracy V/S Fairness tradeoff for ProPublica dataset')\n",
    "    alpha = np.linspace(0, 1, 10) \n",
    "    y = alpha*(min(c1_l) - max(c1_l)) + max(c1_l)\n",
    "    # fig = plt.figure(figsize = (10, 5)) \n",
    "    plt.plot(alpha, y) \n",
    "    plt.legend([\"Experimental\", \"Theoretical\"])\n",
    "    plt.show() \n",
    "#   print(min(c1_l) , max(c1_l))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(\"ratio------------------\")\n",
    "#     alpha1=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "#     plt.plot( alpha1, ratio, 'ro')\n",
    "#     plt.axis([0, 1, 0, 20])\n",
    "#     plt.xlabel('Fairness(Alpha)')\n",
    "#     plt.ylabel('Male/Female Ratio')\n",
    "#     plt.title('Variation of bias w.r.t Fairness')\n",
    "#     alpha = np.linspace(0, 1, 10)  \n",
    "#     plt.show() \n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProPub2():\n",
    "    filename = '13ProPublica_violent_racidivism.csv'\n",
    "\n",
    "    d2 = pd.read_csv(filename)\n",
    "\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:2806,'sex']\n",
    "    x2 = d2.loc[0:2806,'race']\n",
    "    n = x1.shape[0]\n",
    "    R = np.zeros((7, n), dtype = int)\n",
    "    r = np.zeros((1, n), dtype = int)\n",
    "\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'Male':\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] == 'African-American':\n",
    "            R[2][i]= 1\n",
    "        elif x2[i] == 'Caucasian':\n",
    "            R[3][i]= 1\n",
    "        elif x2[i] == 'Hispanic':\n",
    "            R[4][i]= 1\n",
    "        elif x2[i] == 'Asia':\n",
    "            R[5][i]= 1\n",
    "        else:\n",
    "            R[6][i]= 1\n",
    "\n",
    "    racidivism_kasper = discrepancy_minimize(R, norm=np.inf, balanced=False, local_search=0.3)\n",
    "    r = FindDisc(R,racidivism_kasper)\n",
    "    \n",
    "    ##############################################\n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    for i in range(racidivism_kasper.shape[0]):\n",
    "        if racidivism_kasper[i]==1:\n",
    "            racidivism1[i]=0 \n",
    "            racidivism2[i]=1\n",
    "        else:\n",
    "            racidivism1[i]=1\n",
    "            racidivism2[i]=0\n",
    "\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2  \n",
    "#     print(racidivismu1)\n",
    "#     print(racidivismu2)   \n",
    "    print(\"discripency is:\")\n",
    "    print(r)\n",
    "    print(r,math.sqrt(n*math.log2(m)))\n",
    "    return racidivismu1,racidivismu2,R\n",
    "\n",
    "def ProPub2_gender():\n",
    "    filename = '13ProPublica_violent_racidivism.csv'\n",
    "\n",
    "    d2 = pd.read_csv(filename)\n",
    "\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:2806,'sex']\n",
    "    x2 = d2.loc[0:2806,'race']\n",
    "    n = x1.shape[0]\n",
    "    R = np.zeros((2, n), dtype = int)\n",
    "    r = np.zeros((1, n), dtype = int)\n",
    "\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'Male':\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "\n",
    "#     for i in range(n):\n",
    "#         if x2[i] == 'African-American':\n",
    "#             R[2][i]= 1\n",
    "#         elif x2[i] == 'Caucasian':\n",
    "#             R[3][i]= 1\n",
    "#         elif x2[i] == 'Hispanic':\n",
    "#             R[4][i]= 1\n",
    "#         elif x2[i] == 'Asia':\n",
    "#             R[5][i]= 1\n",
    "#         else:\n",
    "#             R[6][i]= 1\n",
    "\n",
    "\n",
    "    racidivism_kasper = discrepancy_minimize(R, norm=np.inf, balanced=False, local_search=0.3)\n",
    "    r = FindDisc(R,racidivism_kasper)\n",
    "    print(r)\n",
    "    ##############################################\n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    for i in range(racidivism_kasper.shape[0]):\n",
    "        if racidivism_kasper[i]==1:\n",
    "            racidivism1[i]=1\n",
    "            racidivism2[i]=0\n",
    "        else:\n",
    "            racidivism1[i]=0\n",
    "            racidivism2[i]=1\n",
    "\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2  \n",
    "#     print(racidivismu1)\n",
    "#     print(racidivismu2)   \n",
    "#     print(r,math.sqrt(n*math.log2(m)))\n",
    "    return racidivismu1,racidivismu2,R\n",
    "def ProPub2_race():\n",
    "    filename = '13ProPublica_violent_racidivism.csv'\n",
    "\n",
    "    d2 = pd.read_csv(filename)\n",
    "\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:2806,'sex']\n",
    "    x2 = d2.loc[0:2806,'race']\n",
    "    n = x1.shape[0]\n",
    "    R = np.zeros((5, n), dtype = int)\n",
    "    r = np.zeros((1, n), dtype = int)\n",
    "\n",
    "#     for i in range(n):\n",
    "#         if x1[i] == 'Male':\n",
    "#             R[0][i]= 1\n",
    "#         else:\n",
    "#             R[1][i]= 1\n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] == 'African-American':\n",
    "            R[0][i]= 1\n",
    "        elif x2[i] == 'Caucasian':\n",
    "            R[1][i]= 1\n",
    "        elif x2[i] == 'Hispanic':\n",
    "            R[2][i]= 1\n",
    "        elif x2[i] == 'Asia':\n",
    "            R[3][i]= 1\n",
    "        else:\n",
    "            R[4][i]= 1\n",
    "\n",
    "\n",
    "    racidivism_kasper = discrepancy_minimize(R, norm=np.inf, balanced=False, local_search=0.3)\n",
    "    r = FindDisc(R,racidivism_kasper)\n",
    "    print(r)\n",
    "    ##############################################\n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    for i in range(racidivism_kasper.shape[0]):\n",
    "        if racidivism_kasper[i]==1:\n",
    "            racidivism1[i]=1 \n",
    "            racidivism2[i]=0\n",
    "        else:\n",
    "            racidivism1[i]=0\n",
    "            racidivism2[i]=1\n",
    "\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2  \n",
    "#     print(racidivismu1)\n",
    "#     print(racidivismu2)   \n",
    "#     print(r,math.sqrt(n*math.log2(m)))\n",
    "    return racidivismu1,racidivismu2,R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "def ProPub2_svm():\n",
    "    ###############2Propublica#####################\n",
    "    # This Python 3 environment comes with many helpful analytics librarie\n",
    "\n",
    "    # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "    # For example, here's several helpful packages to load in \n",
    "\n",
    "   \n",
    "    print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "    # Any results you write to the current directory are saved as output.\n",
    "    #Reading data from CSV file\n",
    "    df = pd.read_csv('../input/13ProPublica_violent_racidivism.csv')\n",
    "    df=df.drop(columns=['age_cat','c_charge_desc'])\n",
    "\n",
    "    df1 = df.copy()\n",
    "    df1 = pd.get_dummies(df1, columns=['sex','race','c_charge_degree','score_text','sex-race'], prefix = ['sex','race','ccd','st','sr'])\n",
    "    print(df1.loc[:,'two_year_recid'])\n",
    "    df1['2_year_racidivism'] = df1.loc[:,'two_year_recid']\n",
    "    df1=df1.drop(columns=['two_year_recid'])\n",
    "    print(df1.head())\n",
    "    print(df1.shape[1])\n",
    "\n",
    "    #Defining data and label\n",
    "    X = df1.iloc[:, 0:29]\n",
    "    y = df1.iloc[:, 30]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0,shuffle=False) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "\n",
    "    #Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train_std, y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test_std, y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    y_1=svm.predict(X_train_std)\n",
    "    print(y_1)\n",
    "\n",
    "    # print(y_1[2:3])\n",
    "    # print(y_1[3:4])\n",
    "    # print(y_1[4:5])\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #      print(y_1[i])\n",
    "\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "    # print(y_train)\n",
    "\n",
    "    # y_train.to_numpy()\n",
    "\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #     print(y_train[i])\n",
    "\n",
    "    ###############################################\n",
    "    print('####Change to colors###############################################')\n",
    "    count=0\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if y_1[i] == y_train[i]:\n",
    "            count=count+1\n",
    "    # print(count)    \n",
    "\n",
    "    # y_trainx=np.zeros((1,X_train.shape[0]),dtype= int)\n",
    "\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #     if y_train[i]==1:\n",
    "    #         y_trainx[i]=-1\n",
    "    #     else:\n",
    "    #         y_trainx[i]=1\n",
    "\n",
    "\n",
    "\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #     if y_1[i]==1:\n",
    "    #         y_1x[i]=-1\n",
    "    #     else:\n",
    "    #         y_1x[i]=1\n",
    "\n",
    "\n",
    "\n",
    "    # print('####Test###############################################')\n",
    "    # y_2=svm.predict(X_test_std)\n",
    "    return y_1,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#run for all ProPub2\n",
    "# u1,u2,R= ProPub2()\n",
    "# y_1,y_train=ProPub2_svm()\n",
    "# ploting(y_train,u1,y_1,R)\n",
    "#\n",
    "\n",
    "u1,u2,R= ProPub2()\n",
    "y_1,y_train=ProPub2_svm()\n",
    "ploting(y_train,u2,y_1,R)\n",
    "#[0.8692554328464553, 0.8375489846811542, 0.791948699679373, 0.7613110081938013, 0.7249732810830067, 0.6854292839330246, 0.6398289989312433, 0.6059850374064838, 0.5781973637335234, 0.5418596366227288, 0.5005343783398646]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u1,u2,R= ProPub2_gender()\n",
    "# y_1,y_train=ProPub2_svm()\n",
    "# ploting(y_train,u1,y_1,R)\n",
    "\n",
    "# u1,u2,R= ProPub2_gender()\n",
    "# y_1,y_train=ProPub2_svm()\n",
    "# ploting(y_train,u2,y_1,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u1,u2,R= ProPub2_race()\n",
    "# y_1,y_train=ProPub2_svm()\n",
    "# ploting(y_train,u1,y_1,R)\n",
    "\n",
    "# u1,u2,R= ProPub2_race()\n",
    "# y_1,y_train=ProPub2_svm()\n",
    "# ploting(y_train,u2,y_1,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "\n",
    "y_1,y_train=ProPub2_svm()\n",
    "maxi=0\n",
    "acc1_l=[]\n",
    "acc2_l=[]\n",
    "epsilon_l=[]\n",
    "for eps in range(0,2800,100) :\n",
    "    count1=0\n",
    "    count2=0\n",
    "    u1,u2,R=min_max_lp_all(eps)\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j]):\n",
    "                count1+=1\n",
    "    acc1=float(count1/y_train.shape[0])        \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j]):\n",
    "                count2+=1\n",
    "    acc2=float(count2/y_train.shape[0])        \n",
    "    epsilon_l.append(eps)\n",
    "    acc2_l.append(acc2)\n",
    "    acc1_l.append(acc1)\n",
    "    print(acc1,acc2)   \n",
    "print(acc1_l)     \n",
    "print(acc2_l)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# y_1,y_train=ProPub2_svm()\n",
    "# u1,u2,R=min_max_lp_all()\n",
    "# ploting(y_train,u1,y_1,R)\n",
    "#x-actual a=min_max_lp_color b=classifier R\n",
    "#[0.8692554328464553, 0.8268614178838618, 0.7905236907730673, 0.7595297470609191, 0.7085856786604916, 0.6740292126825793, 0.6398289989312433, 0.5970787317420734, 0.560741004631279, 0.526540790879943, 0.4880655504096901]\n",
    "\n",
    "# y_1,y_train=ProPub2_svm()\n",
    "# u1,u2,R=min_max_lp_all()\n",
    "# ploting(y_train,u2,y_1,R)\n",
    "#x-actual a=min_max_lp_color b=classifier R\n",
    "#[0.8692554328464553, 0.8307801923762024, 0.7951549697185607, 0.7655860349127181, 0.7185607410046313, 0.6911293195582472, 0.6622728892055575, 0.6177413608835055, 0.5789098681866761, 0.5457784111150694, 0.5069469184182401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROPUBLICA MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all():\n",
    "    filename = '13ProPublica_violent_racidivism.csv'\n",
    "\n",
    "    d2 = pd.read_csv(filename)\n",
    "\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:2806,'sex']\n",
    "    x2 = d2.loc[0:2806,'race']\n",
    "    n = x1.shape[0]\n",
    "    R = np.zeros((7, n), dtype = int)\n",
    "    r = np.zeros((1, n), dtype = int)\n",
    "\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'Male':\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] == 'African-American':\n",
    "            R[2][i]= 1\n",
    "        elif x2[i] == 'Caucasian':\n",
    "            R[3][i]= 1\n",
    "        elif x2[i] == 'Hispanic':\n",
    "            R[4][i]= 1\n",
    "        elif x2[i] == 'Asia':\n",
    "            R[5][i]= 1\n",
    "        else:\n",
    "            R[6][i]= 1\n",
    "\n",
    "        m=R.shape[0]\n",
    "        n=R.shape[1] \n",
    "        # Create a LP Minimization problem \n",
    "        Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "        print(range(n)) \n",
    "        #X[n]=z() n last value of X\n",
    "                \n",
    "        X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "        #X[]=0 to n-1\n",
    "\n",
    "        for i in range(n):\n",
    "            var=str(i)\n",
    "            X[i]=p.LpVariable(var,0,1,cat='Integer')\n",
    "        X[n] =  p.LpVariable(\"z\",lowBound=0)\n",
    "\n",
    "        #########objective function#####################\n",
    "        Lp_prob += X[n] \n",
    "\n",
    "        ###############################################\n",
    "        \n",
    "        ##############constraint#################\n",
    "        for i in range(2*m):\n",
    "            if i<m:\n",
    "                Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "            else:        \n",
    "                Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "\n",
    "      \n",
    "             \n",
    "        #####################################\n",
    "        status = Lp_prob.solve()   # Solver \n",
    "        print(p.LpStatus[status]) \n",
    "        print(\"discripency is:\")\n",
    "        print(p.value(Lp_prob.objective))  # The solution status \n",
    "        racidivism1={}\n",
    "        racidivism2={}\n",
    "        # # Printing the final solution\n",
    "        print(X)\n",
    "        for i in range(n):\n",
    "            if(p.value(X[i])==0):\n",
    "                racidivism1[i]=1 \n",
    "                racidivism2[i]=0\n",
    "            else:\n",
    "                racidivism1[i]=0\n",
    "                racidivism2[i]=1\n",
    "        racidivismu1=racidivism1  \n",
    "        racidivismu2=racidivism2    \n",
    "         \n",
    "        return racidivismu1,racidivismu2,R    \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "##IMP2---------proportion-----------------##\n",
    "##################################################################\n",
    "##PROPUBLICA MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all(eps):\n",
    "        filename = '13ProPublica_violent_racidivism.csv'\n",
    "        d2 = pd.read_csv(filename)\n",
    "        # n = d2.shape[0]\n",
    "        m= d2.shape[1]\n",
    "        x1 = d2.loc[0:2806,'sex']\n",
    "        x2 = d2.loc[0:2806,'race']\n",
    "        n=x1.shape[0]\n",
    "        R = np.zeros((7, n), dtype = int)\n",
    "        for i in range(n):\n",
    "            if x1[i] == 'Male':\n",
    "                R[0][i]= 1\n",
    "            else:\n",
    "                R[1][i]= 1\n",
    "\n",
    "        for i in range(n):\n",
    "            if x2[i] == 'African-American':\n",
    "                R[2][i]= 1\n",
    "            elif x2[i] == 'Caucasian':\n",
    "                R[3][i]= 1\n",
    "            elif x2[i] == 'Hispanic':\n",
    "                R[4][i]= 1\n",
    "            elif x2[i] == 'Asia':\n",
    "                R[5][i]= 1\n",
    "            else:\n",
    "                R[6][i]= 1\n",
    "        \n",
    "        m=R.shape[0]\n",
    "        n=R.shape[1] \n",
    "        \n",
    "        # Create a LP Minimization problem \n",
    "        Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "#       print(range(n)) \n",
    "        #X[n]=z() n last value of X\n",
    "                \n",
    "        X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "        #X[]=0 to n-1\n",
    "\n",
    "        for i in range(n):\n",
    "            var=str(i)\n",
    "            X[i]=p.LpVariable(var,0,1,cat='Integer')\n",
    "        X[n] =  p.LpVariable(\"z\",lowBound=0)\n",
    "\n",
    "        #########objective function#####################\n",
    "        Lp_prob += X[n] \n",
    "\n",
    "        ###############################################\n",
    "\n",
    "        ##############constraint#################\n",
    "        for i in range(2*m):\n",
    "            if i<m:\n",
    "                Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "            else:        \n",
    "                Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "\n",
    "#         Lp_prob += X[n] >= 0.001*n\n",
    "#         Lp_prob += X[n] <= 0.05*n\n",
    "          \n",
    "        Lp_prob += X[n] >= eps\n",
    "        Lp_prob += X[n] <=2800\n",
    "        #####################################\n",
    "        status = Lp_prob.solve()   # Solver \n",
    "#         print(p.LpStatus[status]) \n",
    "#         print(\"discripency is:\")\n",
    "#         print(p.value(Lp_prob.objective))  # The solution status \n",
    "        racidivism1={}\n",
    "        racidivism2={}\n",
    "        # # Printing the final solution\n",
    "        print(X)\n",
    "        for i in range(n):\n",
    "            if(p.value(X[i])==0):\n",
    "                racidivism1[i]=1 \n",
    "                racidivism2[i]=0\n",
    "            else:\n",
    "                racidivism1[i]=0\n",
    "                racidivism2[i]=1\n",
    "        racidivismu1=racidivism1  \n",
    "        racidivismu2=racidivism2    \n",
    "        \n",
    "   \n",
    "        \n",
    "        \n",
    "         \n",
    "        return racidivismu1,racidivismu2,R    \n",
    "# print(p.value(Lp_prob.objective))   \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# u1,u2,R=min_sum_lp_all()\n",
    "# y_1,y_train=ProPub2_svm()\n",
    "# a=ploting(y_train,u1,y_1,R)\n",
    "\n",
    "\n",
    "u1,u2,R=min_sum_lp_all()\n",
    "y_1,y_train=ProPub2_svm()\n",
    "ploting(y_train,u2,y_1,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import the library pulp as p \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "\n",
    "def min_sum_lp_all():\n",
    "    filename = '13ProPublica_violent_racidivism.csv'\n",
    "    d2 = pd.read_csv(filename)\n",
    "    # n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:2806,'sex']\n",
    "    x2 = d2.loc[0:2806,'race']\n",
    "    n=x1.shape[0]\n",
    "    R = np.zeros((7, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'Male':\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] == 'African-American':\n",
    "            R[2][i]= 1\n",
    "        elif x2[i] == 'Caucasian':\n",
    "            R[3][i]= 1\n",
    "        elif x2[i] == 'Hispanic':\n",
    "            R[4][i]= 1\n",
    "        elif x2[i] == 'Asia':\n",
    "            R[5][i]= 1\n",
    "        else:\n",
    "            R[6][i]= 1\n",
    "\n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "        \n",
    "    # Create a LP Minimization problem \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "\n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "\n",
    "    X=np.zeros(n+m,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n+m):\n",
    "        var=str(i)\n",
    "        if(i<n):##n\n",
    "            X[i]=p.LpVariable(var,lowBound=0,upBound=1)\n",
    "        else:##m\n",
    "            X[i] =  p.LpVariable(var,lowBound=0,upBound=n)\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob +=  p.lpSum([X[i+n] for i in range(m)])\n",
    "    ###############################################\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status])  \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective))# The solution status \n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            racidivism1[i]=1 \n",
    "            racidivism2[i]=0\n",
    "        else:\n",
    "            racidivism1[i]=0\n",
    "            racidivism2[i]=1\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2          \n",
    "        #   print(p.value(X[i]))\n",
    "    return racidivismu1,racidivismu2,R \n",
    "\n",
    "\n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############-LP min-sum-3deterministic ######################\n",
    "#pROPUBLICA MIN SUM CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_sum_lp_all():\n",
    "    filename = '../input/1ProPublica_racidivism.csv'\n",
    "    d2 = pd.read_csv(filename)\n",
    "    # n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:4315,'sex']\n",
    "    x2 = d2.loc[0:4315,'race']\n",
    "    n=x1.shape[0]\n",
    "\n",
    "    print(\"1:gender, 2:race\")\n",
    "    s_attribute=input()\n",
    "    if s_attribute==1 :\n",
    "        R = np.zeros((2, n), dtype = int)\n",
    "        for i in range(n):\n",
    "            if x1[i] == 'Male':\n",
    "                R[0][i]= 1\n",
    "            else:\n",
    "                R[1][i]= 1\n",
    "\n",
    "    else:  \n",
    "        R = np.zeros((5, n), dtype = int)\n",
    "        for i in range(n):\n",
    "            if x2[i] == 'African-American':\n",
    "                R[0][i]= 1\n",
    "            elif x2[i] == 'Caucasian':\n",
    "                R[1][i]= 1\n",
    "            elif x2[i] == 'Hispanic':\n",
    "                R[2][i]= 1\n",
    "            elif x2[i] == 'Asia':\n",
    "                R[3][i]= 1\n",
    "            else:\n",
    "                R[4][i]= 1\n",
    "\n",
    "\n",
    "\n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "    # Create a LP Minimization problem \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "\n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "\n",
    "    X=np.zeros(n+m,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n+m):\n",
    "        var=str(i)\n",
    "        if(i<n):##n\n",
    "            X[i]=p.LpVariable(var,lowBound=0,upBound=1)\n",
    "        else:##m\n",
    "            X[i] =  p.LpVariable(var,lowBound=0,upBound=n)\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob +=  p.lpSum([X[i+n] for i in range(m)])\n",
    "    ###############################################\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n+i] >= p.lpSum([X[j]*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n+i-m] >= p.lpSum([-1*X[j]*R[i-m][j] for j in range(n)])\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status])   # The solution status \n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            racidivism1[i]=1 \n",
    "            racidivism2[i]=0\n",
    "        else:\n",
    "            racidivism1[i]=0\n",
    "            racidivism2[i]=1\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2          \n",
    "        #   print(p.value(X[i]))\n",
    "    return racidivismu1,racidivismu2,R \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13ProPublica_violent_racidivism.csv\n",
      "1ProPublica_racidivism.csv\n",
      "3germandata_numeric.txt\n",
      "\n",
      "0       0\n",
      "1       1\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4005    0\n",
      "4006    0\n",
      "4007    0\n",
      "4008    0\n",
      "4009    0\n",
      "Name: two_year_recid, Length: 4010, dtype: int64\n",
      "   age  juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n",
      "0   69              0               0                0             0   \n",
      "1   34              0               0                0             0   \n",
      "2   44              0               0                0             0   \n",
      "3   43              0               0                0             3   \n",
      "4   39              0               0                0             0   \n",
      "\n",
      "   decile_score  sex_Female  sex_Male  race_African-American  race_Asian  ...  \\\n",
      "0             1           0         1                      0           0  ...   \n",
      "1             3           0         1                      1           0  ...   \n",
      "2             1           0         1                      0           0  ...   \n",
      "3             4           0         1                      0           0  ...   \n",
      "4             1           1         0                      0           0  ...   \n",
      "\n",
      "   sr_Female-Caucasian  sr_Female-Hispanic  sr_Female-Other  \\\n",
      "0                    0                   0                0   \n",
      "1                    0                   0                0   \n",
      "2                    0                   0                0   \n",
      "3                    0                   0                0   \n",
      "4                    1                   0                0   \n",
      "\n",
      "   sr_Male-African-American  sr_Male-Asian  sr_Male-Caucasian  \\\n",
      "0                         0              0                  0   \n",
      "1                         1              0                  0   \n",
      "2                         0              0                  0   \n",
      "3                         0              0                  0   \n",
      "4                         0              0                  0   \n",
      "\n",
      "   sr_Male-Hispanic  sr_Male-Native American  sr_Male-Other  2_year_racidivism  \n",
      "0                 0                        0              1                  0  \n",
      "1                 0                        0              0                  1  \n",
      "2                 0                        0              1                  0  \n",
      "3                 0                        0              1                  0  \n",
      "4                 0                        0              0                  0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "31\n",
      "There are 2807 samples in the training set and 1203 samples in the test set\n",
      "The accuracy of the SVM classifier on training data is 0.87\n",
      "The accuracy of the SVM classifier on test data is 0.83\n",
      "####Train prediction Label###############################################\n",
      "[0 0 0 ... 0 0 0]\n",
      "####Actual Train Label###############################################\n",
      "####Change to colors###############################################\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "586.0\n",
      "0.6612041325258283 0.33879586747417173\n",
      "158 1698\n",
      "291 660\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "586.0\n",
      "0.6612041325258283 0.33879586747417173\n",
      "158 1698\n",
      "291 660\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "586.0\n",
      "0.6612041325258283 0.33879586747417173\n",
      "158 1698\n",
      "291 660\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "586.0\n",
      "0.6661916636978981 0.3338083363021019\n",
      "165 1705\n",
      "284 653\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "586.0\n",
      "0.6661916636978981 0.3338083363021019\n",
      "165 1705\n",
      "284 653\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "586.0\n",
      "0.6661916636978981 0.3338083363021019\n",
      "165 1705\n",
      "284 653\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "600.0\n",
      "0.6594228713929462 0.3405771286070538\n",
      "152 1699\n",
      "297 659\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "700.0\n",
      "0.6672604203776273 0.33273957962237266\n",
      "138 1735\n",
      "311 623\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "800.0\n",
      "0.6765229782686142 0.3234770217313858\n",
      "126 1773\n",
      "323 585\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "900.0\n",
      "0.6836480228001425 0.3163519771998575\n",
      "111 1808\n",
      "338 550\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "1000.0\n",
      "0.694335589597435 0.30566441040256503\n",
      "101 1848\n",
      "348 510\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "1100.0\n",
      "0.7256857855361596 0.2743142144638404\n",
      "120 1917\n",
      "329 441\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "1200.0\n",
      "0.7377983612397577 0.2622016387602423\n",
      "112 1959\n",
      "337 399\n",
      "Optimal\n",
      "discripency is:\n",
      "1324.0\n",
      "1300.0\n",
      "0.7484859280370503 0.2515140719629498\n",
      "102 1999\n",
      "347 359\n",
      "Optimal\n",
      "discripency is:\n",
      "1400.0\n",
      "1400.0\n",
      "0.7135732098325615 0.28642679016743855\n",
      "47 1956\n",
      "402 402\n",
      "Optimal\n",
      "discripency is:\n",
      "1500.0\n",
      "1500.0\n",
      "0.7128607053794086 0.2871392946205914\n",
      "46 1955\n",
      "403 403\n",
      "Optimal\n",
      "discripency is:\n",
      "1600.0\n",
      "1600.0\n",
      "0.71571072319202 0.28428927680798005\n",
      "50 1959\n",
      "399 399\n",
      "Optimal\n",
      "discripency is:\n",
      "1700.0\n",
      "1700.0\n",
      "0.7128607053794086 0.2871392946205914\n",
      "46 1955\n",
      "403 403\n",
      "Optimal\n",
      "discripency is:\n",
      "1800.0\n",
      "1800.0\n",
      "0.7100106875667973 0.2899893124332027\n",
      "42 1951\n",
      "407 407\n",
      "Optimal\n",
      "discripency is:\n",
      "1900.0\n",
      "1900.0\n",
      "0.7100106875667973 0.2899893124332027\n",
      "42 1951\n",
      "407 407\n",
      "Optimal\n",
      "discripency is:\n",
      "2000.0\n",
      "2000.0\n",
      "0.6993231207695048 0.3006768792304952\n",
      "27 1936\n",
      "422 422\n",
      "Optimal\n",
      "discripency is:\n",
      "2100.0\n",
      "2100.0\n",
      "0.7014606341289633 0.2985393658710367\n",
      "30 1939\n",
      "419 419\n",
      "Optimal\n",
      "discripency is:\n",
      "2200.0\n",
      "2200.0\n",
      "0.7043106519415746 0.29568934805842534\n",
      "34 1943\n",
      "415 415\n",
      "Optimal\n",
      "discripency is:\n",
      "2300.0\n",
      "2300.0\n",
      "0.7100106875667973 0.2899893124332027\n",
      "42 1951\n",
      "407 407\n",
      "Optimal\n",
      "discripency is:\n",
      "2400.0\n",
      "2400.0\n",
      "0.7100106875667973 0.2899893124332027\n",
      "42 1951\n",
      "407 407\n",
      "Optimal\n",
      "discripency is:\n",
      "2500.0\n",
      "2500.0\n",
      "0.7100106875667973 0.2899893124332027\n",
      "42 1951\n",
      "407 407\n",
      "Optimal\n",
      "discripency is:\n",
      "2600.0\n",
      "2600.0\n",
      "0.7100106875667973 0.2899893124332027\n",
      "42 1951\n",
      "407 407\n",
      "Optimal\n",
      "discripency is:\n",
      "2700.0\n",
      "2700.0\n",
      "0.7100106875667973 0.2899893124332027\n",
      "42 1951\n",
      "407 407\n",
      "[0.6612041325258283, 0.6612041325258283, 0.6612041325258283, 0.6661916636978981, 0.6661916636978981, 0.6661916636978981, 0.6594228713929462, 0.6672604203776273, 0.6765229782686142, 0.6836480228001425, 0.694335589597435, 0.7256857855361596, 0.7377983612397577, 0.7484859280370503, 0.7135732098325615, 0.7128607053794086, 0.71571072319202, 0.7128607053794086, 0.7100106875667973, 0.7100106875667973, 0.6993231207695048, 0.7014606341289633, 0.7043106519415746, 0.7100106875667973, 0.7100106875667973, 0.7100106875667973, 0.7100106875667973, 0.7100106875667973]\n",
      "[0.33879586747417173, 0.33879586747417173, 0.33879586747417173, 0.3338083363021019, 0.3338083363021019, 0.3338083363021019, 0.3405771286070538, 0.33273957962237266, 0.3234770217313858, 0.3163519771998575, 0.30566441040256503, 0.2743142144638404, 0.2622016387602423, 0.2515140719629498, 0.28642679016743855, 0.2871392946205914, 0.28428927680798005, 0.2871392946205914, 0.2899893124332027, 0.2899893124332027, 0.3006768792304952, 0.2985393658710367, 0.29568934805842534, 0.2899893124332027, 0.2899893124332027, 0.2899893124332027, 0.2899893124332027, 0.2899893124332027]\n"
     ]
    }
   ],
   "source": [
    "###############LP-4 with accuracy########################\n",
    "\n",
    "\n",
    "y_1,y_train=ProPub2_svm()\n",
    "maxi=0\n",
    "acc1_l=[]\n",
    "acc2_l=[]\n",
    "epsilon_l=[]\n",
    "for i in range(y_train.shape[0]):\n",
    "        if y_train[i] == 1 :\n",
    "            y_train[i]= -1\n",
    "        else:          \n",
    "            y_train[i]= 1\n",
    "            \n",
    "# for i in range(y_train.shape[0]):\n",
    "#         if y_train[i] == 1 :\n",
    "#             y_train[i]= 1\n",
    "#         else:          \n",
    "#             y_train[i]= -1            \n",
    "            \n",
    "            \n",
    "for eps in range(0,2800,100) :\n",
    "    count1=0\n",
    "    count2=0\n",
    "    u1,u2,R=min_max_lp_all(eps,y_train)\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j]):\n",
    "                count1+=1\n",
    "    acc1=float(count1/y_train.shape[0])        \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j]):\n",
    "                count2+=1\n",
    "    acc2=float(count2/y_train.shape[0])        \n",
    "    epsilon_l.append(eps)\n",
    "    acc2_l.append(acc2)\n",
    "    acc1_l.append(acc1)\n",
    "    print(acc1,acc2)   \n",
    "    \n",
    "    \n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j] and u1[j]==-1):\n",
    "                c1+=1       \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j] and u1[j]==1):\n",
    "                c2+=1\n",
    "    print(c1,c2)\n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j] and u2[j]==-1):\n",
    "                c1+=1       \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j] and u2[j]==1):\n",
    "                c2+=1\n",
    "    print(c1,c2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(acc1_l)     \n",
    "print(acc2_l)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############LP-4 with accuracy########################\n",
    "####2 LP-prop\n",
    "#German MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all(eps,r):\n",
    "    filename = '13ProPublica_violent_racidivism.csv'\n",
    "    d2 = pd.read_csv(filename)\n",
    "    # n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:2806,'sex']\n",
    "    x2 = d2.loc[0:2806,'race']\n",
    "    n=x1.shape[0]\n",
    "    R = np.zeros((7, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'Male':\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] == 'African-American':\n",
    "            R[2][i]= 1\n",
    "        elif x2[i] == 'Caucasian':\n",
    "            R[3][i]= 1\n",
    "        elif x2[i] == 'Hispanic':\n",
    "            R[4][i]= 1\n",
    "        elif x2[i] == 'Asia':\n",
    "            R[5][i]= 1\n",
    "        else:\n",
    "            R[6][i]= 1\n",
    "\n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "        \n",
    "    # Create a LP Minimization problem \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "\n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "\n",
    "    X=np.zeros(n+2,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n):\n",
    "        var=str(i)\n",
    "        X[i]=p.LpVariable(var,lowBound=0,upBound=1,cat='Integer')\n",
    "    X[n] =  p.LpVariable(\"z1\",lowBound=0)\n",
    "    X[n+1] =  p.LpVariable(\"z2\",lowBound=0)\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob += X[n] + X[n+1]\n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "    ##### r(y_train values real labels of data)\n",
    "    Lp_prob += X[n+1] >= p.lpSum([2*(X[j]-0.5)-r[j] for j in range(n)])\n",
    "    Lp_prob += X[n+1] >= p.lpSum([-1*2*(X[j]-0.5)+r[j] for j in range(n)])\n",
    "\n",
    "    Lp_prob += X[n] >= eps\n",
    "    Lp_prob += X[n] <= 2800\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective)) \n",
    "    ###################################################\n",
    "    w=p.value(Lp_prob.objective)-p.value(X[n+1])\n",
    "    print(w)\n",
    "    # The solution status \n",
    "    \n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "        # # Printing the final solution\n",
    "        \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            racidivism1[i]=1 \n",
    "            racidivism2[i]=-1\n",
    "        else:\n",
    "            racidivism1[i]=-1\n",
    "            racidivism2[i]=1\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2    \n",
    "    return racidivismu1,racidivismu2,R   \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "# print(p.value(Lp_prob.objective))   \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
