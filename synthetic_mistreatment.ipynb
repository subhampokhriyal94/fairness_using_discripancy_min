{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############Synthetic data Disperate mistreatment##############################\n",
    "\n",
    "from __future__ import division\n",
    "import os,sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for plotting stuff\n",
    "from random import seed, shuffle\n",
    "from scipy.stats import multivariate_normal # generating synthetic data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SEED = 1122334455\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "sys.path.insert(0, '../../fair_classification/') \n",
    "# import utils as ut\n",
    "\n",
    "\n",
    "def generate_synthetic_data(data_type, plot_data=False):\n",
    "\n",
    "    \"\"\"\n",
    "        Code for generating the synthetic data.\n",
    "        We will have two non-sensitive features and one sensitive feature.\n",
    "        Non sensitive features will be drawn from a 2D gaussian distribution.\n",
    "        Sensitive feature specifies the demographic group of the data point and can take values 0 and 1.\n",
    "\n",
    "        The code will generate data such that a classifier optimizing for accuracy will lead to disparate misclassification rates for the two demographic groups.\n",
    "        You can generate different data configurations using different values for the \"data_type\" parameter.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = 1000 # generate these many data points per cluster\n",
    "\n",
    "    def gen_gaussian_diff_size(mean_in, cov_in, z_val, class_label, n):\n",
    "        \"\"\"\n",
    "        mean_in: mean of the gaussian cluster\n",
    "        cov_in: covariance matrix\n",
    "        z_val: sensitive feature value\n",
    "        class_label: +1 or -1\n",
    "        n: number of points\n",
    "        \"\"\"\n",
    "\n",
    "        nv= multivariate_normal(mean = mean_in, cov = cov_in)\n",
    "        X = nv.rvs(n)\n",
    "        y = np.ones(n, dtype=float) * class_label\n",
    "        z = np.ones(n, dtype=float) * z_val # all the points in this cluster get this value of the sensitive attribute\n",
    "\n",
    "        return nv, X, y, z\n",
    "\n",
    "\n",
    "    if data_type == 1:\n",
    "\n",
    "        \"\"\"\n",
    "        Generate data such that a classifier optimizing for accuracy will have disparate false positive rates as well as disparate false negative rates for both groups.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        cc = [[10,1], [1,4]]\n",
    "        mu1, sigma1 = [2, 3], cc  # z=1, +\n",
    "        cc = [[5,2], [2,5]]\n",
    "        mu2, sigma2 = [1, 2], cc  # z=0, +\n",
    "\n",
    "        cc = [[5, 1], [1, 5]]\n",
    "        mu3, sigma3 = [-5,0], cc # z=1, -\n",
    "        cc = [[7, 1], [1, 7]]\n",
    "        mu4, sigma4 = [0,-1], cc # z=0, -\n",
    "\n",
    "        nv1, X1, y1, z1 = gen_gaussian_diff_size(mu1, sigma1, 1, +1, int(n_samples * 1) ) # z=1, +\n",
    "        nv2, X2, y2, z2 = gen_gaussian_diff_size(mu2, sigma2, 0, +1, int(n_samples * 1) ) # z=0, +\n",
    "        nv3, X3, y3, z3 = gen_gaussian_diff_size(mu3, sigma3, 1, -1, int(n_samples * 1) ) # z=1, -\n",
    "        nv4, X4, y4, z4 = gen_gaussian_diff_size(mu4, sigma4, 0, -1, int(n_samples * 1) ) # z=0, -\n",
    "\n",
    "    elif data_type == 2:\n",
    "\n",
    "        \"\"\"\n",
    "        Generate data such that a classifier optimizing for accuracy will have disparate false positive rates for both groups but will have equal false negative rates.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        cc = [[3,1], [1,3]]\n",
    "        mu1, sigma1 = [2, 2], cc  # z=1, +\n",
    "        mu2, sigma2 = [2, 2], cc  # z=0, +\n",
    "\n",
    "        mu3, sigma3 = [-2,-2], cc # z=1, -\n",
    "        cc = [[3,3], [1,3]]\n",
    "        mu4, sigma4 = [-1,0], cc # z=0, -\n",
    "\n",
    "        nv1, X1, y1, z1 = gen_gaussian_diff_size(mu1, sigma1, 1, +1, int(n_samples * 1) ) # z=1, +\n",
    "        nv2, X2, y2, z2 = gen_gaussian_diff_size(mu2, sigma2, 0, +1, int(n_samples * 1) ) # z=0, +\n",
    "        nv3, X3, y3, z3 = gen_gaussian_diff_size(mu3, sigma3, 1, -1, int(n_samples * 1) ) # z=1, -\n",
    "        nv4, X4, y4, z4 = gen_gaussian_diff_size(mu4, sigma4, 0, -1, int(n_samples * 1) ) # z=0, -\n",
    "\n",
    "\n",
    "\n",
    "    # merge the clusters\n",
    "    X = np.vstack((X1, X2, X3, X4))\n",
    "    y = np.hstack((y1, y2, y3, y4))\n",
    "    x_control = np.hstack((z1, z2, z3, z4))\n",
    "\n",
    "    # shuffle the data\n",
    "    perm = [*range(len(X))]\n",
    "    shuffle(perm)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    x_control = x_control[perm]\n",
    "\n",
    "    \n",
    "    \"\"\" Plot the data \"\"\"\n",
    "    if plot_data:\n",
    "        plt.figure()\n",
    "        num_to_draw = 200 # we will only draw a small number of points to avoid clutter\n",
    "        x_draw = X[:num_to_draw]\n",
    "        y_draw = y[:num_to_draw]\n",
    "        x_control_draw = x_control[:num_to_draw]\n",
    "\n",
    "        X_s_0 = x_draw[x_control_draw == 0.0]\n",
    "        X_s_1 = x_draw[x_control_draw == 1.0]\n",
    "        y_s_0 = y_draw[x_control_draw == 0.0]\n",
    "        y_s_1 = y_draw[x_control_draw == 1.0]\n",
    "\n",
    "        plt.scatter(X_s_0[y_s_0==1.0][:, 0], X_s_0[y_s_0==1.0][:, 1], color='green', marker='x', s=60, linewidth=2, label= \"group-0 +ve\")\n",
    "        plt.scatter(X_s_0[y_s_0==-1.0][:, 0], X_s_0[y_s_0==-1.0][:, 1], color='red', marker='x', s=60, linewidth=2, label = \"group-0 -ve\")\n",
    "        plt.scatter(X_s_1[y_s_1==1.0][:, 0], X_s_1[y_s_1==1.0][:, 1], color='green', marker='o', facecolors='none', s=60, linewidth=2, label = \"group-1 +ve\")\n",
    "        plt.scatter(X_s_1[y_s_1==-1.0][:, 0], X_s_1[y_s_1==-1.0][:, 1], color='red', marker='o', facecolors='none', s=60, linewidth=2, label = \"group-1 -ve\")\n",
    "\n",
    "\n",
    "        plt.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off') # dont need the ticks to see the data distribution\n",
    "        plt.tick_params(axis='y', which='both', left='off', right='off', labelleft='off')\n",
    "        plt.legend(loc=2, fontsize=21)\n",
    "        plt.ylim((-8,12))\n",
    "\n",
    "#         plt.savefig(\"img/data.png\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#     x_control = {\"s1\": x_control} # all the sensitive features are stored in a dictionary\n",
    "#     X = ut.add_intercept(X)\n",
    "    \n",
    "\n",
    "    return X,y,x_control\n",
    "def Synth_data1():\n",
    "    X,y,x_control=generate_synthetic_data(1,True)\n",
    "    \n",
    "    \n",
    "    X=np.column_stack((X,x_control))\n",
    "#     print(X)\n",
    "    return(X,y)\n",
    "def Synth_data2():\n",
    "    X,y,x_control=generate_synthetic_data(2,True)\n",
    "    \n",
    "    \n",
    "    X=np.column_stack((X,x_control))\n",
    "#     print(X)\n",
    "    return(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=Synth_data1()\n",
    "\n",
    "c1=0\n",
    "c2=0\n",
    "for j in range(x.shape[0]):\n",
    "        if(x[j][2]==1 and y[j]==-1):\n",
    "            c1+=1       \n",
    "\n",
    "for j in range(x.shape[0]):\n",
    "        if(x[j][2]==1 and y[j]==1):\n",
    "            c2+=1\n",
    "print(c1,c2)\n",
    "c1=0\n",
    "c2=0\n",
    "for j in range(x.shape[0]):\n",
    "        if(x[j][2]==0 and y[j]==-1):\n",
    "            c1+=1       \n",
    "\n",
    "for j in range(x.shape[0]):\n",
    "        if(x[j][2]==0 and y[j]==1):\n",
    "            c2+=1\n",
    "print(c1,c2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=Synth_data2()\n",
    "\n",
    "c1=0\n",
    "c2=0\n",
    "for j in range(x.shape[0]):\n",
    "        if(x[j][2]==1 and y[j]==-1):\n",
    "            c1+=1       \n",
    "\n",
    "for j in range(x.shape[0]):\n",
    "        if(x[j][2]==1 and y[j]==1):\n",
    "            c2+=1\n",
    "print(c1,c2)\n",
    "c1=0\n",
    "c2=0\n",
    "for j in range(x.shape[0]):\n",
    "        if(x[j][2]==0 and y[j]==-1):\n",
    "            c1+=1       \n",
    "\n",
    "for j in range(x.shape[0]):\n",
    "        if(x[j][2]==0 and y[j]==1):\n",
    "            c2+=1\n",
    "print(c1,c2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3y axis axis in one\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def make_patch_spines_invisible(ax):\n",
    "    ax.set_frame_on(True)\n",
    "    ax.patch.set_visible(False)\n",
    "    for sp in ax.spines.values():\n",
    "        sp.set_visible(False)\n",
    "\n",
    "\n",
    "fig, host = plt.subplots()\n",
    "fig.subplots_adjust(right=0.75)\n",
    "\n",
    "par1 = host.twinx()\n",
    "par2 = host.twinx()\n",
    "\n",
    "# Offset the right spine of par2.  The ticks and label have already been\n",
    "# placed on the right by twinx above.\n",
    "par2.spines[\"right\"].set_position((\"axes\", 1.2))\n",
    "# Having been created by twinx, par2 has its frame off, so the line of its\n",
    "# detached spine is invisible.  First, activate the frame but make the patch\n",
    "# and spines invisible.\n",
    "make_patch_spines_invisible(par2)\n",
    "# Second, show the right spine.\n",
    "par2.spines[\"right\"].set_visible(True)\n",
    "\n",
    "p1, = host.plot([0, 1, 2], [0, 1, 2], \"b-\", label=\"Density\")\n",
    "p2, = par1.plot([0, 1, 2], [0, 3, 2], \"r-\", label=\"Temperature\")\n",
    "p3, = par2.plot([0, 1, 2], [50, 30, 15], \"g-\", label=\"Velocity\")\n",
    "\n",
    "host.set_xlim(0, 2)\n",
    "host.set_ylim(0, 2)\n",
    "par1.set_ylim(0, 4)\n",
    "par2.set_ylim(1, 65)\n",
    "\n",
    "host.set_xlabel(\"Distance\")\n",
    "host.set_ylabel(\"Density\")\n",
    "par1.set_ylabel(\"Temperature\")\n",
    "par2.set_ylabel(\"Velocity\")\n",
    "\n",
    "host.yaxis.label.set_color(p1.get_color())\n",
    "par1.yaxis.label.set_color(p2.get_color())\n",
    "par2.yaxis.label.set_color(p3.get_color())\n",
    "\n",
    "tkw = dict(size=4, width=1.5)\n",
    "host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n",
    "par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n",
    "par2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n",
    "host.tick_params(axis='x', **tkw)\n",
    "\n",
    "lines = [p1, p2, p3]\n",
    "\n",
    "host.legend(lines, [l.get_label() for l in lines])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############Synthetic data disparate impact################\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for plotting stuff\n",
    "from random import seed, shuffle\n",
    "from scipy.stats import multivariate_normal # generating synthetic data\n",
    "SEED = 1122334455\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def generate_synthetic_data(plot_data=False):\n",
    "\n",
    "    \"\"\"\n",
    "        Code for generating the synthetic data.\n",
    "        We will have two non-sensitive features and one sensitive feature.\n",
    "        A sensitive feature value of 0.0 means the example is considered to be in protected group (e.g., female) and 1.0 means it's in non-protected group (e.g., male).\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = 1000000 # generate these many data points per class\n",
    "    disc_factor = math.pi / 4.0 # this variable determines the initial discrimination in the data -- decraese it to generate more discrimination\n",
    "\n",
    "    def gen_gaussian(mean_in, cov_in, class_label):\n",
    "        nv = multivariate_normal(mean = mean_in, cov = cov_in)\n",
    "        X = nv.rvs(n_samples)\n",
    "        y = np.ones(n_samples, dtype=float) * class_label\n",
    "        return nv,X,y\n",
    "\n",
    "    \"\"\" Generate the non-sensitive features randomly \"\"\"\n",
    "    # We will generate one gaussian cluster for each class\n",
    "    mu1, sigma1 = [2, 2], [[5, 1], [1, 5]]\n",
    "    mu2, sigma2 = [-2,-2], [[10, 1], [1, 3]]\n",
    "    nv1, X1, y1 = gen_gaussian(mu1, sigma1, 1) # positive class\n",
    "    nv2, X2, y2 = gen_gaussian(mu2, sigma2, -1) # negative class\n",
    "\n",
    "    # join the posisitve and negative class clusters\n",
    "    X = np.vstack((X1, X2))\n",
    "    y = np.hstack((y1, y2))\n",
    "\n",
    "    # shuffle the data\n",
    "    perm = [*range(0,n_samples*2)]\n",
    "    shuffle(perm)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    \n",
    "    rotation_mult = np.array([[math.cos(disc_factor), -math.sin(disc_factor)], [math.sin(disc_factor), math.cos(disc_factor)]])\n",
    "    X_aux = np.dot(X, rotation_mult)\n",
    "\n",
    "\n",
    "    \"\"\" Generate the sensitive feature here \"\"\"\n",
    "    x_control = [] # this array holds the sensitive feature value\n",
    "    for i in range (0, len(X)):\n",
    "        x = X_aux[i]\n",
    "\n",
    "        # probability for each cluster that the point belongs to it\n",
    "        p1 = nv1.pdf(x)\n",
    "        p2 = nv2.pdf(x)\n",
    "        \n",
    "        # normalize the probabilities from 0 to 1\n",
    "        s = p1+p2\n",
    "        p1 = p1/s\n",
    "        p2 = p2/s\n",
    "        \n",
    "        r = np.random.uniform() # generate a random number from 0 to 1\n",
    "\n",
    "        if r < p1: # the first cluster is the positive class\n",
    "            x_control.append(1.0) # 1.0 means its male\n",
    "        else:\n",
    "            x_control.append(0.0) # 0.0 -> female\n",
    "\n",
    "    x_control = np.array(x_control)\n",
    "\n",
    "    \"\"\" Show the data \"\"\"\n",
    "    if plot_data:\n",
    "        num_to_draw = 200 # we will only draw a small number of points to avoid clutter\n",
    "        x_draw = X[:num_to_draw]\n",
    "        y_draw = y[:num_to_draw]\n",
    "        x_control_draw = x_control[:num_to_draw]\n",
    "\n",
    "        X_s_0 = x_draw[x_control_draw == 0.0]\n",
    "        X_s_1 = x_draw[x_control_draw == 1.0]\n",
    "        y_s_0 = y_draw[x_control_draw == 0.0]\n",
    "        y_s_1 = y_draw[x_control_draw == 1.0]\n",
    "        plt.scatter(X_s_0[y_s_0==1.0][:, 0], X_s_0[y_s_0==1.0][:, 1], color='green', marker='x', s=30, linewidth=1.5, label= \"Prot. +ve\")\n",
    "        plt.scatter(X_s_0[y_s_0==-1.0][:, 0], X_s_0[y_s_0==-1.0][:, 1], color='red', marker='x', s=30, linewidth=1.5, label = \"Prot. -ve\")\n",
    "        plt.scatter(X_s_1[y_s_1==1.0][:, 0], X_s_1[y_s_1==1.0][:, 1], color='green', marker='o', facecolors='none', s=30, label = \"Non-prot. +ve\")\n",
    "        plt.scatter(X_s_1[y_s_1==-1.0][:, 0], X_s_1[y_s_1==-1.0][:, 1], color='red', marker='o', facecolors='none', s=30, label = \"Non-prot. -ve\")\n",
    "\n",
    "        \n",
    "        plt.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off') # dont need the ticks to see the data distribution\n",
    "        plt.tick_params(axis='y', which='both', left='off', right='off', labelleft='off')\n",
    "        plt.legend(loc=2, fontsize=15)\n",
    "        plt.xlim((-15,10))\n",
    "        plt.ylim((-10,15))\n",
    "       #         plt.show()\n",
    "#       plt.savefig(\"img/data.png\")\n",
    "        \n",
    "#     x_control = {\"s1\": x_control} # all the sensitive features are stored in a dictionary\n",
    "    return X,y,x_control\n",
    "\n",
    "def Synth_data():\n",
    "    X,y,x_control=generate_synthetic_data(True)\n",
    "    X=np.column_stack((X,x_control))\n",
    "#     print(X)\n",
    "    return(X,y,x_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n",
      "3\n",
      "2 2000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xx,yy,x_control=Synth_data()\n",
    "print(yy.shape[0])\n",
    "print(xx.shape[1])\n",
    "gamma=0.2\n",
    "u1,u2=min_max_lp_all(x_control,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################---LP3-with epsilon-with accuracy-########################\n",
    "#############----Synthetic with 5D MIN Max COMMAND----###################### \n",
    "\n",
    "import pulp as p \n",
    "def min_max_lp_all(data,gamma):\n",
    "    x1=data\n",
    "    \n",
    "    \n",
    "    n=x1.shape[0]\n",
    "    \n",
    "    R = np.zeros((2, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i]== 1:\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "            \n",
    "    \n",
    "    m=R.shape[0]\n",
    "    print(m,n)\n",
    "    \n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if R[i][j]==1:\n",
    "                count=count+1\n",
    "                \n",
    "        sizes[i]=count\n",
    "   \n",
    "    #X[n]=z() n last value of X\n",
    "   \n",
    "   \n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n):\n",
    "        var1=str(i)\n",
    "        \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "       \n",
    "        \n",
    "    X[n] =  p.LpVariable(\"z1\",lowBound=0)\n",
    "  \n",
    "  \n",
    "\n",
    "    #########objective function#####################\n",
    "    \n",
    "    Lp_prob += X[n] \n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)]) >= abs(2*gamma-1)*sizes[i]\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "            \n",
    "         \n",
    "    ##### r(y_train values real labels of data)\n",
    "    \n",
    "  \n",
    "\n",
    "    \n",
    "    Lp_prob += X[n] <=1000000\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "  \n",
    "   \n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    return Synthu1,Synthu2  \n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
