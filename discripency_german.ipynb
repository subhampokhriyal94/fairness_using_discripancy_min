{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as lin\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#Assume the first r rows of a forms an orthonormal basis\n",
    "#Returns the projection of x onto the orthogonal complement of the rows of a\n",
    "#scaled to unit length\n",
    "def make_orthogonal(a,r,x):\n",
    "    if np.linalg.norm(x)<1e-8:\n",
    "        return None\n",
    "    if r==0:\n",
    "        return x/np.linalg.norm(x)\n",
    "    u = x\n",
    "    for j in range(0,int(r/100)):\n",
    "        u = u - a[range(j*100,(j+1)*100)].T @ (a[range(j*100,(j+1)*100)] @ u)\n",
    "    for j in range(int(r/100)*100,r):\n",
    "        u = u - np.inner(u,a[j]) * a[j]\n",
    "    norm = np.linalg.norm(u)\n",
    "    if norm < np.linalg.norm(x)/100:\n",
    "        return None\n",
    "    u = u/norm\n",
    "    return u\n",
    "\n",
    "def round_coloring(a,x,norm = np.inf, balanced=False):\n",
    "    start = time.time()\n",
    "    n = a.shape[1]\n",
    "    abs = np.absolute(x)\n",
    "    live = (abs < 1.0-1e-4)\n",
    "    #first sample each entry\n",
    "    samples = np.random.random_sample(n)\n",
    "    signs = np.ones(n)\n",
    "    signs[samples < (1.0-abs)/2.0] = -1\n",
    "    flipped = np.multiply(x,signs)\n",
    "    y = np.sign(flipped)\n",
    "    y[y==0]=1\n",
    "    #then try all assignments to the coordinates that were live\n",
    "    num_live = sum(live)\n",
    "    if num_live<=10:\n",
    "        live_indices = [i for i, x in enumerate(live) if x]\n",
    "        ay = a@y\n",
    "        sub_a = a[:,live_indices]\n",
    "        sub_y = y[live_indices]\n",
    "        sub_ay = sub_a @ sub_y\n",
    "        a_outside = ay - sub_ay\n",
    "        best_sub_y = sub_y\n",
    "        best_norm = np.linalg.norm(ay,ord=norm)\n",
    "        sign_flips = np.ones(num_live)\n",
    "        while True:\n",
    "            at = 0\n",
    "            while at<num_live and sign_flips[at]==-1:\n",
    "                sign_flips[at]=1\n",
    "                at = at+1\n",
    "            if at==num_live:\n",
    "                break\n",
    "            sign_flips[at]=-1\n",
    "            new_sub_y = np.multiply(sub_y,sign_flips)\n",
    "            new_sub_ay = sub_a @ new_sub_y\n",
    "            new_ay = a_outside + new_sub_ay\n",
    "            new_norm = np.linalg.norm(new_ay,ord=norm)\n",
    "            if new_norm < best_norm:\n",
    "                best_norm = new_norm\n",
    "                best_sub_y = new_sub_y\n",
    "        y[live_indices] = best_sub_y\n",
    "    #balance the vector in case we need to\n",
    "    if balanced:\n",
    "        while True:\n",
    "            toFlip = 1\n",
    "            if sum(y==1) < n/2:\n",
    "                toFlip = -1\n",
    "            ofToFlip = sum(y==toFlip)\n",
    "            needToFlip = int(ofToFlip-n/2)\n",
    "            if needToFlip==0:\n",
    "                break\n",
    "            listOfToFlip = [i for i, x in enumerate(y) if x==toFlip]\n",
    "            ay = a @ y\n",
    "            best_norm = 1e27\n",
    "            #try all single flips\n",
    "            best_to_flip = 0\n",
    "            for i in listOfToFlip:\n",
    "                col = a[:,i]\n",
    "                new_ay = ay - (2*col*y[i])\n",
    "                new_norm = np.linalg.norm(new_ay,ord=norm)\n",
    "                if new_norm < best_norm:\n",
    "                    best_norm = new_norm\n",
    "                    best_to_flip = i\n",
    "            y[best_to_flip] = -y[best_to_flip]\n",
    "    return y\n",
    "\n",
    "def to_square(a,x,balanced=False):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    if n<=m:\n",
    "        return x\n",
    "    live = n\n",
    "    orth = np.zeros((n,n))\n",
    "    is_live = np.ones(n)\n",
    "    num_orth = 0\n",
    "    for i in range(0,m):\n",
    "        p = make_orthogonal(orth,num_orth,a[i])\n",
    "        if not p is None:\n",
    "            orth[num_orth] = p\n",
    "            num_orth = num_orth + 1\n",
    "    if balanced:\n",
    "        all_ones = np.ones(n)\n",
    "        p = make_orthogonal(orth,num_orth,all_ones)\n",
    "        if np.linalg.norm(p) > 0.01:\n",
    "            orth[num_orth] = p\n",
    "            num_orth = num_orth + 1\n",
    "    while num_orth < n and sum(is_live) > 8:\n",
    "        #sample a random vector\n",
    "        g = np.random.randn(n)\n",
    "        #make it orthogonal to all in orth\n",
    "        gamma = make_orthogonal(orth,num_orth,g)\n",
    "        if gamma is None:\n",
    "            break\n",
    "        #set all that are not live to 0 for numerical stability\n",
    "        for i in range(0,n):\n",
    "            if not is_live[i]:\n",
    "                gamma[i] = 0\n",
    "        #find coord that freezes first\n",
    "        delta = 1e30\n",
    "        for i in range(0,n):\n",
    "            if is_live[i] and abs(gamma[i]) > 1e-7:\n",
    "                dist = 0\n",
    "                if gamma[i] * x[i] >= 0:\n",
    "                    dist = (1-abs(x[i]))/abs(gamma[i])\n",
    "                else:\n",
    "                    dist = (1+abs(x[i]))/abs(gamma[i])\n",
    "                if dist < delta:\n",
    "                    delta = dist\n",
    "        if delta > 1e25:\n",
    "            break\n",
    "        x = x + delta * gamma\n",
    "        for i in range(0,n):\n",
    "            if is_live[i] and abs(x[i]) >= 1-1e-6:\n",
    "                is_live[i] = 0\n",
    "                e = np.zeros(n)\n",
    "                e[i] = 1\n",
    "                p = make_orthogonal(orth,num_orth,e)\n",
    "                if not p is None:\n",
    "                    orth[num_orth] = p\n",
    "                    num_orth = num_orth+1\n",
    "                    if num_orth>=n:\n",
    "                        break\n",
    "    return x\n",
    "\n",
    "def partial_color(a,x,norm=np.inf,balanced=False):\n",
    "    if norm==np.inf:\n",
    "        return partial_infty_color(a,x,balanced)\n",
    "    if norm==2:\n",
    "        return partial_l2_color(a,x,balanced)\n",
    "\n",
    "def partial_l2_color(a, x, balanced=False):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    delta=1e-5\n",
    "\n",
    "    #count number of live coordinates\n",
    "    abs_x = np.absolute(x)\n",
    "    is_live = (abs_x < 1.0-delta)\n",
    "    initial_is_live = is_live.copy()\n",
    "    live = is_live.sum()\n",
    "    if live<8: \n",
    "        return True\n",
    "    initial_live=live\n",
    "    #extract the live coordinates and columns\n",
    "    y = x[initial_is_live]\n",
    "    b = a[:,initial_is_live]\n",
    "    #compute eigenvectors of bTb\n",
    "    bTb = b.T @ b\n",
    "    w, v = lin.eigh(bTb)\n",
    "    num_iters = 0\n",
    "    was_live = np.ones(initial_live,dtype=bool)\n",
    "    num_frozen = 0\n",
    "    orth = np.zeros((initial_live,initial_live))\n",
    "    num_orth = 0\n",
    "    to_add = v[:,range(initial_live-int(initial_live/2), initial_live)].T\n",
    "    orth[range(0,to_add.shape[0])] = to_add\n",
    "    num_orth = to_add.shape[0]\n",
    "    if balanced:\n",
    "        ones = np.ones(initial_live)\n",
    "        ones = make_orthogonal(orth,num_orth,ones)\n",
    "        if not ones is None:\n",
    "            orth[num_orth] = ones\n",
    "            num_orth = num_orth+1\n",
    "    while int((live*3/2)) > initial_live:\n",
    "        #will have at most 1/3 * initial_live that are frozen\n",
    "        abs_y = np.absolute(y)\n",
    "        #start by freezing new frozen coordinates\n",
    "        is_live = (abs_y < 1.0-delta)\n",
    "        diff = is_live!=was_live\n",
    "        num_diff = diff.sum()\n",
    "        if num_diff>0:\n",
    "            for i in range(0,initial_live):\n",
    "                if diff[i]:\n",
    "                    e = np.zeros(initial_live)\n",
    "                    e[i] = 1\n",
    "                    p = make_orthogonal(orth,num_orth,e)\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_frozen = num_frozen + 1\n",
    "            was_live = is_live\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        num_iters = num_iters+1\n",
    "        ax = a @ x\n",
    "        #sample a random vector\n",
    "        g = np.random.randn(initial_live)\n",
    "        #make it orthogonal to all in orth\n",
    "        gamma = make_orthogonal(orth,num_orth,g)\n",
    "        if gamma is None:\n",
    "            break\n",
    "        #set coords to zero where not live, due to numerical stability\n",
    "        for i in range(0,initial_live):\n",
    "            if not is_live[i]:\n",
    "                gamma[i] = 0\n",
    "        if np.linalg.norm(gamma,ord=np.inf)==0:\n",
    "            break\n",
    "        if np.inner(ax,b @ gamma) > 0:\n",
    "            gamma = -gamma\n",
    "        coord_mult = np.multiply(gamma,y)\n",
    "        val = np.where(coord_mult < 0, (1+abs(y))/(1e-27+abs(gamma)), (1-abs(y))/(1e-27 + abs(gamma)))\n",
    "        val = np.where(is_live, val, 1e27)\n",
    "        z = min(val)\n",
    "        y = y + z*gamma\n",
    "        x[initial_is_live] = y\n",
    "        new_abs_y = np.absolute(y)\n",
    "        is_live = (new_abs_y < 1.0-delta)\n",
    "        live = is_live.sum()\n",
    "    return False\n",
    "\n",
    "def partial_infty_color(a, x, balanced=False):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    delta=1e-5\n",
    "\n",
    "    #count number of live coordinates\n",
    "    abs_x = np.absolute(x)\n",
    "    is_live = (abs_x < 1.0-delta)\n",
    "    initial_is_live = is_live.copy()\n",
    "    live = is_live.sum()\n",
    "    if live<8: \n",
    "        return True\n",
    "    initial_live=live\n",
    "    #extract the live coordinates and columns\n",
    "    y = x[initial_is_live]\n",
    "    b = a[:,initial_is_live]\n",
    "    num_iters = 0\n",
    "    was_live = np.ones(initial_live,dtype=bool)\n",
    "    was_small = np.ones(m,dtype=bool)\n",
    "    orth = np.zeros((initial_live,initial_live))\n",
    "    num_orth = 0\n",
    "    if balanced:\n",
    "        ones = np.ones(initial_live)\n",
    "        ones = ones/np.sqrt(initial_live)\n",
    "        orth[0] = ones\n",
    "        num_orth = num_orth+1\n",
    "    num_frozen = 0\n",
    "    num_big = 0\n",
    "    num_initial = 0\n",
    "    while int((live*5)/4) > initial_live:\n",
    "        #will have at most 1/3 * initial_live that are frozen\n",
    "        #freeze up to 1/3 largest coords\n",
    "        abs_y = np.absolute(y)\n",
    "        #start by freezing new frozen coordinates\n",
    "        is_live = (abs_y < 1.0-delta)\n",
    "        diff = is_live!=was_live\n",
    "        num_diff = diff.sum()\n",
    "        if num_diff>0:\n",
    "            for i in range(0,initial_live):\n",
    "                if diff[i]:\n",
    "                    e = np.zeros(initial_live)\n",
    "                    e[i] = 1\n",
    "                    p = make_orthogonal(orth,num_orth,e)\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_frozen = num_frozen + 1\n",
    "            was_live = is_live\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        #may freeze same number of rows based on abs value\n",
    "        num_iters = num_iters+1\n",
    "        ax = a @ x\n",
    "        abs_ax = np.absolute(ax)\n",
    "        if num_initial < initial_live/4:\n",
    "            sorted_indices = np.argsort(-abs_ax)\n",
    "            for i in range(0, m):\n",
    "                if was_small[sorted_indices[i]]:\n",
    "                    p = make_orthogonal(orth,num_orth,b[sorted_indices[i]])\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_initial = num_initial + 1\n",
    "                    was_small[sorted_indices[i]] = False\n",
    "                    if num_initial >= initial_live/4:\n",
    "                        break\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        if num_big < num_frozen:\n",
    "            sorted_indices = np.argsort(-abs_ax)\n",
    "            for i in range(0,m):\n",
    "                if was_small[sorted_indices[i]]:\n",
    "                    p = make_orthogonal(orth,num_orth,b[sorted_indices[i]])\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_big = num_big + 1\n",
    "                    was_small[sorted_indices[i]] = False\n",
    "                    if num_big >= num_frozen:\n",
    "                        break\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        #sample a random vector\n",
    "        g = np.random.randn(initial_live)\n",
    "        #make it orthogonal to all in orth\n",
    "        gamma = make_orthogonal(orth,num_orth,g)\n",
    "        if gamma is None:\n",
    "            break\n",
    "        #set coords to zero where not live, due to numerical stability\n",
    "        for i in range(0,initial_live):\n",
    "            if not is_live[i]:\n",
    "                gamma[i] = 0\n",
    "        if np.linalg.norm(gamma,ord=np.inf)==0:\n",
    "            break\n",
    "        if np.inner(ax,b @ gamma) > 0:\n",
    "            gamma = -gamma\n",
    "        coord_mult = np.multiply(gamma,y)\n",
    "        val = np.where(coord_mult < 0, (1+abs(y))/(1e-27+abs(gamma)), (1-abs(y))/(1e-27 + abs(gamma)))\n",
    "        val = np.where(is_live, val, 1e27)\n",
    "        z = min(val)\n",
    "        y = y + z*gamma\n",
    "        x[initial_is_live] = y\n",
    "        new_abs_y = np.absolute(y)\n",
    "        is_live = (new_abs_y < 1.0-delta)\n",
    "        live = is_live.sum()\n",
    "    return False\n",
    "\n",
    "\n",
    "def local_improvements(a,x,time_limit,norm=np.inf, balanced=False):\n",
    "    ax = a @ x\n",
    "    best_norm = np.linalg.norm(ax,ord=norm)\n",
    "    start_time = time.time()\n",
    "    num_flip = min(7,len(x))\n",
    "    if balanced and num_flip%2==1:\n",
    "        num_flip = num_flip + 1\n",
    "    iters = 0\n",
    "    while True:\n",
    "        iters = iters+1\n",
    "        #Try flipping random coords\n",
    "        for iteration in range(0,a.shape[1]):\n",
    "            sampled_coords = np.random.randint(0,a.shape[1],num_flip)\n",
    "            sampled_coords = np.sort(sampled_coords)\n",
    "            allDistinct=True\n",
    "            for i in range(0,num_flip-1):\n",
    "                if sampled_coords[i]==sampled_coords[i+1]:\n",
    "                    allDistinct=False\n",
    "            if not allDistinct:\n",
    "                continue\n",
    "            if balanced:\n",
    "                #check equal num of +1 and -1\n",
    "                sum_is=0\n",
    "                for i in range(0,num_flip):\n",
    "                    sum_is = sum_is + x[sampled_coords[i]]\n",
    "                if sum_is!=0:\n",
    "                    continue\n",
    "            subcols = a[:,sampled_coords]\n",
    "            subx = [x[index] for index in sampled_coords]\n",
    "            bx = ax - 2*(subcols @ subx)\n",
    "            the_norm = np.linalg.norm(bx,ord=norm)\n",
    "            if the_norm<best_norm:\n",
    "                best_norm = the_norm\n",
    "                for i in sampled_coords:\n",
    "                    x[i] = -x[i]\n",
    "                ax = bx\n",
    "        if time.time()-start_time > time_limit:\n",
    "            break \n",
    "    return x\n",
    "\n",
    "def basic_local_search(a,x,norm,balanced=False):\n",
    "    ax = a@x\n",
    "    best_norm = np.linalg.norm(ax,ord=norm)\n",
    "    improved=True\n",
    "    while improved:\n",
    "        improved=False\n",
    "        #Try flipping single coords\n",
    "        for i in range(0,a.shape[1]):\n",
    "            flipped = ax - 2*x[i]*a[:,i]\n",
    "            if np.linalg.norm(flipped, ord=norm) < best_norm:\n",
    "                if balanced:\n",
    "                    #must find one to swap with\n",
    "                    for j in range(0,a.shape[1]):\n",
    "                        if x[i]==x[j]:\n",
    "                            continue\n",
    "                        final_flipped = flipped - 2*x[j]*a[:,j]\n",
    "                        if np.linalg.norm(final_flipped,ord=norm) < best_norm:\n",
    "                            ax = final_flipped\n",
    "                            x[i] = -x[i]\n",
    "                            x[j] = -x[j]\n",
    "                            best_norm = np.linalg.norm(final_flipped,ord=norm)\n",
    "                            improved=True\n",
    "                            break\n",
    "                else:\n",
    "                    ax = flipped\n",
    "                    x[i] = -x[i]\n",
    "                    best_norm = np.linalg.norm(flipped,ord=norm)\n",
    "                    improved=True\n",
    "    return x\n",
    "\n",
    "def greedy(a,norm,balanced=False):\n",
    "    x = np.zeros(a.shape[1])\n",
    "    if balanced:\n",
    "        so_far = np.zeros(a.shape[0])\n",
    "        for i in range(0,a.shape[1]):\n",
    "            if i%2==1:\n",
    "                continue\n",
    "            test = so_far + a[:,i]\n",
    "            test_minus = so_far - a[:,i]\n",
    "            if i<a.shape[1]-1:\n",
    "                test = test - a[:,i+1]\n",
    "                test_minus = test_minus + a[:,i+1]\n",
    "            if np.linalg.norm(test,ord=norm) < np.linalg.norm(test_minus,ord=norm):\n",
    "                x[i] = 1\n",
    "                if i<a.shape[1]-1:\n",
    "                    x[i+1]=-1\n",
    "            else:\n",
    "                x[i] = -1\n",
    "                if i<a.shape[1]-1:\n",
    "                    x[i+1] = 1\n",
    "    else:\n",
    "        x[0] = 1\n",
    "        so_far = a[:,0]\n",
    "        for i in range(1,a.shape[1]):\n",
    "            test = so_far + a[:,i]\n",
    "            test_minus = so_far - a[:,i]\n",
    "            if np.linalg.norm(test,ord=norm) <  np.linalg.norm(test_minus,ord=norm):\n",
    "                x[i] = 1\n",
    "            else:\n",
    "                x[i] = -1\n",
    "            so_far = so_far + x[i]*a[:,i]\n",
    "    return x\n",
    "\n",
    "def discrepancy_minimize(a, norm=np.inf, balanced=False, local_search=0.3):\n",
    "    n = a.shape[1]\n",
    "    x = np.zeros(n)\n",
    "    start_time = time.time()\n",
    "    x = to_square(a,x,balanced)\n",
    "    while not partial_color(a,x, norm, balanced):\n",
    "        pass\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    y = round_coloring(a,x,norm, balanced)\n",
    "    y = basic_local_search(a,y,norm,balanced)\n",
    "    #check if greedy approach is better\n",
    "    g = greedy(a,norm,balanced)\n",
    "    g = basic_local_search(a,g,norm,balanced)\n",
    "    if np.linalg.norm(a@g,ord=norm) < np.linalg.norm(a@y, ord=norm):\n",
    "        y = g\n",
    "    y = local_improvements(a,y, elapsed*local_search, norm, balanced)\n",
    "    y = basic_local_search(a,y,norm,balanced)\n",
    "    total_elapsed = time.time()-start_time\n",
    "    #make sure we return an int array, not floating\n",
    "    z = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if y[i]==-1:\n",
    "            z[i]=-1\n",
    "        else:\n",
    "            z[i]=1\n",
    "    return z\n",
    "\n",
    "def Com(a):\n",
    "    n = a.shape[0]\n",
    "    b = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if a[i] == 1:\n",
    "            b[i]= 0\n",
    "        else:\n",
    "            b[i]= 1\n",
    "    return b   \n",
    "\n",
    "#python\n",
    "\n",
    "def FindDisc(a, v):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    disc = 0\n",
    "    for i in range(m):\n",
    "        newdisc = 0\n",
    "        for j in range(n):\n",
    "            newdisc = newdisc + v[j]\n",
    "            #print(newdisc)\n",
    "        modisc = abs(newdisc)\n",
    "        if modisc >= disc:\n",
    "            disc = modisc\n",
    "    return disc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################3ALL Fair#################3\n",
    "from random import *\n",
    "def fair(x,a,b,alpha,R):\n",
    "    #x-actual a=kesper b=classifier\n",
    "    \n",
    "    a_acc=0\n",
    "    b_acc=0\n",
    "    f_acc=0\n",
    "    n= x.shape[0]\n",
    "    f= np.zeros(n) \n",
    "    count=0\n",
    "    acc=0\n",
    "    for i in range(n):\n",
    "        z=random()\n",
    "        if z < alpha:\n",
    "            f[i]= a[i] \n",
    "            count=count+1\n",
    "        else:\n",
    "            f[i]= b[i]\n",
    "                    \n",
    "        \n",
    "    for i in range(n):\n",
    "         if a[i] == x[i]:\n",
    "                a_acc=a_acc+1\n",
    "    for i in range(n):\n",
    "         if b[i] == x[i]:\n",
    "                b_acc=b_acc+1\n",
    "    for i in range(n):\n",
    "         if f[i] == x[i]:\n",
    "                f_acc=f_acc+1\n",
    "\n",
    "    a_acc_percent=a_acc/n            \n",
    "    b_acc_percent=b_acc/n  \n",
    "    f_acc_percent=f_acc/n  \n",
    "    \n",
    "    count1=0\n",
    "    count2=0\n",
    "    for i in range(R.shape[1]):\n",
    "        if(R[0,i]==1):\n",
    "            if f[i]==1:\n",
    "                  count1+=1\n",
    "        else:\n",
    "            if f[i]==1:\n",
    "                count2+=1\n",
    "            \n",
    "    ratio=float(count1/count2)  \n",
    "#############################################################\n",
    "    \n",
    "    print(\"###############################\")\n",
    "#     print(f)\n",
    "#     print(x)\n",
    "#     print(b)\n",
    "#     print(a_acc_percent,b_acc_percent)\n",
    "    print(\"###############################\")\n",
    "    #kasper svm final ratio\n",
    "    return a_acc_percent,b_acc_percent,f_acc_percent,ratio\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def ploting(y_train,u1,y_1,R):\n",
    "    alpha1_l=[]\n",
    "    c1_l=[]\n",
    "    ratio_l=[]\n",
    "    \n",
    "    ####### plot################   \n",
    "    for alpha in [0,0.1, 0.2, 0.3 ,0.4,0.5, 0.6,0.7,0.8,0.9,1]:\n",
    "        a,b,c,ratio  = fair(y_train,u1,y_1,alpha,R)\n",
    "        ratio_l.append(ratio)\n",
    "        alpha1_l.append(alpha)\n",
    "        c1_l.append(c)\n",
    "    print(c1_l)\n",
    "    plt.plot( alpha1_l, c1_l, 'ro')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('Fairness(Alpha)')\n",
    "    plt.ylabel('Train Accuracy')\n",
    "    plt.title('Accuracy V/S Fairness tradeoff for ProPublica dataset')\n",
    "    alpha = np.linspace(0, 1, 10) \n",
    "    y = alpha*(min(c1_l) - max(c1_l)) + max(c1_l)\n",
    "    # fig = plt.figure(figsize = (10, 5)) \n",
    "    plt.plot(alpha, y) \n",
    "    plt.legend([\"Experimental\", \"Theoretical\"])\n",
    "    plt.show() \n",
    "#   print(min(c1_l) , max(c1_l))\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def german1():\n",
    "    filename = '3german.txt'\n",
    "    d2 = pd.read_csv(filename,delim_whitespace=True)\n",
    "    n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.iloc[0:699,8]\n",
    "    x2 = d2.iloc[0:699,12]\n",
    "    n = x2.shape[0]\n",
    "\n",
    "    list2= []  \n",
    "    R = np.zeros((8, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'A91':\n",
    "            R[0][i]= 1\n",
    "        elif x1[i] == 'A92':\n",
    "            R[1][i]= 1\n",
    "        elif x1[i] == 'A93':\n",
    "            R[2][i]= 1\n",
    "        elif x1[i] == 'A94':\n",
    "            R[3][i]= 1\n",
    "        else:\n",
    "            R[4][i]= 1\n",
    "        \n",
    "    for i in range(len(x2)):\n",
    "        t = int(x2[i])\n",
    "        list2.append(t)\n",
    "\n",
    "    x2=list2    \n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] <= 35 :\n",
    "            R[5][i]= 1\n",
    "        elif x2[i] >= 55:\n",
    "            R[6][i]= 1\n",
    "        else :\n",
    "            R[7][i]= 1\n",
    "\n",
    "\n",
    "\n",
    "    german_kasper = discrepancy_minimize(R, norm=np.inf, balanced=False, local_search=0.3)\n",
    "    r = FindDisc(R,german_kasper)\n",
    "    i=0\n",
    "\n",
    "    print(r)\n",
    "    ##############################################\n",
    "    german1={}\n",
    "    german2={}\n",
    "    for i in range(german_kasper.shape[0]):\n",
    "        if german_kasper[i]==1:\n",
    "            german1[i]=2\n",
    "            german2[i]=1\n",
    "        else:\n",
    "            german1[i]=1\n",
    "            german2[i]=2\n",
    "\n",
    "    germanu1=german1   \n",
    "    germanu2=german2  \n",
    "    # germanu1=german1[0:698]\n",
    "    \n",
    "    print(r,math.sqrt(n*math.log2(m)))\n",
    "\n",
    "    return germanu1,germanu2,R\n",
    "    #1.0 66.2414153332791\n",
    "def german1_gender_personal():\n",
    "    filename = '3german.txt'\n",
    "    d2 = pd.read_csv(filename,delim_whitespace=True)\n",
    "    n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.iloc[0:699,8]\n",
    "#     x2 = d2.iloc[0:699,12]\n",
    "    n = x1.shape[0]\n",
    "\n",
    "    list2= []  \n",
    "    R = np.zeros((5, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'A91':\n",
    "            R[0][i]= 1\n",
    "        elif x1[i] == 'A92':\n",
    "            R[1][i]= 1\n",
    "        elif x1[i] == 'A93':\n",
    "            R[2][i]= 1\n",
    "        elif x1[i] == 'A94':\n",
    "            R[3][i]= 1\n",
    "        else:\n",
    "            R[4][i]= 1\n",
    "        \n",
    "\n",
    "    german_kasper = discrepancy_minimize(R, norm=np.inf, balanced=False, local_search=0.3)\n",
    "    r = FindDisc(R,german_kasper)\n",
    "    i=0\n",
    "    print(\"discripency is:\")\n",
    "    print(r)\n",
    "    ##############################################\n",
    "    german1={}\n",
    "    german2={}\n",
    "    for i in range(german_kasper.shape[0]):\n",
    "        if german_kasper[i]==1:\n",
    "            german1[i]=2\n",
    "            german2[i]=1\n",
    "        else:\n",
    "            german1[i]=1\n",
    "            german2[i]=2\n",
    "\n",
    "    germanu1=german1   \n",
    "    germanu2=german2  \n",
    "    # germanu1=german1[0:698]\n",
    "    print(r,math.sqrt(n*math.log2(m)))\n",
    "\n",
    "    return germanu1,germanu2,R\n",
    "#     print(r,math.sqrt(n*math.log2(m)))\n",
    "\n",
    "     \n",
    "    #1.0 66.2414153332791    \n",
    "def german1_age():\n",
    "    filename = '3german.txt'\n",
    "    d2 = pd.read_csv(filename,delim_whitespace=True)\n",
    "    n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "#     x1 = d2.iloc[0:699,8]\n",
    "    x2 = d2.iloc[0:699,12]\n",
    "    n = x2.shape[0]\n",
    "\n",
    "    list2= []  \n",
    "    R = np.zeros((3, n), dtype = int)\n",
    "        \n",
    "    for i in range(len(x2)):\n",
    "        t = int(x2[i])\n",
    "        list2.append(t)\n",
    "\n",
    "    x2=list2    \n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] <= 25 :\n",
    "            R[0][i]= 1\n",
    "        elif x2[i] <= 45:\n",
    "            R[1][i]= 1\n",
    "        else :\n",
    "            R[2][i]= 1\n",
    "\n",
    "\n",
    "\n",
    "    german_kasper = discrepancy_minimize(R, norm=np.inf, balanced=False, local_search=0.3)\n",
    "    r = FindDisc(R,german_kasper)\n",
    " \n",
    "\n",
    "    print(r)\n",
    "    ##############################################\n",
    "    german1={}\n",
    "    german2={}\n",
    "    for i in range(german_kasper.shape[0]):\n",
    "        if german_kasper[i]==1:\n",
    "            german1[i]=2\n",
    "            german2[i]=1\n",
    "        else:\n",
    "            german1[i]=1\n",
    "            german2[i]=2\n",
    "\n",
    "    germanu1=german1   \n",
    "    germanu2=german2  \n",
    "    # germanu1=german1[0:698]\n",
    "    \n",
    "#     print(r,math.sqrt(n*math.log2(m)))\n",
    "\n",
    "    return germanu1,germanu2,R\n",
    "    #1.0 66.2414153332791    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['uniform', 'seed', 'randint', 'triangular', 'choice', 'shuffle', 'sample', 'random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "#SVM GERMAN\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "def german_svm():\n",
    "    ###############German#####################\n",
    "    # This Python 3 environment comes with many helpful analytics librarie\n",
    "\n",
    "    # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "    # For example, here's several helpful packages to load in \n",
    "\n",
    " \n",
    "    print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "    # Any results you write to the current directory are saved as output.\n",
    "    #Reading data from CSV file\n",
    "    df = pd.read_csv('../input/3germandata_numeric.txt',delim_whitespace=True,dtype=int32)\n",
    "\n",
    "    #Defining data and label\n",
    "    X = df.iloc[:, 0:23]\n",
    "    y = df.iloc[:, 24]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0,shuffle=False) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "\n",
    "    #Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train_std, y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test_std, y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    y_1=svm.predict(X_train_std)\n",
    "    # print(y_1)\n",
    "\n",
    "    # print(y_1[2:3])\n",
    "    # print(y_1[3:4])\n",
    "    # print(y_1[4:5])\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #      print(y_1[i])\n",
    "\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "    # print(y_train)\n",
    "\n",
    "    # y_train.to_numpy()\n",
    "\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #     print(y_train[i])\n",
    "\n",
    "    ###############################################\n",
    "    print('####Change to colors###############################################')\n",
    "    count=0\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if y_1[i] == y_train[i]:\n",
    "            count=count+1\n",
    "    print(count)    \n",
    "\n",
    "    y_trainx=np.zeros((1,X_train.shape[0]),dtype= int)\n",
    "\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #     if y_train[i]==1:\n",
    "    #         y_trainx[i]=-1\n",
    "    #     else:\n",
    "    #         y_trainx[i]=1\n",
    "\n",
    "\n",
    "\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #     if y_1[i]==1:\n",
    "    #         y_1x[i]=-1\n",
    "    #     else:\n",
    "    #         y_1x[i]=1\n",
    "\n",
    "\n",
    "\n",
    "    print('####Test###############################################')\n",
    "    y_2=svm.predict(X_test_std)\n",
    "\n",
    "\n",
    "    print(y_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # a,b,c  = fair(y_train,germanu1,y_1,0.1)\n",
    "    # print(a)\n",
    "    # print(b)\n",
    "    # print(c)\n",
    "\n",
    "    # for i in range(X_test.shape[0]):\n",
    "    #     y_test_pred[i]=y_1[i:i+1]\n",
    "    #     print(y_test_pred[i])\n",
    "\n",
    "\n",
    "    # y_test.to_numpy()\n",
    "    # for i in range(X_test.shape[0]):\n",
    "    #     y_test1[i]=y_test[i:i+1]\n",
    "    #     print(y_test1[i])\n",
    "\n",
    "\n",
    "    # for i in range(X_test.shape[0]):\n",
    "    #     print(y_2[i])\n",
    "\n",
    "\n",
    "\n",
    "    # for i in range(X_test.shape[0]):\n",
    "    #     print(y_test[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     #Applying Knn\n",
    "    # from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    # knn = KNeighborsClassifier(n_neighbors = 7, p = 2, metric='minkowski')\n",
    "    # knn.fit(X_train_std, y_train)\n",
    "\n",
    "    # print('The accuracy of the Knn classifier on training data is {:.2f}'.format(knn.score(X_train_std, y_train)))\n",
    "    # print('The accuracy of the Knn classifier on test data is {:.2f}'.format(knn.score(X_test_std, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "    # #Applying XGBoost\n",
    "    # import xgboost as xgb\n",
    "\n",
    "    # xgb_clf = xgb.XGBClassifier()\n",
    "    # xgb_clf = xgb_clf.fit(X_train_std, y_train)\n",
    "\n",
    "    # print('The accuracy of the XGBoost classifier on training data is {:.2f}'.format(xgb_clf.score(X_train_std, y_train)))\n",
    "    # print('The accuracy of the XGBoost classifier on test data is {:.2f}'.format(xgb_clf.score(X_test_std, y_test)))\n",
    "\n",
    "\n",
    "    # #Applying Decision Tree\n",
    "    # from sklearn import tree\n",
    "\n",
    "    # #Create tree object\n",
    "    # decision_tree = tree.DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "    # #Train DT based on scaled training set\n",
    "    # decision_tree.fit(X_train_std, y_train)\n",
    "\n",
    "    # #Print performance\n",
    "    # print('The accuracy of the Decision Tree classifier on training data is {:.2f}'.format(decision_tree.score(X_train_std, y_train)))\n",
    "    # print('The accuracy of the Decision Tree classifier on test data is {:.2f}'.format(decision_tree.score(X_test_std, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "    # #Applying RandomForest\n",
    "    # from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    # #Create Random Forest object\n",
    "    # random_forest = RandomForestClassifier()\n",
    "\n",
    "    # #Train model\n",
    "    # random_forest.fit(X_train_std, y_train)\n",
    "\n",
    "    # #Print performance\n",
    "    # print('The accuracy of the Random Forest classifier on training data is {:.2f}'.format(random_forest.score(X_train_std, y_train)))\n",
    "    # print('The accuracy of the Random Forest classifier on test data is {:.2f}'.format(random_forest.score(X_test_std, y_test)))\n",
    "\n",
    "    return y_1,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u1,u2,R= german1()\n",
    "# y_1,y_train=german_svm()\n",
    "# ploting(y_train,u1,y_1,R)\n",
    "#[0.9384835479256081, 0.8884120171673819, 0.8540772532188842, 0.8082975679542204, 0.7195994277539342, 0.7238912732474965, 0.6852646638054364, 0.6494992846924177, 0.586552217453505, 0.530758226037196, 0.4792560801144492]\n",
    "\n",
    "u1,u2,R= german1()\n",
    "y_1,y_train=german_svm()\n",
    "ploting(y_train,u2,y_1,R)\n",
    "#1.0 55.40965510199783\n",
    "#[0.9384835479256081, 0.9113018597997139, 0.8354792560801144, 0.8226037195994278, 0.759656652360515, 0.7024320457796852, 0.6638054363376252, 0.6266094420600858, 0.6022889842632332, 0.5536480686695279, 0.5050071530758226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1,u2,R= german1_gender_personal()\n",
    "y_1,y_train=german_svm()\n",
    "ploting(y_train,u1,y_1,R)\n",
    "\n",
    "# u1,u2,R= german1_gender_personal()\n",
    "# y_1,y_train=german_svm()\n",
    "# ploting(y_train,u2,y_1,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1,u2,R= german1_age()\n",
    "y_1,y_train=german_svm()\n",
    "ploting(y_train,u1,y_1,R)\n",
    "\n",
    "# u1,u2,R= german1_race()\n",
    "# y_1,y_train=german_svm()\n",
    "# ploting(y_train,u2,y_1,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# alpha_l = np.arange(0.0, 1.0, 0.1)\n",
    "# epsilon_l= np.arange(0, 900, 100)\n",
    "\n",
    "# X, Y = np.meshgrid(alpha_l, epsilon_l)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot( 111,projection = '3d')\n",
    "# ax.plot_surface(X, Y,Z)        \n",
    "#print(acc1,acc2)   \n",
    "# print(acc1_l)     \n",
    "# print(acc2_l)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# acc1_l=[0.49928469241773965, 0.4592274678111588, 0.37052932761087265, 0.34334763948497854, 0.2989985693848355, 0.296137339055794, 0.296137339055794]\n",
    "# acc2_l=[0.5007153075822603, 0.5407725321888412, 0.6294706723891274, 0.6566523605150214, 0.7010014306151645, 0.703862660944206, 0.703862660944206]\n",
    "# plt.axis([0, 28000, 0, 100])\n",
    "# plt.xlabel('Fairness(Alpha)')\n",
    "# plt.ylabel('Train Accuracy')\n",
    "# plt.title('Accuracy V/S Fairness tradeoff for ProPublica violent dataset')\n",
    "# # \n",
    "# var = np.linspace(0, 40, 10) \n",
    "# plt.plot(epsilon_l,acc1_l)   \n",
    "# plt.plot(epsilon_l,acc2_l)\n",
    "# plt.legend([\"Experimental LP\", \"Experimental  LP\"])\n",
    "# plt.show() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################LP -- Random--------------------\n",
    "\n",
    "\n",
    "# y_1,y_train=german_svm()\n",
    "# u1,u2,R=min_max_lp_all()\n",
    "# ploting(y_train,u1,y_1,R)\n",
    "#x-actual a=min_max_lp_color b=classifier R\n",
    "#[0.9384835479256081, 0.9041487839771102, 0.8497854077253219, 0.8412017167381974, 0.7582260371959942, 0.7296137339055794, 0.6952789699570815, 0.6337625178826896, 0.5937052932761088, 0.5608011444921316, 0.5178826895565093]\n",
    "\n",
    "\n",
    "# y_1,y_train=german_svm()\n",
    "# u1,u2,R=min_max_lp_all()\n",
    "# ploting(y_train,u2,y_1,R)\n",
    "#x-actual a=min_max_lp_color b=classifier R\n",
    "#[0.9384835479256081, 0.9055793991416309, 0.844062947067239, 0.804005722460658, 0.7610872675250357, 0.7010014306151645, 0.6638054363376252, 0.6323319027181689, 0.6094420600858369, 0.5493562231759657, 0.5007153075822603]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 LP -RANDOM\n",
    "#PROPUBLICA MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all():\n",
    "    filename = '3german.txt'\n",
    "    d2 = pd.read_csv(filename,delim_whitespace=True)\n",
    "    n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.iloc[0:699,8]\n",
    "    x2 = d2.iloc[0:699,12]\n",
    "    n = x2.shape[0]\n",
    "    list2= []  \n",
    "    R = np.zeros((8, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'A91':\n",
    "            R[0][i]= 1\n",
    "        elif x1[i] == 'A92':\n",
    "            R[1][i]= 1\n",
    "        elif x1[i] == 'A93':\n",
    "            R[2][i]= 1\n",
    "        elif x1[i] == 'A94':\n",
    "            R[3][i]= 1\n",
    "        else:\n",
    "            R[4][i]= 1\n",
    "        \n",
    "    for i in range(len(x2)):\n",
    "        t = int(x2[i])\n",
    "        list2.append(t)\n",
    "\n",
    "    x2=list2    \n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] <= 35 :\n",
    "            R[5][i]= 1\n",
    "        elif x2[i] >= 55:\n",
    "            R[6][i]= 1\n",
    "        else :\n",
    "            R[7][i]= 1\n",
    "\n",
    "    \n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "\n",
    "\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "    print(range(n)) \n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n):\n",
    "        var=str(i)\n",
    "        X[i]=p.LpVariable(var,0,1,cat='Integer')\n",
    "    X[n] =  p.LpVariable(\"z\",lowBound=0)\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob += X[n] \n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective))  # The solution status \n",
    "    german1={}\n",
    "    german2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            german1[i]=1 \n",
    "            german2[i]=2\n",
    "        else:\n",
    "            german1[i]=2\n",
    "            german2[i]=1\n",
    "    germanu1=german1  \n",
    "    germanu2=german2  \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective))  \n",
    "    return germanu1,germanu2,R    \n",
    "# print(p.value(Lp_prob.objective))   \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########2 LP ##################1 LP-LP(flip-proportions)LP epsilon- svm\n",
    "y_1,y_train=german_svm()\n",
    "maxi=0\n",
    "acc1_l=[]\n",
    "acc2_l=[]\n",
    "epsilon_l=[]\n",
    "for eps in range(0,700,100) :\n",
    "    count1=0\n",
    "    count2=0\n",
    "    u1,u2,R=min_max_lp_all(eps)\n",
    "    \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j]):\n",
    "                count1+=1\n",
    "    acc1=float(count1/y_train.shape[0])        \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j]):\n",
    "                count2+=1\n",
    "    acc2=float(count2/y_train.shape[0])        \n",
    "    epsilon_l.append(eps)\n",
    "    acc2_l.append(acc2)\n",
    "    acc1_l.append(acc1)\n",
    "    print(acc1,acc2)   \n",
    "print(acc1_l)     \n",
    "print(acc2_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####2 LP-prop\n",
    "#German MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all(eps):\n",
    "    filename = '3german.txt'\n",
    "    d2 = pd.read_csv(filename,delim_whitespace=True)\n",
    "    n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.iloc[0:699,8]\n",
    "    x2 = d2.iloc[0:699,12]\n",
    "    n = x2.shape[0]\n",
    "    list2= []  \n",
    "    R = np.zeros((8, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'A91':\n",
    "            R[0][i]= 1\n",
    "        elif x1[i] == 'A92':\n",
    "            R[1][i]= 1\n",
    "        elif x1[i] == 'A93':\n",
    "            R[2][i]= 1\n",
    "        elif x1[i] == 'A94':\n",
    "            R[3][i]= 1\n",
    "        else:\n",
    "            R[4][i]= 1\n",
    "        \n",
    "    for i in range(len(x2)):\n",
    "        t = int(x2[i])\n",
    "        list2.append(t)\n",
    "\n",
    "    x2=list2    \n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] <= 35 :\n",
    "            R[5][i]= 1\n",
    "        elif x2[i] >= 55:\n",
    "            R[6][i]= 1\n",
    "        else :\n",
    "            R[7][i]= 1\n",
    "\n",
    "    \n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "\n",
    "\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "    print(range(n)) \n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n):\n",
    "        var=str(i)\n",
    "        X[i]=p.LpVariable(var,0,1,cat='Integer')\n",
    "    X[n] =  p.LpVariable(\"z\",lowBound=0)\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob += X[n] \n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "\n",
    "    Lp_prob += X[n] >=eps\n",
    "    Lp_prob += X[n] <=700\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective))  # The solution status \n",
    "    german1={}\n",
    "    german2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            german1[i]=1 \n",
    "            german2[i]=2\n",
    "        else:\n",
    "            german1[i]=2\n",
    "            german2[i]=1\n",
    "    germanu1=german1  \n",
    "    germanu2=german2  \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective))  \n",
    "    return germanu1,germanu2,R    \n",
    "# print(p.value(Lp_prob.objective))   \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################3LP3 - LP SUM\n",
    "########################LP -- Random--------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "u1,u2,R=min_sum_lp_all()\n",
    "y_1,y_train=german_svm()\n",
    "a= ploting(y_train,u1,y_1,R)\n",
    "#x-actual a=min_max_lp_color b=classifier R\n",
    "\n",
    "\n",
    "\n",
    "#x-actual a=min_max_lp_color b=classifier R\n",
    "\n",
    "# y_1,y_train=german_svm()\n",
    "# u1,u2,R=min_sum_lp_all()\n",
    "# a= ploting(y_train,u2,y_1,R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PROPUBLICA MIN SUM CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_sum_lp_all():\n",
    "    filename = '3german.txt'\n",
    "    d2 = pd.read_csv(filename,delim_whitespace=True)\n",
    "    n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.iloc[0:699,8]\n",
    "    x2 = d2.iloc[0:699,12]\n",
    "    n = x2.shape[0]\n",
    "\n",
    "    list2= []  \n",
    "    R = np.zeros((8, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'A91':\n",
    "            R[0][i]= 1\n",
    "        elif x1[i] == 'A92':\n",
    "            R[1][i]= 1\n",
    "        elif x1[i] == 'A93':\n",
    "            R[2][i]= 1\n",
    "        elif x1[i] == 'A94':\n",
    "            R[3][i]= 1\n",
    "        else:\n",
    "            R[4][i]= 1\n",
    "        \n",
    "    for i in range(len(x2)):\n",
    "        t = int(x2[i])\n",
    "        list2.append(t)\n",
    "\n",
    "    x2=list2    \n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] <= 35 :\n",
    "            R[5][i]= 1\n",
    "        elif x2[i] >= 55:\n",
    "            R[6][i]= 1\n",
    "        else :\n",
    "            R[7][i]= 1  \n",
    "    \n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "    # Create a LP Minimization problem \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "\n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "\n",
    "    X=np.zeros(n+m,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n+m):\n",
    "        var=str(i)\n",
    "        if(i<n):##n\n",
    "            X[i]=p.LpVariable(var,lowBound=0,upBound=1)\n",
    "        else:##m\n",
    "            X[i] =  p.LpVariable(var,lowBound=0,upBound=n)\n",
    "            \n",
    "         \n",
    "    #########objective function#####################\n",
    "    Lp_prob +=  p.lpSum([X[i+n] for i in range(m)])\n",
    "    ###############################################\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "\n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status])   # The solution status \n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            racidivism1[i]=1 \n",
    "            racidivism2[i]=2\n",
    "        else:\n",
    "            racidivism1[i]=2\n",
    "            racidivism2[i]=1\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2          \n",
    "        #   print(p.value(X[i]))\n",
    "    return racidivismu1,racidivismu2,R \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13ProPublica_violent_racidivism.csv\n",
      "1ProPublica_racidivism.csv\n",
      "3germandata_numeric.txt\n",
      "\n",
      "There are 699 samples in the training set and 300 samples in the test set\n",
      "The accuracy of the SVM classifier on training data is 0.94\n",
      "The accuracy of the SVM classifier on test data is 0.76\n",
      "####Train prediction Label###############################################\n",
      "####Actual Train Label###############################################\n",
      "####Change to colors###############################################\n",
      "656\n",
      "####Test###############################################\n",
      "[1 1 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 1 1\n",
      " 1 1 2 2 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
      " 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1\n",
      " 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 1 2 1]\n",
      "0      1\n",
      "1     -1\n",
      "2     -1\n",
      "3      1\n",
      "4     -1\n",
      "      ..\n",
      "694   -1\n",
      "695   -1\n",
      "696   -1\n",
      "697   -1\n",
      "698   -1\n",
      "Name: 1.7, Length: 699, dtype: int32\n",
      "range(0, 699)\n",
      "Optimal\n",
      "discripency is:\n",
      "117.0\n",
      "117.0\n",
      "0.5851216022889842 0.41487839771101576\n",
      "347 62\n",
      "145 145\n",
      "0      1\n",
      "1     -1\n",
      "2     -1\n",
      "3      1\n",
      "4     -1\n",
      "      ..\n",
      "694   -1\n",
      "695   -1\n",
      "696   -1\n",
      "697   -1\n",
      "698   -1\n",
      "Name: 1.7, Length: 699, dtype: int32\n",
      "range(0, 699)\n",
      "Optimal\n",
      "discripency is:\n",
      "117.0\n",
      "117.0\n",
      "0.5622317596566524 0.43776824034334766\n",
      "339 54\n",
      "153 153\n",
      "0      1\n",
      "1     -1\n",
      "2     -1\n",
      "3      1\n",
      "4     -1\n",
      "      ..\n",
      "694   -1\n",
      "695   -1\n",
      "696   -1\n",
      "697   -1\n",
      "698   -1\n",
      "Name: 1.7, Length: 699, dtype: int32\n",
      "range(0, 699)\n",
      "Optimal\n",
      "discripency is:\n",
      "200.0\n",
      "200.0\n",
      "0.5965665236051502 0.4034334763948498\n",
      "351 66\n",
      "141 141\n",
      "0      1\n",
      "1     -1\n",
      "2     -1\n",
      "3      1\n",
      "4     -1\n",
      "      ..\n",
      "694   -1\n",
      "695   -1\n",
      "696   -1\n",
      "697   -1\n",
      "698   -1\n",
      "Name: 1.7, Length: 699, dtype: int32\n",
      "range(0, 699)\n",
      "Optimal\n",
      "discripency is:\n",
      "300.0\n",
      "300.0\n",
      "0.6366237482117311 0.36337625178826893\n",
      "365 80\n",
      "127 127\n",
      "0      1\n",
      "1     -1\n",
      "2     -1\n",
      "3      1\n",
      "4     -1\n",
      "      ..\n",
      "694   -1\n",
      "695   -1\n",
      "696   -1\n",
      "697   -1\n",
      "698   -1\n",
      "Name: 1.7, Length: 699, dtype: int32\n",
      "range(0, 699)\n",
      "Optimal\n",
      "discripency is:\n",
      "400.0\n",
      "400.0\n",
      "0.6337625178826896 0.36623748211731044\n",
      "364 79\n",
      "128 128\n",
      "0      1\n",
      "1     -1\n",
      "2     -1\n",
      "3      1\n",
      "4     -1\n",
      "      ..\n",
      "694   -1\n",
      "695   -1\n",
      "696   -1\n",
      "697   -1\n",
      "698   -1\n",
      "Name: 1.7, Length: 699, dtype: int32\n",
      "range(0, 699)\n",
      "Optimal\n",
      "discripency is:\n",
      "500.0\n",
      "500.0\n",
      "0.5565092989985694 0.4434907010014306\n",
      "337 52\n",
      "155 155\n",
      "0      1\n",
      "1     -1\n",
      "2     -1\n",
      "3      1\n",
      "4     -1\n",
      "      ..\n",
      "694   -1\n",
      "695   -1\n",
      "696   -1\n",
      "697   -1\n",
      "698   -1\n",
      "Name: 1.7, Length: 699, dtype: int32\n",
      "range(0, 699)\n",
      "Optimal\n",
      "discripency is:\n",
      "600.0\n",
      "600.0\n",
      "0.5565092989985694 0.4434907010014306\n",
      "337 52\n",
      "155 155\n",
      "[0.5851216022889842, 0.5622317596566524, 0.5965665236051502, 0.6366237482117311, 0.6337625178826896, 0.5565092989985694, 0.5565092989985694]\n",
      "[0.41487839771101576, 0.43776824034334766, 0.4034334763948498, 0.36337625178826893, 0.36623748211731044, 0.4434907010014306, 0.4434907010014306]\n"
     ]
    }
   ],
   "source": [
    "###############LP-4 min max with accuracy########################\n",
    "import numpy as np\n",
    "y_1,y_train=german_svm()\n",
    "maxi=0\n",
    "acc1_l=[]\n",
    "acc2_l=[]\n",
    "epsilon_l=[]\n",
    "\n",
    "# for i in range(y_train.shape[0]):\n",
    "#         if y_train[i] == 1 :\n",
    "#             y_train[i]= -1\n",
    "#         else:          \n",
    "#             y_train[i]= 1\n",
    "\n",
    "#[0.5851216022889842, 0.5622317596566524, 0.5965665236051502, 0.6366237482117311, 0.6337625178826896, 0.5565092989985694, 0.5565092989985694]\n",
    "#[0.41487839771101576, 0.43776824034334766, 0.4034334763948498, 0.36337625178826893, 0.36623748211731044, 0.4434907010014306, 0.4434907010014306]\n",
    "\n",
    "for i in range(y_train.shape[0]):\n",
    "        if y_train[i] == 1 :\n",
    "            y_train[i]= 1\n",
    "        else:          \n",
    "            y_train[i]= -1\n",
    "            \n",
    "#[0.5507868383404864, 0.5851216022889842, 0.5994277539341917, 0.5736766809728183, 0.5622317596566524, 0.5536480686695279, 0.5536480686695279]\n",
    "#[0.4492131616595136, 0.41487839771101576, 0.4005722460658083, 0.4263233190271817, 0.43776824034334766, 0.44635193133047213, 0.44635193133047213]            \n",
    "    \n",
    "for eps in range(0,700,100) :\n",
    "    count1=0\n",
    "    count2=0\n",
    "    u1,u2,R=min_max_lp_all(eps,y_train)\n",
    "    \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j]):\n",
    "                count1+=1\n",
    "    acc1=float(count1/y_train.shape[0])        \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j]):\n",
    "                count2+=1\n",
    "    acc2=float(count2/y_train.shape[0])        \n",
    "    epsilon_l.append(eps)\n",
    "    acc2_l.append(acc2)\n",
    "    acc1_l.append(acc1)\n",
    "    print(acc1,acc2)\n",
    "    \n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j] and u1[j]==-1):\n",
    "                c1+=1       \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j] and u1[j]==1):\n",
    "                c2+=1\n",
    "    print(c1,c2)\n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j] and u2[j]==-1):\n",
    "                c1+=1       \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j] and u2[j]==1):\n",
    "                c2+=1\n",
    "    print(c1,c2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(acc1_l)     \n",
    "print(acc2_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############LP-4 with accuracy########################\n",
    "####2 LP-prop\n",
    "#German MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all(eps,r):\n",
    "   \n",
    "    filename = '3german.txt'\n",
    "    d2 = pd.read_csv(filename,delim_whitespace=True)\n",
    "    n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    \n",
    "    \n",
    "    print(r)\n",
    "    \n",
    "    x1 = d2.iloc[0:699,8]\n",
    "    x2 = d2.iloc[0:699,12]\n",
    "    n = x2.shape[0]\n",
    "    list2= []  \n",
    "    R = np.zeros((8, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'A91':\n",
    "            R[0][i]= 1\n",
    "        elif x1[i] == 'A92':\n",
    "            R[1][i]= 1\n",
    "        elif x1[i] == 'A93':\n",
    "            R[2][i]= 1\n",
    "        elif x1[i] == 'A94':\n",
    "            R[3][i]= 1\n",
    "        else:\n",
    "            R[4][i]= 1\n",
    "        \n",
    "    for i in range(len(x2)):\n",
    "        t = int(x2[i])\n",
    "        list2.append(t)\n",
    "\n",
    "    x2=list2    \n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] <= 35 :\n",
    "            R[5][i]= 1\n",
    "        elif x2[i] >= 55:\n",
    "            R[6][i]= 1\n",
    "        else :\n",
    "            R[7][i]= 1\n",
    "\n",
    "    \n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "\n",
    "\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "    print(range(n)) \n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "    X=np.zeros(n+2,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n):\n",
    "        var=str(i)\n",
    "        X[i]=p.LpVariable(var,lowBound=0,upBound=1,cat='Integer')\n",
    "    X[n] =  p.LpVariable(\"z1\",lowBound=0)\n",
    "    X[n+1] =  p.LpVariable(\"z2\",lowBound=0)\n",
    "\n",
    "    #########objective function#####################\n",
    "    \n",
    "    Lp_prob += X[n] + X[n+1]\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "    ##### r(y_train values real labels of data)\n",
    "    Lp_prob += X[n+1] >= p.lpSum([2*(X[j]-0.5)-   r[j] for j in range(n)])\n",
    "    Lp_prob += X[n+1] >= p.lpSum([-1*2*(X[j]-0.5)+  r[j] for j in range(n)])\n",
    "\n",
    "    Lp_prob += X[n] >=eps\n",
    "    Lp_prob += X[n] <=700\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective)) \n",
    "    w=p.value(Lp_prob.objective)-p.value(X[n+1])\n",
    "    print(w)\n",
    "    # The solution status \n",
    "    german1={}\n",
    "    german2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            german1[i]=1 \n",
    "            german2[i]=-1\n",
    "        else:\n",
    "            german1[i]=-1\n",
    "            german2[i]=1\n",
    "    germanu1=german1  \n",
    "    germanu2=german2  \n",
    "    \n",
    "    return germanu1,germanu2,R    \n",
    "# print(p.value(Lp_prob.objective))   \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13ProPublica_violent_racidivism.csv\n",
      "1ProPublica_racidivism.csv\n",
      "3germandata_numeric.txt\n",
      "\n",
      "There are 699 samples in the training set and 300 samples in the test set\n",
      "The accuracy of the SVM classifier on training data is 0.94\n",
      "The accuracy of the SVM classifier on test data is 0.76\n",
      "####Train prediction Label###############################################\n",
      "####Actual Train Label###############################################\n",
      "####Change to colors###############################################\n",
      "656\n",
      "####Test###############################################\n",
      "[1 1 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 1 1\n",
      " 1 1 2 2 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
      " 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1\n",
      " 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 1 2 1]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3fa1c8bd6ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mFns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mMs\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#####################-----LP-epsilon--with---accuracy-----2----######################\n",
    "\n",
    "# seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "# np.random.seed(SEED)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(data.shape[0])\n",
    "# print(data.shape[1])\n",
    "\n",
    "\n",
    "y_1,y_train = german_svm()\n",
    "#####################################################\n",
    "\n",
    "Ms=0\n",
    "Mns=0\n",
    "Fs=0\n",
    "Fns=0\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(data[j][2]==1 and y_train[j]==1):\n",
    "            Ms+=1       \n",
    "\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(data[j][2]==1 and y_train[j]==-1):\n",
    "            Mns+=1\n",
    "\n",
    "\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(data[j][2]==0 and y_train[j]==1):\n",
    "            Fs+=1       \n",
    "\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(data[j][2]==0 and y_train[j]==-1):\n",
    "            Fns+=1\n",
    "\n",
    "\n",
    "######################################################\n",
    "print(\"actual\")\n",
    "ALL=0\n",
    "ALL=Ms+Mns+Fs+Fns\n",
    "print(ALL)\n",
    "print(\"total males,female\")\n",
    "M=0\n",
    "F=0\n",
    "M=Ms+Mns\n",
    "F=Fs+Fns\n",
    "print(M,F)\n",
    "print(\"total male select,not select\")\n",
    "print(Ms,Mns)\n",
    "print(\"total female select,not select\")\n",
    "print(Fs,Fns)\n",
    "\n",
    "\n",
    "\n",
    "#####################################################\n",
    "# a,b,c,d=ploting(y_train,u1,y_1,R)\n",
    "# a,b,c,d=ploting(y_train,u2,y_1,R)\n",
    "\n",
    "maxi=0\n",
    "acc1_l=[]\n",
    "acc2_l=[]\n",
    "epsilon_l=[]\n",
    "DI1=[]\n",
    "DI2=[]\n",
    "for eps in range(0,1300,100) :\n",
    "    count1=0\n",
    "    count2=0\n",
    "    u1,u2,R=min_max_lp_all(eps,y_train)\n",
    "\n",
    "\n",
    "######################################Disp_impact###########\n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==1 and u1[j]==1 ):\n",
    "                c1+=1       \n",
    "\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==1 and u1[j]==-1 ):\n",
    "                c2+=1\n",
    "    c1=float(c1/M)\n",
    "    c2=float(c2/M)\n",
    "    print(c1)\n",
    "    c3=0\n",
    "    c4=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==0 and u1[j]==1 ):\n",
    "                c3+=1       \n",
    "\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==0 and u1[j]==-1 ):\n",
    "                c4+=1\n",
    "   \n",
    "    c3=float(c3/F)\n",
    "    c4=float(c4/F)\n",
    "    print(c3)\n",
    "    \n",
    "    cx=c1-c3\n",
    "    DIa=cx\n",
    "    DI1.append(DIa)\n",
    "    \n",
    "    \n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==1 and u2[j]==1 ):\n",
    "                c1+=1       \n",
    "\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==1 and u2[j]==-1 ):\n",
    "                c2+=1\n",
    "    c1=float(c1/M)\n",
    "    c2=float(c2/M)\n",
    "    print(c1)\n",
    "    c3=0\n",
    "    c4=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==0 and u2[j]==1 ):\n",
    "                c3+=1       \n",
    "\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==0 and u2[j]==-1 ):\n",
    "                c4+=1\n",
    "   \n",
    "    c3=float(c3/F)\n",
    "    c4=float(c4/F)\n",
    "    print(c3)\n",
    "    cx=c1-c3\n",
    "    DIb=cx\n",
    "    DI2.append(DIb)\n",
    "\n",
    "################################################ \n",
    "\n",
    "\n",
    "    \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j]):\n",
    "                count1+=1\n",
    "    acc1=float(count1/y_train.shape[0])        \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j]):\n",
    "                count2+=1\n",
    "    acc2=float(count2/y_train.shape[0])        \n",
    "    epsilon_l.append(eps)\n",
    "    acc2_l.append(acc2)\n",
    "    acc1_l.append(acc1)\n",
    "    print(acc1,acc2)   \n",
    "print(acc1_l)     \n",
    "print(acc2_l)\n",
    "print(\"Disparate Impact\")\n",
    "print(DI1)     \n",
    "print(DI2)\n",
    "print(epsilon_l)\n",
    "#     print(y_train.shape[0])\n",
    "#     count3=0\n",
    "#     count1=0\n",
    "#     count2=0\n",
    "#     for j in range(y_train.shape[0]):\n",
    "#                 if(y_train[j]==1):\n",
    "#                     count3+=1\n",
    "   \n",
    "#     for i in range(y_train.shape[0]):    \n",
    "#         if y_train[i]==u1[i] and y_train[i]==1 :\n",
    "#             count1+=1\n",
    "#         if y_train[i]==u2[i] and y_train[i]==1 :\n",
    "#             count2+=1\n",
    "#     print(count3)        \n",
    "#     print(count1)\n",
    "#     print(count2)\n",
    "#     count3=0\n",
    "#     count1=0\n",
    "#     count2=0\n",
    "#     for j in range(y_train.shape[0]):\n",
    "#                 if(y_train[j]==-1):\n",
    "#                     count3+=1\n",
    "   \n",
    "#     for i in range(y_train.shape[0]):    \n",
    "#         if y_train[i]==u1[i] and y_train[i]==-1 :\n",
    "#             count1+=1\n",
    "#         if y_train[i]==u2[i] and y_train[i]==-1 :\n",
    "#             count2+=1\n",
    "#     print(count3)        \n",
    "#     print(count1)\n",
    "#     print(count2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############LP-4 with accuracy 22222222222nd way########################\n",
    "####2 LP-prop\n",
    "#German MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all(eps,r):\n",
    "   \n",
    "    filename = '3german.txt'\n",
    "    d2 = pd.read_csv(filename,delim_whitespace=True)\n",
    "    n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    \n",
    "    \n",
    "    x1 = d2.iloc[0:699,8]\n",
    "    x2 = d2.iloc[0:699,12]\n",
    "    n = x2.shape[0]\n",
    "    list2= []  \n",
    "    R = np.zeros((5, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'A91':\n",
    "            R[0][i]= 1\n",
    "        elif x1[i] == 'A92':\n",
    "            R[1][i]= 1\n",
    "        elif x1[i] == 'A93':\n",
    "            R[2][i]= 1\n",
    "        elif x1[i] == 'A94':\n",
    "            R[3][i]= 1\n",
    "        else:\n",
    "            R[4][i]= 1\n",
    "        \n",
    "#     for i in range(len(x2)):\n",
    "#         t = int(x2[i])\n",
    "#         list2.append(t)\n",
    "\n",
    "#     x2=list2    \n",
    "\n",
    "#     for i in range(n):\n",
    "#         if x2[i] <= 35 :\n",
    "#             R[5][i]= 1\n",
    "#         elif x2[i] >= 55:\n",
    "#             R[6][i]= 1\n",
    "#         else :\n",
    "#             R[7][i]= 1\n",
    "\n",
    "    \n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "    print(range(n)) \n",
    "    #X[n]=z() n last value of X\n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    Y=np.zeros(n,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "    for i in range(n):\n",
    "        var1=str(i)\n",
    "        var2=str(i+n+2)\n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "        Y[i]=p.LpVariable(var2,lowBound=0)\n",
    "        \n",
    "    X[n] =  p.LpVariable(\"z1\",lowBound=0)\n",
    "  \n",
    "\n",
    "    #########objective function#####################\n",
    "    \n",
    "    Lp_prob += X[n] + p.lpSum([Y[j] for j in range(n)])\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "            \n",
    "    for i in range(2*n):\n",
    "        if i<n:\n",
    "            Lp_prob += Y[i] >= X[i]-r[i]\n",
    "        else:        \n",
    "            Lp_prob += Y[i-n] >= -1*(X[i-n]-r[i-n])       \n",
    "    ##### r(y_train values real labels of data)\n",
    "    \n",
    "  \n",
    "\n",
    "    Lp_prob += X[n] >=eps\n",
    "    Lp_prob += X[n] <=700\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "#     x=0\n",
    "#     for i in range(n):\n",
    "#         x=x+p.value(Y[j])\n",
    "        \n",
    "    w=p.value(X[n])\n",
    "    print(w) \n",
    "    # The solution status \n",
    "    german1={}\n",
    "    german2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            german1[i]=1 \n",
    "            german2[i]=-1\n",
    "        else:\n",
    "            german1[i]=-1\n",
    "            german2[i]=1\n",
    "    germanu1=german1  \n",
    "    germanu2=german2  \n",
    "    \n",
    "    return germanu1,germanu2,R    \n",
    "# print(p.value(Lp_prob.objective))   \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
