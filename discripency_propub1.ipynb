{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as lin\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#Assume the first r rows of a forms an orthonormal basis\n",
    "#Returns the projection of x onto the orthogonal complement of the rows of a\n",
    "#scaled to unit length\n",
    "def make_orthogonal(a,r,x):\n",
    "    if np.linalg.norm(x)<1e-8:\n",
    "        return None\n",
    "    if r==0:\n",
    "        return x/np.linalg.norm(x)\n",
    "    u = x\n",
    "    for j in range(0,int(r/100)):\n",
    "        u = u - a[range(j*100,(j+1)*100)].T @ (a[range(j*100,(j+1)*100)] @ u)\n",
    "    for j in range(int(r/100)*100,r):\n",
    "        u = u - np.inner(u,a[j]) * a[j]\n",
    "    norm = np.linalg.norm(u)\n",
    "    if norm < np.linalg.norm(x)/100:\n",
    "        return None\n",
    "    u = u/norm\n",
    "    return u\n",
    "\n",
    "def round_coloring(a,x,norm = np.inf, balanced=False):\n",
    "    start = time.time()\n",
    "    n = a.shape[1]\n",
    "    abs = np.absolute(x)\n",
    "    live = (abs < 1.0-1e-4)\n",
    "    #first sample each entry\n",
    "    samples = np.random.random_sample(n)\n",
    "    signs = np.ones(n)\n",
    "    signs[samples < (1.0-abs)/2.0] = -1\n",
    "    flipped = np.multiply(x,signs)\n",
    "    y = np.sign(flipped)\n",
    "    y[y==0]=1\n",
    "    #then try all assignments to the coordinates that were live\n",
    "    num_live = sum(live)\n",
    "    if num_live<=10:\n",
    "        live_indices = [i for i, x in enumerate(live) if x]\n",
    "        ay = a@y\n",
    "        sub_a = a[:,live_indices]\n",
    "        sub_y = y[live_indices]\n",
    "        sub_ay = sub_a @ sub_y\n",
    "        a_outside = ay - sub_ay\n",
    "        best_sub_y = sub_y\n",
    "        best_norm = np.linalg.norm(ay,ord=norm)\n",
    "        sign_flips = np.ones(num_live)\n",
    "        while True:\n",
    "            at = 0\n",
    "            while at<num_live and sign_flips[at]==-1:\n",
    "                sign_flips[at]=1\n",
    "                at = at+1\n",
    "            if at==num_live:\n",
    "                break\n",
    "            sign_flips[at]=-1\n",
    "            new_sub_y = np.multiply(sub_y,sign_flips)\n",
    "            new_sub_ay = sub_a @ new_sub_y\n",
    "            new_ay = a_outside + new_sub_ay\n",
    "            new_norm = np.linalg.norm(new_ay,ord=norm)\n",
    "            if new_norm < best_norm:\n",
    "                best_norm = new_norm\n",
    "                best_sub_y = new_sub_y\n",
    "        y[live_indices] = best_sub_y\n",
    "    #balance the vector in case we need to\n",
    "    if balanced:\n",
    "        while True:\n",
    "            toFlip = 1\n",
    "            if sum(y==1) < n/2:\n",
    "                toFlip = -1\n",
    "            ofToFlip = sum(y==toFlip)\n",
    "            needToFlip = int(ofToFlip-n/2)\n",
    "            if needToFlip==0:\n",
    "                break\n",
    "            listOfToFlip = [i for i, x in enumerate(y) if x==toFlip]\n",
    "            ay = a @ y\n",
    "            best_norm = 1e27\n",
    "            #try all single flips\n",
    "            best_to_flip = 0\n",
    "            for i in listOfToFlip:\n",
    "                col = a[:,i]\n",
    "                new_ay = ay - (2*col*y[i])\n",
    "                new_norm = np.linalg.norm(new_ay,ord=norm)\n",
    "                if new_norm < best_norm:\n",
    "                    best_norm = new_norm\n",
    "                    best_to_flip = i\n",
    "            y[best_to_flip] = -y[best_to_flip]\n",
    "    return y\n",
    "\n",
    "def to_square(a,x,balanced=False):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    if n<=m:\n",
    "        return x\n",
    "    live = n\n",
    "    orth = np.zeros((n,n))\n",
    "    is_live = np.ones(n)\n",
    "    num_orth = 0\n",
    "    for i in range(0,m):\n",
    "        p = make_orthogonal(orth,num_orth,a[i])\n",
    "        if not p is None:\n",
    "            orth[num_orth] = p\n",
    "            num_orth = num_orth + 1\n",
    "    if balanced:\n",
    "        all_ones = np.ones(n)\n",
    "        p = make_orthogonal(orth,num_orth,all_ones)\n",
    "        if np.linalg.norm(p) > 0.01:\n",
    "            orth[num_orth] = p\n",
    "            num_orth = num_orth + 1\n",
    "    while num_orth < n and sum(is_live) > 8:\n",
    "        #sample a random vector\n",
    "        g = np.random.randn(n)\n",
    "        #make it orthogonal to all in orth\n",
    "        gamma = make_orthogonal(orth,num_orth,g)\n",
    "        if gamma is None:\n",
    "            break\n",
    "        #set all that are not live to 0 for numerical stability\n",
    "        for i in range(0,n):\n",
    "            if not is_live[i]:\n",
    "                gamma[i] = 0\n",
    "        #find coord that freezes first\n",
    "        delta = 1e30\n",
    "        for i in range(0,n):\n",
    "            if is_live[i] and abs(gamma[i]) > 1e-7:\n",
    "                dist = 0\n",
    "                if gamma[i] * x[i] >= 0:\n",
    "                    dist = (1-abs(x[i]))/abs(gamma[i])\n",
    "                else:\n",
    "                    dist = (1+abs(x[i]))/abs(gamma[i])\n",
    "                if dist < delta:\n",
    "                    delta = dist\n",
    "        if delta > 1e25:\n",
    "            break\n",
    "        x = x + delta * gamma\n",
    "        for i in range(0,n):\n",
    "            if is_live[i] and abs(x[i]) >= 1-1e-6:\n",
    "                is_live[i] = 0\n",
    "                e = np.zeros(n)\n",
    "                e[i] = 1\n",
    "                p = make_orthogonal(orth,num_orth,e)\n",
    "                if not p is None:\n",
    "                    orth[num_orth] = p\n",
    "                    num_orth = num_orth+1\n",
    "                    if num_orth>=n:\n",
    "                        break\n",
    "    return x\n",
    "\n",
    "def partial_color(a,x,norm=np.inf,balanced=False):\n",
    "    if norm==np.inf:\n",
    "        return partial_infty_color(a,x,balanced)\n",
    "    if norm==2:\n",
    "        return partial_l2_color(a,x,balanced)\n",
    "\n",
    "def partial_l2_color(a, x, balanced=False):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    delta=1e-5\n",
    "\n",
    "    #count number of live coordinates\n",
    "    abs_x = np.absolute(x)\n",
    "    is_live = (abs_x < 1.0-delta)\n",
    "    initial_is_live = is_live.copy()\n",
    "    live = is_live.sum()\n",
    "    if live<8: \n",
    "        return True\n",
    "    initial_live=live\n",
    "    #extract the live coordinates and columns\n",
    "    y = x[initial_is_live]\n",
    "    b = a[:,initial_is_live]\n",
    "    #compute eigenvectors of bTb\n",
    "    bTb = b.T @ b\n",
    "    w, v = lin.eigh(bTb)\n",
    "    num_iters = 0\n",
    "    was_live = np.ones(initial_live,dtype=bool)\n",
    "    num_frozen = 0\n",
    "    orth = np.zeros((initial_live,initial_live))\n",
    "    num_orth = 0\n",
    "    to_add = v[:,range(initial_live-int(initial_live/2), initial_live)].T\n",
    "    orth[range(0,to_add.shape[0])] = to_add\n",
    "    num_orth = to_add.shape[0]\n",
    "    if balanced:\n",
    "        ones = np.ones(initial_live)\n",
    "        ones = make_orthogonal(orth,num_orth,ones)\n",
    "        if not ones is None:\n",
    "            orth[num_orth] = ones\n",
    "            num_orth = num_orth+1\n",
    "    while int((live*3/2)) > initial_live:\n",
    "        #will have at most 1/3 * initial_live that are frozen\n",
    "        abs_y = np.absolute(y)\n",
    "        #start by freezing new frozen coordinates\n",
    "        is_live = (abs_y < 1.0-delta)\n",
    "        diff = is_live!=was_live\n",
    "        num_diff = diff.sum()\n",
    "        if num_diff>0:\n",
    "            for i in range(0,initial_live):\n",
    "                if diff[i]:\n",
    "                    e = np.zeros(initial_live)\n",
    "                    e[i] = 1\n",
    "                    p = make_orthogonal(orth,num_orth,e)\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_frozen = num_frozen + 1\n",
    "            was_live = is_live\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        num_iters = num_iters+1\n",
    "        ax = a @ x\n",
    "        #sample a random vector\n",
    "        g = np.random.randn(initial_live)\n",
    "        #make it orthogonal to all in orth\n",
    "        gamma = make_orthogonal(orth,num_orth,g)\n",
    "        if gamma is None:\n",
    "            break\n",
    "        #set coords to zero where not live, due to numerical stability\n",
    "        for i in range(0,initial_live):\n",
    "            if not is_live[i]:\n",
    "                gamma[i] = 0\n",
    "        if np.linalg.norm(gamma,ord=np.inf)==0:\n",
    "            break\n",
    "        if np.inner(ax,b @ gamma) > 0:\n",
    "            gamma = -gamma\n",
    "        coord_mult = np.multiply(gamma,y)\n",
    "        val = np.where(coord_mult < 0, (1+abs(y))/(1e-27+abs(gamma)), (1-abs(y))/(1e-27 + abs(gamma)))\n",
    "        val = np.where(is_live, val, 1e27)\n",
    "        z = min(val)\n",
    "        y = y + z*gamma\n",
    "        x[initial_is_live] = y\n",
    "        new_abs_y = np.absolute(y)\n",
    "        is_live = (new_abs_y < 1.0-delta)\n",
    "        live = is_live.sum()\n",
    "    return False\n",
    "\n",
    "def partial_infty_color(a, x, balanced=False):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    delta=1e-5\n",
    "\n",
    "    #count number of live coordinates\n",
    "    abs_x = np.absolute(x)\n",
    "    is_live = (abs_x < 1.0-delta)\n",
    "    initial_is_live = is_live.copy()\n",
    "    live = is_live.sum()\n",
    "    if live<8: \n",
    "        return True\n",
    "    initial_live=live\n",
    "    #extract the live coordinates and columns\n",
    "    y = x[initial_is_live]\n",
    "    b = a[:,initial_is_live]\n",
    "    num_iters = 0\n",
    "    was_live = np.ones(initial_live,dtype=bool)\n",
    "    was_small = np.ones(m,dtype=bool)\n",
    "    orth = np.zeros((initial_live,initial_live))\n",
    "    num_orth = 0\n",
    "    if balanced:\n",
    "        ones = np.ones(initial_live)\n",
    "        ones = ones/np.sqrt(initial_live)\n",
    "        orth[0] = ones\n",
    "        num_orth = num_orth+1\n",
    "    num_frozen = 0\n",
    "    num_big = 0\n",
    "    num_initial = 0\n",
    "    while int((live*5)/4) > initial_live:\n",
    "        #will have at most 1/3 * initial_live that are frozen\n",
    "        #freeze up to 1/3 largest coords\n",
    "        abs_y = np.absolute(y)\n",
    "        #start by freezing new frozen coordinates\n",
    "        is_live = (abs_y < 1.0-delta)\n",
    "        diff = is_live!=was_live\n",
    "        num_diff = diff.sum()\n",
    "        if num_diff>0:\n",
    "            for i in range(0,initial_live):\n",
    "                if diff[i]:\n",
    "                    e = np.zeros(initial_live)\n",
    "                    e[i] = 1\n",
    "                    p = make_orthogonal(orth,num_orth,e)\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_frozen = num_frozen + 1\n",
    "            was_live = is_live\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        #may freeze same number of rows based on abs value\n",
    "        num_iters = num_iters+1\n",
    "        ax = a @ x\n",
    "        abs_ax = np.absolute(ax)\n",
    "        if num_initial < initial_live/4:\n",
    "            sorted_indices = np.argsort(-abs_ax)\n",
    "            for i in range(0, m):\n",
    "                if was_small[sorted_indices[i]]:\n",
    "                    p = make_orthogonal(orth,num_orth,b[sorted_indices[i]])\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_initial = num_initial + 1\n",
    "                    was_small[sorted_indices[i]] = False\n",
    "                    if num_initial >= initial_live/4:\n",
    "                        break\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        if num_big < num_frozen:\n",
    "            sorted_indices = np.argsort(-abs_ax)\n",
    "            for i in range(0,m):\n",
    "                if was_small[sorted_indices[i]]:\n",
    "                    p = make_orthogonal(orth,num_orth,b[sorted_indices[i]])\n",
    "                    if not p is None:\n",
    "                        orth[num_orth] = p\n",
    "                        num_orth = num_orth + 1\n",
    "                        if num_orth>=initial_live:\n",
    "                            break\n",
    "                    num_big = num_big + 1\n",
    "                    was_small[sorted_indices[i]] = False\n",
    "                    if num_big >= num_frozen:\n",
    "                        break\n",
    "        if num_orth>=initial_live:\n",
    "            break\n",
    "        #sample a random vector\n",
    "        g = np.random.randn(initial_live)\n",
    "        #make it orthogonal to all in orth\n",
    "        gamma = make_orthogonal(orth,num_orth,g)\n",
    "        if gamma is None:\n",
    "            break\n",
    "        #set coords to zero where not live, due to numerical stability\n",
    "        for i in range(0,initial_live):\n",
    "            if not is_live[i]:\n",
    "                gamma[i] = 0\n",
    "        if np.linalg.norm(gamma,ord=np.inf)==0:\n",
    "            break\n",
    "        if np.inner(ax,b @ gamma) > 0:\n",
    "            gamma = -gamma\n",
    "        coord_mult = np.multiply(gamma,y)\n",
    "        val = np.where(coord_mult < 0, (1+abs(y))/(1e-27+abs(gamma)), (1-abs(y))/(1e-27 + abs(gamma)))\n",
    "        val = np.where(is_live, val, 1e27)\n",
    "        z = min(val)\n",
    "        y = y + z*gamma\n",
    "        x[initial_is_live] = y\n",
    "        new_abs_y = np.absolute(y)\n",
    "        is_live = (new_abs_y < 1.0-delta)\n",
    "        live = is_live.sum()\n",
    "    return False\n",
    "\n",
    "\n",
    "def local_improvements(a,x,time_limit,norm=np.inf, balanced=False):\n",
    "    ax = a @ x\n",
    "    best_norm = np.linalg.norm(ax,ord=norm)\n",
    "    start_time = time.time()\n",
    "    num_flip = min(7,len(x))\n",
    "    if balanced and num_flip%2==1:\n",
    "        num_flip = num_flip + 1\n",
    "    iters = 0\n",
    "    while True:\n",
    "        iters = iters+1\n",
    "        #Try flipping random coords\n",
    "        for iteration in range(0,a.shape[1]):\n",
    "            sampled_coords = np.random.randint(0,a.shape[1],num_flip)\n",
    "            sampled_coords = np.sort(sampled_coords)\n",
    "            allDistinct=True\n",
    "            for i in range(0,num_flip-1):\n",
    "                if sampled_coords[i]==sampled_coords[i+1]:\n",
    "                    allDistinct=False\n",
    "            if not allDistinct:\n",
    "                continue\n",
    "            if balanced:\n",
    "                #check equal num of +1 and -1\n",
    "                sum_is=0\n",
    "                for i in range(0,num_flip):\n",
    "                    sum_is = sum_is + x[sampled_coords[i]]\n",
    "                if sum_is!=0:\n",
    "                    continue\n",
    "            subcols = a[:,sampled_coords]\n",
    "            subx = [x[index] for index in sampled_coords]\n",
    "            bx = ax - 2*(subcols @ subx)\n",
    "            the_norm = np.linalg.norm(bx,ord=norm)\n",
    "            if the_norm<best_norm:\n",
    "                best_norm = the_norm\n",
    "                for i in sampled_coords:\n",
    "                    x[i] = -x[i]\n",
    "                ax = bx\n",
    "        if time.time()-start_time > time_limit:\n",
    "            break \n",
    "    return x\n",
    "\n",
    "def basic_local_search(a,x,norm,balanced=False):\n",
    "    ax = a@x\n",
    "    best_norm = np.linalg.norm(ax,ord=norm)\n",
    "    improved=True\n",
    "    while improved:\n",
    "        improved=False\n",
    "        #Try flipping single coords\n",
    "        for i in range(0,a.shape[1]):\n",
    "            flipped = ax - 2*x[i]*a[:,i]\n",
    "            if np.linalg.norm(flipped, ord=norm) < best_norm:\n",
    "                if balanced:\n",
    "                    #must find one to swap with\n",
    "                    for j in range(0,a.shape[1]):\n",
    "                        if x[i]==x[j]:\n",
    "                            continue\n",
    "                        final_flipped = flipped - 2*x[j]*a[:,j]\n",
    "                        if np.linalg.norm(final_flipped,ord=norm) < best_norm:\n",
    "                            ax = final_flipped\n",
    "                            x[i] = -x[i]\n",
    "                            x[j] = -x[j]\n",
    "                            best_norm = np.linalg.norm(final_flipped,ord=norm)\n",
    "                            improved=True\n",
    "                            break\n",
    "                else:\n",
    "                    ax = flipped\n",
    "                    x[i] = -x[i]\n",
    "                    best_norm = np.linalg.norm(flipped,ord=norm)\n",
    "                    improved=True\n",
    "    return x\n",
    "\n",
    "def greedy(a,norm,balanced=False):\n",
    "    x = np.zeros(a.shape[1])\n",
    "    if balanced:\n",
    "        so_far = np.zeros(a.shape[0])\n",
    "        for i in range(0,a.shape[1]):\n",
    "            if i%2==1:\n",
    "                continue\n",
    "            test = so_far + a[:,i]\n",
    "            test_minus = so_far - a[:,i]\n",
    "            if i<a.shape[1]-1:\n",
    "                test = test - a[:,i+1]\n",
    "                test_minus = test_minus + a[:,i+1]\n",
    "            if np.linalg.norm(test,ord=norm) < np.linalg.norm(test_minus,ord=norm):\n",
    "                x[i] = 1\n",
    "                if i<a.shape[1]-1:\n",
    "                    x[i+1]=-1\n",
    "            else:\n",
    "                x[i] = -1\n",
    "                if i<a.shape[1]-1:\n",
    "                    x[i+1] = 1\n",
    "    else:\n",
    "        x[0] = 1\n",
    "        so_far = a[:,0]\n",
    "        for i in range(1,a.shape[1]):\n",
    "            test = so_far + a[:,i]\n",
    "            test_minus = so_far - a[:,i]\n",
    "            if np.linalg.norm(test,ord=norm) <  np.linalg.norm(test_minus,ord=norm):\n",
    "                x[i] = 1\n",
    "            else:\n",
    "                x[i] = -1\n",
    "            so_far = so_far + x[i]*a[:,i]\n",
    "    return x\n",
    "\n",
    "def discrepancy_minimize(a, norm=np.inf, balanced=False, local_search=0.3):\n",
    "    n = a.shape[1]\n",
    "    x = np.zeros(n)\n",
    "    start_time = time.time()\n",
    "    x = to_square(a,x,balanced)\n",
    "    while not partial_color(a,x, norm, balanced):\n",
    "        pass\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    y = round_coloring(a,x,norm, balanced)\n",
    "    y = basic_local_search(a,y,norm,balanced)\n",
    "    #check if greedy approach is better\n",
    "    g = greedy(a,norm,balanced)\n",
    "    g = basic_local_search(a,g,norm,balanced)\n",
    "    if np.linalg.norm(a@g,ord=norm) < np.linalg.norm(a@y, ord=norm):\n",
    "        y = g\n",
    "    y = local_improvements(a,y, elapsed*local_search, norm, balanced)\n",
    "    y = basic_local_search(a,y,norm,balanced)\n",
    "    total_elapsed = time.time()-start_time\n",
    "    #make sure we return an int array, not floating\n",
    "    z = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if y[i]==-1:\n",
    "            z[i]=-1\n",
    "        else:\n",
    "            z[i]=1\n",
    "    return z\n",
    "\n",
    "def Com(a):\n",
    "    n = a.shape[0]\n",
    "    b = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if a[i] == 1:\n",
    "            b[i]= 0\n",
    "        else:\n",
    "            b[i]= 1\n",
    "    return b   \n",
    "\n",
    "#python\n",
    "\n",
    "def FindDisc(a, v):\n",
    "    n = a.shape[1]\n",
    "    m = a.shape[0]\n",
    "    disc = 0\n",
    "    for i in range(m):\n",
    "        newdisc = 0\n",
    "        for j in range(n):\n",
    "            newdisc = newdisc + v[j]\n",
    "            #print(newdisc)\n",
    "        modisc = abs(newdisc)\n",
    "        if modisc >= disc:\n",
    "            disc = modisc\n",
    "    return disc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################3ALL Fair#################3\n",
    "from random import *\n",
    "def fair(x,a,b,alpha,R):\n",
    "    #x-actual a=kesper b=classifier\n",
    "    \n",
    "    a_acc=0\n",
    "    b_acc=0\n",
    "    f_acc=0\n",
    "    n= x.shape[0]\n",
    "    f= np.zeros(n) \n",
    "    count=0\n",
    "    acc=0\n",
    "    for i in range(n):\n",
    "        z=random()\n",
    "        if z < alpha:\n",
    "            f[i]= a[i] \n",
    "            count=count+1\n",
    "        else:\n",
    "            f[i]= b[i]\n",
    "                    \n",
    "        \n",
    "    for i in range(n):\n",
    "         if a[i] == x[i]:\n",
    "                a_acc=a_acc+1\n",
    "    for i in range(n):\n",
    "         if b[i] == x[i]:\n",
    "                b_acc=b_acc+1\n",
    "    for i in range(n):\n",
    "         if f[i] == x[i]:\n",
    "                f_acc=f_acc+1\n",
    "\n",
    "    a_acc_percent=a_acc/n            \n",
    "    b_acc_percent=b_acc/n  \n",
    "    f_acc_percent=f_acc/n  \n",
    "    count1=0\n",
    "    count2=0\n",
    "    for i in range(R.shape[1]):\n",
    "        if(R[0,i]==1):\n",
    "            if f[i]==1:\n",
    "                  count1+=1\n",
    "        else:\n",
    "            if f[i]==1:\n",
    "                count2+=1\n",
    "            \n",
    "    ratio=float(count1/count2)  \n",
    "#############################################################\n",
    "    \n",
    "    print(\"###############################\")\n",
    "#     print(f)\n",
    "#     print(x)\n",
    "#     print(b)\n",
    "#     print(a_acc_percent,b_acc_percent)\n",
    "    print(\"###############################\")\n",
    "    #kasper svm final ratio\n",
    "    return a_acc_percent,b_acc_percent,f_acc_percent,ratio\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def ploting(y_train,u1,y_1,R):\n",
    "    alpha1_l=[]\n",
    "    c1_l=[]\n",
    "    ratio_l=[]\n",
    "    \n",
    "    ####### plot################   \n",
    "    for alpha in [0,0.1, 0.2, 0.3 ,0.4,0.5, 0.6,0.7,0.8,0.9,1]:\n",
    "        a,b,c,ratio  = fair(y_train,u1,y_1,alpha,R)\n",
    "        ratio_l.append(ratio)\n",
    "        alpha1_l.append(alpha)\n",
    "        c1_l.append(c)\n",
    "    print(c1_l)\n",
    "    plt.plot( alpha1_l, c1_l, 'ro')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('Fairness(Alpha)')\n",
    "    plt.ylabel('Train Accuracy')\n",
    "    plt.title('Accuracy V/S Fairness tradeoff for ProPublica dataset')\n",
    "    alpha = np.linspace(0, 1, 10) \n",
    "    y = alpha*(min(c1_l) - max(c1_l)) + max(c1_l)\n",
    "    # fig = plt.figure(figsize = (10, 5)) \n",
    "    plt.plot(alpha, y) \n",
    "    plt.legend([\"Experimental\", \"Theoretical\"])\n",
    "    plt.show() \n",
    "#   print(min(c1_l) , max(c1_l))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(\"ratio------------------\")\n",
    "#     alpha1=[0,0.1, 0.2, 0.3 ,0.4,0.5, 0.6,0.7,0.8,0.9,1]\n",
    "#     plt.plot( alpha1, ratio, 'ro')\n",
    "#     plt.axis([0, 1, 0, 20])\n",
    "#     plt.xlabel('Fairness(Alpha)')\n",
    "#     plt.ylabel('Male/Female Ratio')\n",
    "#     plt.title('Variation of bias w.r.t Fairness')\n",
    "#     alpha = np.linspace(0, 1, 10) \n",
    "#     y = 4\n",
    "#     # fig = plt.figure(figsize = (10, 5)) \n",
    "#     plt.plot(1, y) \n",
    "#     plt.show() \n",
    "\n",
    "    return 1\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "def ploting_lp_prop(y_train,u1,y_1,R):\n",
    "    alpha1_l=[]\n",
    "    c1_l=[]\n",
    "    ratio_l=[]\n",
    "    \n",
    "    ####### plot################   \n",
    "    for alpha in [0,0.1, 0.2, 0.3 ,0.4,0.5, 0.6,0.7,0.8,0.9,1]:\n",
    "        a,b,c,ratio  = fair(y_train,u1,y_1,alpha,R)\n",
    "        ratio_l.append(ratio)\n",
    "        alpha1_l.append(alpha)\n",
    "        c1_l.append(c)\n",
    "#     print(c1_l)\n",
    "#     plt.plot( alpha1_l, c1_l, 'ro')\n",
    "#     plt.axis([0, 1, 0, 1])\n",
    "#     plt.xlabel('Fairness(Alpha)')\n",
    "#     plt.ylabel('Train Accuracy')\n",
    "#     plt.title('Accuracy V/S Fairness tradeoff for ProPublica dataset')\n",
    "#     alpha = np.linspace(0, 1, 10) \n",
    "#     y = alpha*(min(c1_l) - max(c1_l)) + max(c1_l)\n",
    "#     # fig = plt.figure(figsize = (10, 5)) \n",
    "#     plt.plot(alpha, y) \n",
    "#     plt.legend([\"Experimental\", \"Theoretical\"])\n",
    "#     plt.show() \n",
    "#   print(min(c1_l) , max(c1_l))\n",
    "    \n",
    "    \n",
    "\n",
    "    return c1_l[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProPub1():\n",
    "    filename = '../input/1ProPublica_racidivism.csv'\n",
    "    d2 = pd.read_csv(filename)\n",
    "    # n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:4315,'sex']\n",
    "    x2 = d2.loc[0:4315,'race']\n",
    "    n=x1.shape[0]\n",
    "    R = np.zeros((7, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'Male':\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] == 'African-American':\n",
    "            R[2][i]= 1\n",
    "        elif x2[i] == 'Caucasian':\n",
    "            R[3][i]= 1\n",
    "        elif x2[i] == 'Hispanic':\n",
    "            R[4][i]= 1\n",
    "        elif x2[i] == 'Asia':\n",
    "            R[5][i]= 1\n",
    "        else:\n",
    "            R[6][i]= 1\n",
    "\n",
    "    racidivism_kasper= discrepancy_minimize(R, norm=np.inf, balanced=False, local_search=0.3)\n",
    "    r = FindDisc(R,racidivism_kasper)\n",
    "    print(r)\n",
    "    ##############################################\n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    for i in range(racidivism_kasper.shape[0]):\n",
    "        if racidivism_kasper[i]==1:\n",
    "            racidivism1[i]=0 \n",
    "            racidivism2[i]=1\n",
    "        else:\n",
    "            racidivism1[i]=1\n",
    "            racidivism2[i]=0\n",
    "\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2  \n",
    "#     print(racidivismu1)\n",
    "#     print(racidivismu2)   \n",
    "    print(\"discripency is:\")\n",
    "    print(r,math.sqrt(n*math.log2(m)))\n",
    "    return racidivismu1,racidivismu2,R\n",
    "\n",
    "def ProPub1_gender():\n",
    "    filename = '../input/1ProPublica_racidivism.csv'\n",
    "    d2 = pd.read_csv(filename)\n",
    "    # n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:4315,'sex']\n",
    "    x2 = d2.loc[0:4315,'race']\n",
    "    n=x1.shape[0]\n",
    "    R = np.zeros((2, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'Male':\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "\n",
    "    racidivism_kasper= discrepancy_minimize(R, norm=np.inf, balanced=False, local_search=0.3)\n",
    "    r = FindDisc(R,racidivism_kasper)\n",
    "    print(r)\n",
    "    ##############################################\n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    for i in range(racidivism_kasper.shape[0]):\n",
    "        if racidivism_kasper[i]==1:\n",
    "            racidivism1[i]=1\n",
    "            racidivism2[i]=0\n",
    "        else:\n",
    "            racidivism1[i]=0\n",
    "            racidivism2[i]=1\n",
    "\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2  \n",
    "#     print(racidivismu1)\n",
    "#     print(racidivismu2)   \n",
    "#     print(r,math.sqrt(n*math.log2(m)))\n",
    "    return racidivismu1,racidivismu2,R\n",
    "def ProPub1_race():\n",
    "    filename = '../input/1ProPublica_racidivism.csv'\n",
    "    d2 = pd.read_csv(filename)\n",
    "    # n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:4315,'sex']\n",
    "    x2 = d2.loc[0:4315,'race']\n",
    "    n=x1.shape[0]\n",
    "    R = np.zeros((5, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x2[i] == 'African-American':\n",
    "            R[0][i]= 1\n",
    "        elif x2[i] == 'Caucasian':\n",
    "            R[1][i]= 1\n",
    "        elif x2[i] == 'Hispanic':\n",
    "            R[2][i]= 1\n",
    "        elif x2[i] == 'Asia':\n",
    "            R[3][i]= 1\n",
    "        else:\n",
    "            R[4][i]= 1\n",
    "\n",
    "    racidivism_kasper= discrepancy_minimize(R, norm=np.inf, balanced=False, local_search=0.3)\n",
    "    r = FindDisc(R,racidivism_kasper)\n",
    "    print(r)\n",
    "    ##############################################\n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    for i in range(racidivism_kasper.shape[0]):\n",
    "        if racidivism_kasper[i]==1:\n",
    "            racidivism1[i]=1 \n",
    "            racidivism2[i]=0\n",
    "        else:\n",
    "            racidivism1[i]=0\n",
    "            racidivism2[i]=1\n",
    "\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2  \n",
    "#     print(racidivismu1)\n",
    "#     print(racidivismu2)   \n",
    "#     print(r,math.sqrt(n*math.log2(m)))\n",
    "    return racidivismu1,racidivismu2,R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#SVM ProPub1\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "from subprocess import check_output\n",
    "def ProPub1_svm():\n",
    "    print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "    # Any results you write to the current directory are saved as output.\n",
    "    #Reading data from CSV file\n",
    "    df = pd.read_csv('../input/1ProPublica_racidivism.csv')\n",
    "    print(df.head())\n",
    "    df=df.drop(columns=['age_cat','c_charge_desc'])\n",
    "\n",
    "    df1 = df.copy()\n",
    "    df1 = pd.get_dummies(df1, columns=['sex','race','c_charge_degree','score_text','sex-race'], prefix = ['sex','race','ccd','st','sr'])\n",
    "    print(df1.loc[:,'two_year_recid'])\n",
    "    print(df1.shape[1])\n",
    "    df1['2_year_racidivism'] = df1.loc[:,'two_year_recid']\n",
    "    print(df1.shape[1])\n",
    "    df1=df1.drop(columns=['two_year_recid'])\n",
    "    print(df1.head())\n",
    "    print(df1.shape[1])\n",
    "\n",
    "    #Defining data and label\n",
    "    X = df1.iloc[:, 0:30]\n",
    "    y = df1.iloc[:, 31]\n",
    "\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0,shuffle=False) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "\n",
    "    #Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train_std, y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test_std, y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    y_1=svm.predict(X_train_std)\n",
    "    print(y_1)\n",
    "\n",
    "    # print(y_1[2:3])\n",
    "    # print(y_1[3:4])\n",
    "    # print(y_1[4:5])\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #      print(y_1[i])\n",
    "\n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "    # print(y_train)\n",
    "\n",
    "    # y_train.to_numpy()\n",
    "\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #     print(y_train[i])\n",
    "\n",
    "    ###############################################\n",
    "    print('####Change to colors###############################################')\n",
    "    count=0\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if y_1[i] == y_train[i]:\n",
    "            count=count+1\n",
    "    # print(count)    \n",
    "\n",
    "    # y_trainx=np.zeros((1,X_train.shape[0]),dtype= int)\n",
    "\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #     if y_train[i]==1:\n",
    "    #         y_trainx[i]=-1\n",
    "    #     else:\n",
    "    #         y_trainx[i]=1\n",
    "\n",
    "\n",
    "\n",
    "    # for i in range(X_train.shape[0]):\n",
    "    #     if y_1[i]==1:\n",
    "    #         y_1x[i]=-1\n",
    "    #     else:\n",
    "    #         y_1x[i]=1\n",
    "\n",
    "\n",
    "\n",
    "#     print('####Test###############################################')\n",
    "#     y_2=svm.predict(X_test_std)\n",
    "    \n",
    "    return y_1,y_train\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "discripency is:\n",
      "0.0 128.18948413813288\n",
      "13ProPublica_violent_racidivism.csv\n",
      "1ProPublica_racidivism.csv\n",
      "2adult.csv\n",
      "3germandata_numeric.txt\n",
      "adult.csv\n",
      "\n",
      "0       0\n",
      "1       1\n",
      "2       1\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "6162    0\n",
      "6163    0\n",
      "6164    0\n",
      "6165    0\n",
      "6166    1\n",
      "Name: two_year_recid, Length: 6167, dtype: int64\n",
      "32\n",
      "33\n",
      "   age  juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n",
      "0   69              0               0                0             0   \n",
      "1   34              0               0                0             0   \n",
      "2   24              0               0                1             4   \n",
      "3   44              0               0                0             0   \n",
      "4   41              0               0                0            14   \n",
      "\n",
      "   decile_score  sex_Female  sex_Male  race_African-American  race_Asian  ...  \\\n",
      "0             1           0         1                      0           0  ...   \n",
      "1             3           0         1                      1           0  ...   \n",
      "2             4           0         1                      1           0  ...   \n",
      "3             1           0         1                      0           0  ...   \n",
      "4             6           0         1                      0           0  ...   \n",
      "\n",
      "   sr_Female-Hispanic  sr_Female-Native American  sr_Female-Other  \\\n",
      "0                   0                          0                0   \n",
      "1                   0                          0                0   \n",
      "2                   0                          0                0   \n",
      "3                   0                          0                0   \n",
      "4                   0                          0                0   \n",
      "\n",
      "   sr_Male-African-American  sr_Male-Asian  sr_Male-Caucasian  \\\n",
      "0                         0              0                  0   \n",
      "1                         1              0                  0   \n",
      "2                         1              0                  0   \n",
      "3                         0              0                  0   \n",
      "4                         0              0                  1   \n",
      "\n",
      "   sr_Male-Hispanic  sr_Male-Native American  sr_Male-Other  2_year_racidivism  \n",
      "0                 0                        0              1                  0  \n",
      "1                 0                        0              0                  1  \n",
      "2                 0                        0              0                  1  \n",
      "3                 0                        0              1                  0  \n",
      "4                 0                        0              0                  1  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "32\n",
      "There are 4316 samples in the training set and 1851 samples in the test set\n",
      "The accuracy of the SVM classifier on training data is 0.70\n",
      "The accuracy of the SVM classifier on test data is 0.65\n",
      "####Train prediction Label###############################################\n",
      "[0 0 1 ... 0 0 0]\n",
      "####Actual Train Label###############################################\n",
      "####Change to colors###############################################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "###############################\n",
      "[0.7029657089898054, 0.6851251158480074, 0.6610287303058388, 0.6450417052826691, 0.6255792400370713, 0.602873030583874, 0.5699721964782206, 0.5560704355885079, 0.5424003707136237, 0.5210843373493976, 0.49814643188137164]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################kasper##############3\n",
    "\n",
    "# u1,u2,R= ProPub1()\n",
    "# y_1,y_train=ProPub1_svm()\n",
    "# ploting(y_train,u1,y_1,R)\n",
    "#[0.7029657089898054, 0.6784059314179796, 0.6638090824837812, 0.6322984244670992, 0.6167747914735866, 0.5996292863762743, 0.5753012048192772, 0.556533827618165, 0.5347544022242817, 0.5094995366079703, 0.48841519925857274]\n",
    "u1,u2,R= ProPub1()\n",
    "y_1,y_train=ProPub1_svm()\n",
    "ploting(y_train,u2,y_1,R)\n",
    "#[0.7029657089898054, 0.6839666357738647, 0.6672845227062094, 0.6334569045412419, 0.6202502316960148, 0.6100556070435589, 0.5848007414272475, 0.5634847080630213, 0.5456441149212233, 0.5173772011121409, 0.49976830398517147]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################kasper##############3\n",
    "u1,u2,R= ProPub1_gender()\n",
    "y_1,y_train=ProPub1_svm()\n",
    "ploting(y_train,u1,y_1,R)\n",
    "\n",
    "# u1,u2,R= ProPub1_gender()\n",
    "# y_1,y_train=ProPub1_svm()\n",
    "# ploting(y_train,u2,y_1,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################kasper##############3\n",
    "u1,u2,R= ProPub1_race()\n",
    "y_1,y_train=ProPub1_svm()\n",
    "ploting(y_train,u1,y_1,R)\n",
    "\n",
    "# u1,u2,R= ProPub1_race()\n",
    "# y_1,y_train=ProPub1_svm()\n",
    "# ploting(y_train,u2,y_1,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################LP min max##############3\n",
    "# y_1,y_train=ProPub1_svm()\n",
    "# maxi=0\n",
    "# for i in range(0,4000,100) :\n",
    "#     u1,u2,R=min_max_lp_all(i)\n",
    "#     min_max=ploting_lp_prop(y_train,u1,y_1,R)\n",
    "#     if min_max>maxi:\n",
    "#         maxi=min_max\n",
    "#         remember=i\n",
    "#     print(maxi)\n",
    "      \n",
    "# print(maxi)\n",
    "# print(remember)\n",
    "\n",
    "##################################################3\n",
    "\n",
    "y_1,y_train=ProPub1_svm()\n",
    "maxi=0\n",
    "acc1_l=[]\n",
    "acc2_l=[]\n",
    "epsilon_l=[]\n",
    "for eps in range(0,4000,100) :\n",
    "    count1=0\n",
    "    count2=0\n",
    "    u1,u2,R=min_max_lp_all(eps)\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j]):\n",
    "                count1+=1\n",
    "    acc1=float(count1/y_train.shape[0])        \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j]):\n",
    "                count2+=1\n",
    "    acc2=float(count2/y_train.shape[0])        \n",
    "    epsilon_l.append(eps)\n",
    "    acc2_l.append(acc2)\n",
    "    acc1_l.append(acc1)\n",
    "    print(acc1,acc2)   \n",
    "print(acc1_l)     \n",
    "print(acc2_l)      \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "acc1_l=[0.5152919369786839, 0.5085727525486562, 0.5048656163113995, 0.5104263206672845, 0.4819277108433735, 0.4860982391102873, 0.49212233549582945, 0.49304911955514363, 0.4860982391102873, 0.484708063021316, 0.4823911028730306, 0.4823911028730306, 0.479610750695088, 0.4789156626506024, 0.48123262279888784, 0.46825764596848934, 0.4696478220574606, 0.4705746061167748, 0.47335495829471735, 0.47335495829471735, 0.4752085264133457, 0.47706209453197407, 0.48030583873957367, 0.4798424467099166, 0.47752548656163113, 0.47659870250231695, 0.47428174235403153, 0.47289156626506024, 0.4696478220574606, 0.4650139017608897, 0.4691844300278035, 0.4677942539388322, 0.4626969416126043, 0.46362372567191845, 0.4594531974050046, 0.45296570898980537, 0.4522706209453197, 0.4522706209453197, 0.4522706209453197, 0.4522706209453197]\n",
    "acc2_l=[0.484708063021316, 0.49142724745134386, 0.4951343836886006, 0.48957367933271545, 0.5180722891566265, 0.5139017608897127, 0.5078776645041705, 0.5069508804448564, 0.5139017608897127, 0.5152919369786839, 0.5176088971269694, 0.5176088971269694, 0.5203892493049119, 0.5210843373493976, 0.5187673772011121, 0.5317423540315107, 0.5303521779425394, 0.5294253938832252, 0.5266450417052827, 0.5266450417052827, 0.5247914735866543, 0.522937905468026, 0.5196941612604263, 0.5201575532900834, 0.5224745134383688, 0.523401297497683, 0.5257182576459685, 0.5271084337349398, 0.5303521779425394, 0.5349860982391103, 0.5308155699721965, 0.5322057460611678, 0.5373030583873958, 0.5363762743280815, 0.5405468025949953, 0.5470342910101946, 0.5477293790546802, 0.5477293790546802, 0.5477293790546802, 0.5477293790546802]\n",
    "\n",
    "plt.axis([0, 3900, 30, 60])\n",
    "plt.xlabel('Fairness(Alpha)')\n",
    "plt.ylabel('Train Accuracy')\n",
    "plt.title('Accuracy V/S Fairness tradeoff for ProPublica dataset')\n",
    "# \n",
    "var = np.linspace(0, 40, 10) \n",
    "plt.plot(epsilon_l,acc1_l)   \n",
    "plt.plot(epsilon_l,acc2_l)\n",
    "plt.legend([\"Experimental LP\", \"Experimental  lp\"])\n",
    "plt.show() \n",
    "#[0.484708063021316, 0.49142724745134386, 0.4951343836886006, 0.48957367933271545, 0.5180722891566265, 0.5139017608897127, 0.5078776645041705, 0.5069508804448564, 0.5139017608897127, 0.5152919369786839, 0.5176088971269694, 0.5176088971269694, 0.5203892493049119, 0.5210843373493976, 0.5187673772011121, 0.5317423540315107, 0.5303521779425394, 0.5294253938832252, 0.5266450417052827, 0.5266450417052827, 0.5247914735866543, 0.522937905468026, 0.5196941612604263, 0.5201575532900834, 0.5224745134383688, 0.523401297497683, 0.5257182576459685, 0.5271084337349398, 0.5303521779425394, 0.5349860982391103, 0.5308155699721965, 0.5322057460611678, 0.5373030583873958, 0.5363762743280815, 0.5405468025949953, 0.5470342910101946, 0.5477293790546802, 0.5477293790546802, 0.5477293790546802, 0.5477293790546802]\n",
    "# y_1,y_train=ProPub1_svm()\n",
    "# u1,u2,R=min_max_lp_all()\n",
    "# ploting(y_train,u1,y_1,R)\n",
    "#x-actual a=min_max_lp_color b=classifier R\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# count=0\n",
    "# count1=0\n",
    "# for i in range(y_train.shape[0]):\n",
    "#     if(y_train[i]==1):\n",
    "#         count+=1\n",
    "#     else:\n",
    "#         count1+=1\n",
    "# print(count,count1)  \n",
    "# y_1,y_train=ProPub1_svm()\n",
    "# u1,u2,R=min_max_lp_all()\n",
    "# ploting(y_train,u2,y_1,R)\n",
    "#x-actual a=min_max_lp_color b=classifier R\n",
    "#1-discrepancy\n",
    "#[0.7029657089898054, 0.6774791473586654, 0.6570898980537535, 0.6429564411492122, 0.6163113994439295, 0.5887395736793327, 0.5815569972196478, 0.5553753475440223, 0.5289620018535681, 0.505097312326228, 0.484708063021316]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################LP min sum##############3\n",
    "###############################################################################################3\n",
    "###############################################################################################3\n",
    "u1,u2,R=min_sum_lp_all()\n",
    "y_1,y_train=ProPub1_svm()\n",
    "ploting(y_train,u1,y_1,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "##IMP1 LP-basic\n",
    "##################################################################\n",
    "#PROPUBLICA MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all():\n",
    "        filename = '../input/1ProPublica_racidivism.csv'\n",
    "        d2 = pd.read_csv(filename)\n",
    "        # n = d2.shape[0]\n",
    "        m= d2.shape[1]\n",
    "        x1 = d2.loc[0:4315,'sex']\n",
    "        x2 = d2.loc[0:4315,'race']\n",
    "        n=x1.shape[0]\n",
    "        R = np.zeros((7, n), dtype = int)\n",
    "        for i in range(n):\n",
    "            if x1[i] == 'Male':\n",
    "                R[0][i]= 1\n",
    "            else:\n",
    "                R[1][i]= 1\n",
    "\n",
    "        for i in range(n):\n",
    "            if x2[i] == 'African-American':\n",
    "                R[2][i]= 1\n",
    "            elif x2[i] == 'Caucasian':\n",
    "                R[3][i]= 1\n",
    "            elif x2[i] == 'Hispanic':\n",
    "                R[4][i]= 1\n",
    "            elif x2[i] == 'Asia':\n",
    "                R[5][i]= 1\n",
    "            else:\n",
    "                R[6][i]= 1\n",
    "        \n",
    "        m=R.shape[0]\n",
    "        n=R.shape[1] \n",
    "        \n",
    "        # Create a LP Minimization problem \n",
    "        Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "        print(range(n)) \n",
    "        #X[n]=z() n last value of X\n",
    "                \n",
    "        X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "        #X[]=0 to n-1\n",
    "\n",
    "        for i in range(n):\n",
    "            var=str(i)\n",
    "            X[i]=p.LpVariable(var,0,1,cat='Integer')\n",
    "        X[n] =  p.LpVariable(\"z\",lowBound=0)\n",
    "\n",
    "        #########objective function#####################\n",
    "        Lp_prob += X[n] \n",
    "\n",
    "        ###############################################\n",
    "\n",
    "        ##############constraint#################\n",
    "        for i in range(2*m):\n",
    "            if i<m:\n",
    "                Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "            else:        \n",
    "                Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "\n",
    "      \n",
    "             \n",
    "        #####################################\n",
    "        status = Lp_prob.solve()   # Solver \n",
    "        print(p.LpStatus[status]) \n",
    "        print(\"discripency is:\")\n",
    "        print(p.value(Lp_prob.objective))  # The solution status \n",
    "        racidivism1={}\n",
    "        racidivism2={}\n",
    "        # # Printing the final solution\n",
    "        print(X)\n",
    "        for i in range(n):\n",
    "            if(p.value(X[i])==0):\n",
    "                racidivism1[i]=1 \n",
    "                racidivism2[i]=0\n",
    "            else:\n",
    "                racidivism1[i]=0\n",
    "                racidivism2[i]=1\n",
    "        racidivismu1=racidivism1  \n",
    "        racidivismu2=racidivism2    \n",
    "         \n",
    "        return racidivismu1,racidivismu2,R    \n",
    "# print(p.value(Lp_prob.objective))   \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "##IMP2---------proportion\n",
    "##################################################################\n",
    "#PROPUBLICA MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all(eps):\n",
    "        filename = '../input/1ProPublica_racidivism.csv'\n",
    "        d2 = pd.read_csv(filename)\n",
    "        # n = d2.shape[0]\n",
    "        m= d2.shape[1]\n",
    "        x1 = d2.loc[0:4315,'sex']\n",
    "        x2 = d2.loc[0:4315,'race']\n",
    "        n=x1.shape[0]\n",
    "        R = np.zeros((7, n), dtype = int)\n",
    "        for i in range(n):\n",
    "            if x1[i] == 'Male':\n",
    "                R[0][i]= 1\n",
    "            else:\n",
    "                R[1][i]= 1\n",
    "\n",
    "        for i in range(n):\n",
    "            if x2[i] == 'African-American':\n",
    "                R[2][i]= 1\n",
    "            elif x2[i] == 'Caucasian':\n",
    "                R[3][i]= 1\n",
    "            elif x2[i] == 'Hispanic':\n",
    "                R[4][i]= 1\n",
    "            elif x2[i] == 'Asia':\n",
    "                R[5][i]= 1\n",
    "            else:\n",
    "                R[6][i]= 1\n",
    "        \n",
    "        m=R.shape[0]\n",
    "        n=R.shape[1] \n",
    "        \n",
    "        # Create a LP Minimization problem \n",
    "        Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "#         print(range(n)) \n",
    "        #X[n]=z() n last value of X\n",
    "                \n",
    "        X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "        #X[]=0 to n-1\n",
    "\n",
    "        for i in range(n):\n",
    "            var=str(i)\n",
    "            X[i]=p.LpVariable(var,0,1,cat='Integer')\n",
    "        X[n] =  p.LpVariable(\"z\",lowBound=0)\n",
    "\n",
    "        #########objective function#####################\n",
    "        Lp_prob += X[n] \n",
    "\n",
    "        ###############################################\n",
    "\n",
    "        ##############constraint#################\n",
    "        for i in range(2*m):\n",
    "            if i<m:\n",
    "                Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "            else:        \n",
    "                Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "\n",
    "#         Lp_prob += X[n] >= 0.001*n\n",
    "#         Lp_prob += X[n] <= 0.05*n\n",
    "          \n",
    "        Lp_prob += X[n] >= eps\n",
    "        Lp_prob += X[n] <=4100\n",
    "        #####################################\n",
    "        status = Lp_prob.solve()   # Solver \n",
    "#         print(p.LpStatus[status]) \n",
    "#         print(\"discripency is:\")\n",
    "#         print(p.value(Lp_prob.objective))  # The solution status \n",
    "        racidivism1={}\n",
    "        racidivism2={}\n",
    "        # # Printing the final solution\n",
    "        print(X)\n",
    "        for i in range(n):\n",
    "            if(p.value(X[i])==0):\n",
    "                racidivism1[i]=1 \n",
    "                racidivism2[i]=0\n",
    "            else:\n",
    "                racidivism1[i]=0\n",
    "                racidivism2[i]=1\n",
    "        racidivismu1=racidivism1  \n",
    "        racidivismu2=racidivism2    \n",
    "        \n",
    "   \n",
    "        \n",
    "        \n",
    "         \n",
    "        return racidivismu1,racidivismu2,R    \n",
    "# print(p.value(Lp_prob.objective))   \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#LP deterministic selection\n",
    "##############################3\n",
    "\n",
    "#PROPUBLICA MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all():\n",
    "    filename = '13ProPublica_violent_racidivism.csv'\n",
    "\n",
    "    d2 = pd.read_csv(filename)\n",
    "\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:2806,'sex']\n",
    "    x2 = d2.loc[0:2806,'race']\n",
    "    n = x1.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    print(\"1:gender, 2:race\")\n",
    "    s_attribute=input()\n",
    "    if s_attribute==1 :\n",
    "        R = np.zeros((2, n), dtype = int)\n",
    "        for i in range(n):\n",
    "            if x1[i] == 'Male':\n",
    "                R[0][i]= 1\n",
    "            else:\n",
    "                R[1][i]= 1\n",
    "                \n",
    "    else:  \n",
    "        R = np.zeros((5, n), dtype = int)\n",
    "        for i in range(n):\n",
    "            if x2[i] == 'African-American':\n",
    "                R[0][i]= 1\n",
    "            elif x2[i] == 'Caucasian':\n",
    "                R[1][i]= 1\n",
    "            elif x2[i] == 'Hispanic':\n",
    "                R[2][i]= 1\n",
    "            elif x2[i] == 'Asia':\n",
    "                R[3][i]= 1\n",
    "            else:\n",
    "                R[4][i]= 1\n",
    "\n",
    "\n",
    "\n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "\n",
    "    # Create a LP Minimization problem \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "    print( range(n)) \n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n):\n",
    "        var=str(i)\n",
    "        X[i]=p.LpVariable(var,lowBound=0,upBound=1,cat='Integer')\n",
    "    X[n] =  p.LpVariable(\"z\",lowBound=0)\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob += X[n] \n",
    "\n",
    "\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*R.shape[0]):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective))  # The solution status \n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    # # Printing the final solution\n",
    "    print(X)\n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==0):\n",
    "            racidivism1[i]=1 \n",
    "            racidivism2[i]=0\n",
    "        else:\n",
    "            racidivism1[i]=0\n",
    "            racidivism2[i]=1\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2    \n",
    "\n",
    "    return racidivismu1,racidivismu2,R    \n",
    "# print(p.value(Lp_prob.objective))   \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# y_1,y_train=ProPub1_svm()\n",
    "# u1,u2,R=min_sum_lp_all()\n",
    "# a=ploting(y_train,u2,y_1,R)\n",
    "\n",
    "y_1,y_train=ProPub1_svm()\n",
    "u1,u2,R=min_sum_lp_all()\n",
    "ploting(y_train,u1,y_1,R)\n",
    "count1=0\n",
    "count2=0\n",
    "\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(y_train[j]==u1[j] and y_train==1):\n",
    "            count1+=1       \n",
    "\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(y_train[j]==u2[j] and y_train[j]==0):\n",
    "            count2+=1\n",
    "            \n",
    "print(count1)\n",
    "print(count2)\n",
    "count1=0\n",
    "count2=0\n",
    "\n",
    "for j in range(y_train.shape[0] ):\n",
    "        if(y_train[j]==u1[j] and y_train[j]==0):\n",
    "            count1+=1       \n",
    "\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(y_train[j]==u2[j] and y_train==1):\n",
    "            count2+=1\n",
    "\n",
    "print(count1)\n",
    "print(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################  \n",
    "#MIn SUM\n",
    "#####################################################################\n",
    "#pROPUBLICA MIN SUM CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_sum_lp_all(eps,r):\n",
    "    filename = '../input/1ProPublica_racidivism.csv'\n",
    "    d2 = pd.read_csv(filename)\n",
    "    # n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:4315,'sex']\n",
    "    x2 = d2.loc[0:4315,'race']\n",
    "    n=x1.shape[0]\n",
    "    R = np.zeros((7, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'Male':\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] == 'African-American':\n",
    "            R[2][i]= 1\n",
    "        elif x2[i] == 'Caucasian':\n",
    "            R[3][i]= 1\n",
    "        elif x2[i] == 'Hispanic':\n",
    "            R[4][i]= 1\n",
    "        elif x2[i] == 'Asia':\n",
    "            R[5][i]= 1\n",
    "        else:\n",
    "            R[6][i]= 1\n",
    "\n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "    # Create a LP Minimization problem \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "\n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "\n",
    "    X=np.zeros(n+m,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n+m):\n",
    "        var=str(i)\n",
    "        if(i<n):##n\n",
    "            X[i]=p.LpVariable(var,lowBound=0,upBound=1)\n",
    "        else:##m\n",
    "            X[i] =  p.LpVariable(var,lowBound=0,upBound=n)\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob +=  p.lpSum([X[i+n] for i in range(m)])\n",
    "    ###############################################\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status])  \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective))# The solution status \n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "    # # Printing the final solution \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            racidivism1[i]=1 \n",
    "            racidivism2[i]=0\n",
    "        else:\n",
    "            racidivism1[i]=0\n",
    "            racidivism2[i]=1\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2          \n",
    "        #   print(p.value(X[i]))\n",
    "    return racidivismu1,racidivismu2,R \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################Pulp DEMO#########################################3\n",
    "\n",
    "# # import the library pulp as p \n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import pulp as p \n",
    "# def min_sum_lp_all():\n",
    "#     filename = '../input/1ProPublica_racidivism.csv'\n",
    "#     d2 = pd.read_csv(filename)\n",
    "#     # n = d2.shape[0]\n",
    "#     m= d2.shape[1]\n",
    "#     x1 = d2.loc[0:4315,'sex']\n",
    "#     x2 = d2.loc[0:4315,'race']\n",
    "#     n=x1.shape[0]\n",
    "#     R = np.zeros((7, n), dtype = int)\n",
    "#     for i in range(n):\n",
    "#         if x1[i] == 'Male':\n",
    "#             R[0][i]= 1\n",
    "#         else:\n",
    "#             R[1][i]= 1\n",
    "\n",
    "#     for i in range(n):\n",
    "#         if x2[i] == 'African-American':\n",
    "#             R[2][i]= 1\n",
    "#         elif x2[i] == 'Caucasian':\n",
    "#             R[3][i]= 1\n",
    "#         elif x2[i] == 'Hispanic':\n",
    "#             R[4][i]= 1\n",
    "#         elif x2[i] == 'Asia':\n",
    "#             R[5][i]= 1\n",
    "#         else:\n",
    "#             R[6][i]= 1\n",
    "\n",
    "#     m=R.shape[0]\n",
    "#     n=R.shape[1] \n",
    "#     # Create a LP Minimization problem \n",
    "#     Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "#     print( range(n)) \n",
    "#     #X[n]=z() n last value of X\n",
    "#     X=p.LpProblem('Problem', p.LpMinimize)\n",
    "#     X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "#     #X[]=0 to n-1\n",
    "\n",
    "#     for i in range(n):\n",
    "#         var=str(i)\n",
    "#         X[i]=p.LpVariable(var,lowBound=-1,upBound=1)\n",
    "#     X[n] =  p.LpVariable(\"z\",lowBound=0)\n",
    "\n",
    "#     #########objective function#####################\n",
    "#     Lp_prob += X[n] \n",
    "\n",
    "#     ###############################################\n",
    "\n",
    "#     ##############constraint#################\n",
    "#     for i in range(2*m):\n",
    "#         if i<m:\n",
    "#             Lp_prob += X[n] >= p.lpSum([X[j]*R[i][j] for j in range(n)])\n",
    "#         else:        \n",
    "#             Lp_prob += X[n] >= p.lpSum([-1*X[j]*R[i-m][j] for j in range(n)])\n",
    "\n",
    "\n",
    "#     #####################################\n",
    "#     status = Lp_prob.solve()   # Solver \n",
    "#     print(p.LpStatus[status])   # The solution status \n",
    "\n",
    "#     # # Printing the final solution \n",
    "#     racidivism1={}\n",
    "#     racidivism2={}\n",
    "#         # # Printing the final solution \n",
    "#     for i in range(n):\n",
    "#         if(p.value(X[i])>0):\n",
    "#             racidivism1[i]=1 \n",
    "#             racidivism2[i]=0\n",
    "#         else:\n",
    "#             racidivism1[i]=0\n",
    "#             racidivism2[i]=1\n",
    "#     racidivismu1=racidivism1  \n",
    "#     racidivismu2=racidivism2          \n",
    "\n",
    "#     return racidivismu1,racidivismu2,R \n",
    "\n",
    "\n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############LP-4 min max with accuracy########################\n",
    "\n",
    "\n",
    "y_1,y_train=ProPub1_svm()\n",
    "\n",
    "acc1_l=[]\n",
    "acc2_l=[]\n",
    "epsilon_l=[]\n",
    "for i in range(y_train.shape[0]):\n",
    "        if y_train[i] == 1 :\n",
    "            y_train[i]= 1\n",
    "        else:          \n",
    "            y_train[i]= -1\n",
    "# for i in range(y_train.shape[0]):\n",
    "#         if y_train[i] == 1 :\n",
    "#             y_train[i]= -1\n",
    "#         else:          \n",
    "#             y_train[i]= 1\n",
    "for eps in range(0,4000,100) :\n",
    "    count1=0\n",
    "    count2=0\n",
    "    u1,u2,R=min_max_lp_all(eps,y_train)    \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j]):\n",
    "                count1+=1\n",
    "    acc1=float(count1/y_train.shape[0])        \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j]):\n",
    "                count2+=1\n",
    "    acc2=float(count2/y_train.shape[0])        \n",
    "    epsilon_l.append(eps)\n",
    "    acc2_l.append(acc2)\n",
    "    acc1_l.append(acc1)\n",
    "    print(acc1,acc2) \n",
    "    \n",
    "    \n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j] and u1[j]==-1):\n",
    "                c1+=1       \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j] and u1[j]==1):\n",
    "                c2+=1\n",
    "    print(c1,c2)\n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j] and u2[j]==-1):\n",
    "                c1+=1       \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j] and u2[j]==1):\n",
    "                c2+=1\n",
    "    print(c1,c2)\n",
    "    \n",
    "    \n",
    "print(acc1_l)     \n",
    "print(acc2_l)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############LP-4 min max with accuracy########################\n",
    "\n",
    "#German MIN Max COMMAND \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all(eps,r):\n",
    "    filename = '../input/1ProPublica_racidivism.csv'\n",
    "    d2 = pd.read_csv(filename)\n",
    "    # n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:4315,'sex']\n",
    "    x2 = d2.loc[0:4315,'race']\n",
    "    n=x1.shape[0]\n",
    "    R = np.zeros((7, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'Male':\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "\n",
    "    for i in range(n):\n",
    "        if x2[i] == 'African-American':\n",
    "            R[2][i]= 1\n",
    "        elif x2[i] == 'Caucasian':\n",
    "            R[3][i]= 1\n",
    "        elif x2[i] == 'Hispanic':\n",
    "            R[4][i]= 1\n",
    "        elif x2[i] == 'Asia':\n",
    "            R[5][i]= 1\n",
    "        else:\n",
    "            R[6][i]= 1\n",
    "\n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "    # Create a LP Minimization problem \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "\n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "\n",
    "    X=np.zeros(n+2,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n):\n",
    "        var=str(i)\n",
    "        X[i]=p.LpVariable(var,lowBound=0,upBound=1,cat='Integer')\n",
    "    X[n] =  p.LpVariable(\"z1\",lowBound=0)\n",
    "    X[n+1] =  p.LpVariable(\"z2\",lowBound=0)\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob += X[n] + X[n+1]\n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "    ##### r(y_train values real labels of data)\n",
    "    Lp_prob += X[n+1] >= p.lpSum([2*(X[j]-0.5)-r[j] for j in range(n)])\n",
    "    Lp_prob += X[n+1] >= p.lpSum([-1*2*(X[j]-0.5)+r[j] for j in range(n)])\n",
    "\n",
    "    Lp_prob += X[n] >= eps\n",
    "    Lp_prob += X[n] <= 4100\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective)) \n",
    "    ###################################################\n",
    "    w=p.value(Lp_prob.objective)-p.value(X[n+1])\n",
    "    print(w)\n",
    "    # The solution status \n",
    "    \n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "        # # Printing the final solution\n",
    "        \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            racidivism1[i]=1 \n",
    "            racidivism2[i]=-1\n",
    "        else:\n",
    "            racidivism1[i]=-1\n",
    "            racidivism2[i]=1\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2    \n",
    "    return racidivismu1,racidivismu2,R   \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "# print(p.value(Lp_prob.objective))   \n",
    "\n",
    "# objectivefn\n",
    "# Lp_prob +=  exp\n",
    "\n",
    "# # Create problem Variables  \n",
    "# x = p.LpVariable(\"x\", lowBound = 0)   # Create a variable x >= 0 \n",
    "# y = p.LpVariable(\"y\", lowBound = 0)   # Create a variable y >= 0 \n",
    "  \n",
    "# Objective Function \n",
    "# Lp_prob += 3 * x + 5 * y    \n",
    "  \n",
    "# x=\"x[0]\"\n",
    "\n",
    "# # Constraints: \n",
    "# Lp_prob += 2 * x + 3 * y >= 12\n",
    "# Lp_prob += -x + y <= 3\n",
    "# Lp_prob += x >= 4\n",
    "# Lp_prob += y <= 3\n",
    "# print(type(Lp_prob)) \n",
    "# # Display the problem \n",
    "# print(Lp_prob) \n",
    "  \n",
    "# status = Lp_prob.solve()   # Solver \n",
    "# print(p.LpStatus[status])   # The solution status \n",
    "  \n",
    "# # Prianting the final solution \n",
    "# print(p.value(x), p.value(y), p.value(Lp_prob.objective))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############LP-4 min max with accuracy  22222222222222222########################\n",
    "\n",
    "\n",
    "y_1,y_train=ProPub1_svm()\n",
    "\n",
    "acc1_l=[]\n",
    "acc2_l=[]\n",
    "epsilon_l=[]\n",
    "for i in range(y_train.shape[0]):\n",
    "        if y_train[i] == 1 :\n",
    "            y_train[i]= 1\n",
    "        else:          \n",
    "            y_train[i]= -1\n",
    "# for i in range(y_train.shape[0]):\n",
    "#         if y_train[i] == 1 :\n",
    "#             y_train[i]= -1\n",
    "#         else:          \n",
    "#             y_train[i]= 1\n",
    "for eps in range(0,4000,100) :\n",
    "    count1=0\n",
    "    count2=0\n",
    "    u1,u2,R = min_max_lp_all(eps,y_train)    \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j]):\n",
    "                count1+=1\n",
    "    acc1=float(count1/y_train.shape[0])        \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j]):\n",
    "                count2+=1\n",
    "    acc2=float(count2/y_train.shape[0])        \n",
    "    epsilon_l.append(eps)\n",
    "    acc2_l.append(acc2)\n",
    "    acc1_l.append(acc1)\n",
    "    print(acc1,acc2) \n",
    "    \n",
    "    \n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j] and u1[j]==-1):\n",
    "                c1+=1       \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j] and u1[j]==1):\n",
    "                c2+=1\n",
    "    print(c1,c2)\n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j] and u2[j]==-1):\n",
    "                c1+=1       \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j] and u2[j]==1):\n",
    "                c2+=1\n",
    "    print(c1,c2)\n",
    "    \n",
    "    \n",
    "print(acc1_l)     \n",
    "print(acc2_l)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############LP-4 min max with accuracy 2222222########################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp as p \n",
    "def min_max_lp_all(eps,r):\n",
    "    filename = '../input/1ProPublica_racidivism.csv'\n",
    "    d2 = pd.read_csv(filename)\n",
    "    # n = d2.shape[0]\n",
    "    m= d2.shape[1]\n",
    "    x1 = d2.loc[0:4315,'sex']\n",
    "    x2 = d2.loc[0:4315,'race']\n",
    "    n=x1.shape[0]\n",
    "    R = np.zeros((2, n), dtype = int)\n",
    "    for i in range(n):\n",
    "        if x1[i] == 'Male':\n",
    "            R[0][i]= 1\n",
    "        else:\n",
    "            R[1][i]= 1\n",
    "\n",
    "#     for i in range(n):\n",
    "#         if x2[i] == 'African-American':\n",
    "#             R[2][i]= 1\n",
    "#         elif x2[i] == 'Caucasian':\n",
    "#             R[3][i]= 1\n",
    "#         elif x2[i] == 'Hispanic':\n",
    "#             R[4][i]= 1\n",
    "#         elif x2[i] == 'Asia':\n",
    "#             R[5][i]= 1\n",
    "#         else:\n",
    "#             R[6][i]= 1\n",
    "\n",
    "    m=R.shape[0]\n",
    "    n=R.shape[1] \n",
    "    # Create a LP Minimization problem \n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "\n",
    "    #X[n]=z() n last value of X\n",
    "\n",
    "\n",
    "    X=np.zeros(n+2,dtype=p.LpVariable)\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n):\n",
    "        var=str(i)\n",
    "        X[i]=p.LpVariable(var,lowBound=0,upBound=1,cat='Integer')\n",
    "    X[n] =  p.LpVariable(\"z1\",lowBound=0)\n",
    "    X[n+1] =  p.LpVariable(\"z2\",lowBound=0)\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob += X[n] + X[n+1]\n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*R[i][j] for j in range(n)])\n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*R[i-m][j] for j in range(n)])\n",
    "    ##### r(y_train values real labels of data)\n",
    "    Lp_prob += X[n+1] >= p.lpSum([2*(X[j]-0.5)-r[j] for j in range(n)])\n",
    "    Lp_prob += X[n+1] >= p.lpSum([-1*2*(X[j]-0.5)+r[j] for j in range(n)])\n",
    "\n",
    "    Lp_prob += X[n] >= eps\n",
    "    Lp_prob += X[n] <= 4100\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")\n",
    "    print(p.value(Lp_prob.objective)) \n",
    "    ###################################################\n",
    "    w=p.value(Lp_prob.objective)-p.value(X[n+1])\n",
    "    print(w)\n",
    "    # The solution status \n",
    "    \n",
    "    racidivism1={}\n",
    "    racidivism2={}\n",
    "        # # Printing the final solution\n",
    "        \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])>0):\n",
    "            racidivism1[i]=1 \n",
    "            racidivism2[i]=-1\n",
    "        else:\n",
    "            racidivism1[i]=-1\n",
    "            racidivism2[i]=1\n",
    "    racidivismu1=racidivism1  \n",
    "    racidivismu2=racidivism2    \n",
    "    return racidivismu1,racidivismu2,R   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,y=Synth_data()\n",
    "# print(data.shape[0])\n",
    "# print(data.shape[1])\n",
    "y_train,y_1=Synth_svm(data,y)\n",
    "#####################################################\n",
    "\n",
    "Ms=0\n",
    "Mns=0\n",
    "Fs=0\n",
    "Fns=0\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(data[j][2]==1 and y_train[j]==1):\n",
    "            Ms+=1       \n",
    "\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(data[j][2]==1 and y_train[j]==-1):\n",
    "            Mns+=1\n",
    "\n",
    "\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(data[j][2]==0 and y_train[j]==1):\n",
    "            Fs+=1       \n",
    "\n",
    "for j in range(y_train.shape[0]):\n",
    "        if(data[j][2]==0 and y_train[j]==-1):\n",
    "            Fns+=1\n",
    "\n",
    "\n",
    "######################################################\n",
    "print(\"actual\")\n",
    "ALL=0\n",
    "ALL=Ms+Mns+Fs+Fns\n",
    "print(ALL)\n",
    "print(\"total males,female\")\n",
    "M=0\n",
    "F=0\n",
    "M=Ms+Mns\n",
    "F=Fs+Fns\n",
    "print(M,F)\n",
    "print(\"total male select,not select\")\n",
    "print(Ms,Mns)\n",
    "print(\"total female select,not select\")\n",
    "print(Fs,Fns)\n",
    "\n",
    "\n",
    "maxi=0\n",
    "acc1_l=[]\n",
    "acc2_l=[]\n",
    "epsilon_l=[]\n",
    "DI1=[]\n",
    "DI2=[]\n",
    "for eps in range(0,1300,100) :\n",
    "    count1=0\n",
    "    count2=0\n",
    "    u1,u2,R = min_max_lp_all(data,eps,y_train)\n",
    "    \n",
    "\n",
    "######################################Disp_impact###########\n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==1 and u1[j]==1 ):\n",
    "                c1+=1       \n",
    "\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==1 and u1[j]==-1 ):\n",
    "                c2+=1\n",
    "    c1=float(c1/M)\n",
    "    c2=float(c2/M)\n",
    "    print(c1)\n",
    "    c3=0\n",
    "    c4=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==0 and u1[j]==1 ):\n",
    "                c3+=1       \n",
    "\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==0 and u1[j]==-1 ):\n",
    "                c4+=1\n",
    "   \n",
    "    c3=float(c3/F)\n",
    "    c4=float(c4/F)\n",
    "    print(c3)\n",
    "    \n",
    "    cx=c1-c3\n",
    "    DIa=cx\n",
    "    DI1.append(DIa)\n",
    "    \n",
    "    \n",
    "    c1=0\n",
    "    c2=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==1 and u2[j]==1 ):\n",
    "                c1+=1       \n",
    "\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==1 and u2[j]==-1 ):\n",
    "                c2+=1\n",
    "    c1=float(c1/M)\n",
    "    c2=float(c2/M)\n",
    "    print(c1)\n",
    "    c3=0\n",
    "    c4=0\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==0 and u2[j]==1 ):\n",
    "                c3+=1       \n",
    "\n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(data[j][2]==0 and u2[j]==-1 ):\n",
    "                c4+=1\n",
    "   \n",
    "    c3=float(c3/F)\n",
    "    c4=float(c4/F)\n",
    "    print(c3)\n",
    "    cx=c1-c3\n",
    "    DIb=cx\n",
    "    DI2.append(DIb)\n",
    "\n",
    "################################################ \n",
    "\n",
    "\n",
    "    \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u1[j]):\n",
    "                count1+=1\n",
    "    acc1=float(count1/y_train.shape[0])        \n",
    "       \n",
    "    for j in range(y_train.shape[0]):\n",
    "            if(y_train[j]==u2[j]):\n",
    "                count2+=1\n",
    "    acc2=float(count2/y_train.shape[0])        \n",
    "    epsilon_l.append(eps)\n",
    "    acc2_l.append(acc2)\n",
    "    acc1_l.append(acc1)\n",
    "    print(acc1,acc2)   \n",
    "print(acc1_l)     \n",
    "print(acc2_l)\n",
    "print(\"Disparate Impact\")\n",
    "print(DI1)     \n",
    "print(DI2)\n",
    "print(epsilon_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
