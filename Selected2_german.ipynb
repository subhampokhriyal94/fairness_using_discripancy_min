{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['triangular', 'uniform', 'sample', 'seed', 'randint', 'choice', 'shuffle', 'random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "#SVM GERMAN\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from random import *\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "def german_svm():\n",
    "    ###############German#####################\n",
    "     \n",
    "    print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "    # Any results you write to the current directory are saved as output.\n",
    "    #Reading data from CSV file\n",
    "#     df = pd.read_csv('../input/3germandata_numeric.txt',delim_whitespace=True,dtype=int32)\n",
    "    \n",
    "    df = pd.read_csv('../input/3german.txt',delim_whitespace=True)\n",
    "    print(df.head)\n",
    "#     df=df.drop(columns=[8,12])\n",
    "\n",
    "    df1 = df.copy()\n",
    "    df1 = pd.get_dummies(df1, columns=['sex','race','c_charge_degree','score_text','sex-race'], prefix = ['sex','race','ccd','st','sr'])\n",
    "    print(df1.loc[:,'two_year_recid'])\n",
    "    \n",
    "    \n",
    "    #Defining data and label\n",
    "    X = df.iloc[:, 0:23]\n",
    "    y = df.iloc[:, 24]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Split data into training and test datasets (training will be based on 70% of data)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0,shuffle=False) \n",
    "    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n",
    "    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "\n",
    "    #Scaling data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "    #X_train_std and X_test_std are the scaled datasets to be used in algorithms\n",
    "\n",
    "    #Applying SVC (Support Vector Classification)\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n",
    "    svm.fit(X_train_std, y_train)\n",
    "    print('The accuracy of the SVM classifier on training data is {:.2f}'.format(svm.score(X_train_std, y_train)))\n",
    "    print('The accuracy of the SVM classifier on test data is {:.2f}'.format(svm.score(X_test_std, y_test)))\n",
    "    print('####Train prediction Label###############################################')\n",
    "    y_1=svm.predict(X_train_std)\n",
    "   \n",
    "\n",
    "    print('####Actual Train Label###############################################')\n",
    "   \n",
    "\n",
    "    ###############################################\n",
    "    print('####Change to colors###############################################')\n",
    "    count=0\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if y_1[i] == y_train[i]:\n",
    "            count=count+1\n",
    "    print(count)    \n",
    "\n",
    "    y_trainx=np.zeros((1,X_train.shape[0]),dtype= int)\n",
    "\n",
    "    print('####Test###############################################')\n",
    "    y_2=svm.predict(X_test_std)\n",
    "\n",
    "\n",
    "    print(y_2)\n",
    "    return y_1,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = '3german.txt'\n",
    "d2 = pd.read_csv(filename,delim_whitespace=True)\n",
    "\n",
    "n = d2.shape[0]\n",
    "m= d2.shape[1]\n",
    "x1 = d2.iloc[0:699,8]\n",
    "x2 = d2.iloc[0:699,12]\n",
    "n = x2.shape[0]\n",
    "y=d2.iloc[0:699,21]\n",
    "\n",
    "list2= []  \n",
    "R = np.zeros((8, n), dtype = int)\n",
    "for i in range(n):\n",
    "    if x1[i] == 'A91':\n",
    "        R[0][i]= 1\n",
    "    elif x1[i] == 'A92':\n",
    "        R[1][i]= 1\n",
    "    elif x1[i] == 'A93':\n",
    "        R[2][i]= 1\n",
    "    elif x1[i] == 'A94':\n",
    "        R[3][i]= 1\n",
    "    else:\n",
    "        R[4][i]= 1\n",
    "\n",
    "for i in range(len(x2)):\n",
    "    t = int(x2[i])\n",
    "    list2.append(t)\n",
    "\n",
    "x2=list2    \n",
    "\n",
    "for i in range(n):\n",
    "    if x2[i] <= 35 :\n",
    "        R[5][i]= 1\n",
    "    elif x2[i] >= 55:\n",
    "        R[6][i]= 1\n",
    "    else :\n",
    "        R[7][i]= 1\n",
    "ytrain,ytest = german_svm()        \n",
    "\n",
    "gamma=0.3\n",
    "epsilon=0.05\n",
    "\n",
    "u1,u2=min_max_lp_all(data1,gamma,eps,R):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1     4   7   10  12  15  17  20\n",
      "0     6  1169   4   4  67   2   1   1\n",
      "1    48  5951   2   2  22   1   1   2\n",
      "2    12  2096   2   3  49   1   2   1\n",
      "3    42  7882   2   4  45   1   2   1\n",
      "4    24  4870   3   4  53   2   2   2\n",
      "..   ..   ...  ..  ..  ..  ..  ..  ..\n",
      "995  12  1736   3   4  31   1   1   1\n",
      "996  30  3857   4   4  40   1   1   1\n",
      "997  12   804   4   4  38   1   1   1\n",
      "998  45  1845   4   4  23   1   1   2\n",
      "999  45  4576   3   4  27   1   1   1\n",
      "\n",
      "[1000 rows x 8 columns]\n",
      "      0    2    3    5    6    8     9     11    13    14    16    18    19\n",
      "0    a11  a34  a43  a65  a75  a93  a101  a121  a143  a152  a173  a192  a201\n",
      "1    a12  a32  a43  a61  a73  a92  a101  a121  a143  a152  a173  a191  a201\n",
      "2    a14  a34  a46  a61  a74  a93  a101  a121  a143  a152  a172  a191  a201\n",
      "3    a11  a32  a42  a61  a74  a93  a103  a122  a143  a153  a173  a191  a201\n",
      "4    a11  a33  a40  a61  a73  a93  a101  a124  a143  a153  a173  a191  a201\n",
      "..   ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...   ...   ...\n",
      "995  a14  a32  a42  a61  a74  a92  a101  a121  a143  a152  a172  a191  a201\n",
      "996  a11  a32  a41  a61  a73  a91  a101  a122  a143  a152  a174  a192  a201\n",
      "997  a14  a32  a43  a61  a75  a93  a101  a123  a143  a152  a173  a191  a201\n",
      "998  a11  a32  a43  a61  a73  a93  a101  a124  a143  a153  a173  a192  a201\n",
      "999  a12  a34  a41  a62  a71  a93  a101  a123  a143  a152  a173  a191  a201\n",
      "\n",
      "[1000 rows x 13 columns]\n",
      "     0_a11  0_a12  0_a13  0_a14  2_a30  2_a31  2_a32  2_a33  2_a34  3_a40  \\\n",
      "0        1      0      0      0      0      0      0      0      1      0   \n",
      "1        0      1      0      0      0      0      1      0      0      0   \n",
      "2        0      0      0      1      0      0      0      0      1      0   \n",
      "3        1      0      0      0      0      0      1      0      0      0   \n",
      "4        1      0      0      0      0      0      0      1      0      1   \n",
      "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "995      0      0      0      1      0      0      1      0      0      0   \n",
      "996      1      0      0      0      0      0      1      0      0      0   \n",
      "997      0      0      0      1      0      0      1      0      0      0   \n",
      "998      1      0      0      0      0      0      1      0      0      0   \n",
      "999      0      1      0      0      0      0      0      0      1      0   \n",
      "\n",
      "     ...  14_a152  14_a153  16_a171  16_a172  16_a173  16_a174  18_a191  \\\n",
      "0    ...        1        0        0        0        1        0        0   \n",
      "1    ...        1        0        0        0        1        0        1   \n",
      "2    ...        1        0        0        1        0        0        1   \n",
      "3    ...        0        1        0        0        1        0        1   \n",
      "4    ...        0        1        0        0        1        0        1   \n",
      "..   ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "995  ...        1        0        0        1        0        0        1   \n",
      "996  ...        1        0        0        0        0        1        0   \n",
      "997  ...        1        0        0        0        1        0        1   \n",
      "998  ...        0        1        0        0        1        0        0   \n",
      "999  ...        1        0        0        0        1        0        1   \n",
      "\n",
      "     18_a192  19_a201  19_a202  \n",
      "0          1        1        0  \n",
      "1          0        1        0  \n",
      "2          0        1        0  \n",
      "3          0        1        0  \n",
      "4          0        1        0  \n",
      "..       ...      ...      ...  \n",
      "995        0        1        0  \n",
      "996        1        1        0  \n",
      "997        0        1        0  \n",
      "998        1        1        0  \n",
      "999        0        1        0  \n",
      "\n",
      "[1000 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# define the location of the dataset\n",
    "url = \"3german.txt\"\n",
    "# load the dataset\n",
    "df = read_csv(url, header=None,delim_whitespace=True)\n",
    "# retrieve the array of data\n",
    "df_numeric=df.drop(columns=[0,2,3,5,6,8,9,11,13,14,16,18,19])\n",
    "print(df_numeric)\n",
    "df_string=df.drop(columns=[1,4,7,10,12,15,17,20])\n",
    "print(df_string)\n",
    "df1 = pd.get_dummies(df_string.astype(str))\n",
    "print(df1)\n",
    "# dataset[]\n",
    "# data = dataset.values\n",
    "# # separate into input and output columns\n",
    "# X = data[:, :-1].astype(str)\n",
    "# y = data[:, -1].astype(str)\n",
    "# print(X.shape[0])\n",
    "# print(X.shape[1])\n",
    "# # one hot encode input variables\n",
    "# onehot_encoder = OneHotEncoder(sparse=False)\n",
    "# X = onehot_encoder.fit_transform(X)\n",
    "# # ordinal encode target variable\n",
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(y)\n",
    "# # summarize the transformed data\n",
    "# print('Input', X.shape)\n",
    "# print(X[:5, :])\n",
    "# print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pulp as p \n",
    "def min_max_lp_all(data1,gamma,eps,r):\n",
    "#     x1=data1\n",
    "#     x2=np.logical_not(x1).astype(int)\n",
    "#     data1=np.append(x1,x2,axis=0)\n",
    "#   R = np.zeros((2, n), dtype = int)\n",
    "#     for i in range(n):\n",
    "#         if x1[i]== 1:\n",
    "#             R[0][i]= 1\n",
    "#         else:\n",
    "    \n",
    "    \n",
    "    m=data1.shape[0]\n",
    "    n=data1.shape[1]\n",
    "    print('dimension of data')\n",
    "    print(m,n)\n",
    "    Lp_prob = p.LpProblem('Problem', p.LpMinimize)  \n",
    "   \n",
    "    #X[n]=z() n last value of X\n",
    "    #X=np.zeros(n+2,dtype=p.LpVariable)\n",
    "    X=np.zeros(n+1,dtype=p.LpVariable)\n",
    "    sizes=np.zeros(m,dtype=int)\n",
    "    for i in range(m):\n",
    "        count=0\n",
    "        for j in range(n):\n",
    "            if data1[i][j]==1:\n",
    "                count=count+1\n",
    "                \n",
    "        sizes[i]=count\n",
    "    #X[]=0 to n-1\n",
    "\n",
    "    for i in range(n):\n",
    "        var1=str(i)\n",
    "        \n",
    "        X[i]=p.LpVariable(var1,lowBound=0,upBound=1,cat='Integer')\n",
    "       \n",
    "        \n",
    "    X[n] =  p.LpVariable(\"z1\",lowBound=0)\n",
    "    #X[n+1] =  p.LpVariable(\"z2\",lowBound=0)\n",
    "\n",
    "    #########objective function#####################\n",
    "    Lp_prob += X[n]\n",
    "#     Lp_prob += X[n] +X[n+1]\n",
    "\n",
    "    ##############constraint#################\n",
    "    for i in range(2*m):\n",
    "        if i<m:\n",
    "            Lp_prob += X[n] >= p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)])\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) >= (2*gamma-1)*sizes[i]\n",
    "            Lp_prob += p.lpSum([2*(X[j]-0.5)*data1[i][j] for j in range(n)]) <= ((2*gamma-1)+eps)*sizes[i]\n",
    "            \n",
    "        else:        \n",
    "            Lp_prob += X[n] >= p.lpSum([-1*2*(X[j]-0.5)*data1[i-m][j] for j in range(n)])          \n",
    "       \n",
    "    Lp_prob += X[n] <= 42000\n",
    "    \n",
    "    #####################################\n",
    "    status = Lp_prob.solve()   # Solver \n",
    "    print(p.LpStatus[status]) \n",
    "    print(\"discripency is:\")        \n",
    "    print(p.value(Lp_prob.objective))\n",
    "    x=np.zeros(n,dtype=float)\n",
    "\n",
    "    Synth1={}\n",
    "    Synth2={}\n",
    "   \n",
    "    for i in range(n):\n",
    "        if(p.value(X[i])==1):\n",
    "            Synth1[i]=1 \n",
    "            Synth2[i]=-1\n",
    "        else:\n",
    "            Synth1[i]=-1\n",
    "            Synth2[i]=1\n",
    "    Synthu1=Synth1  \n",
    "    Synthu2=Synth2  \n",
    "    \n",
    "              \n",
    "    return Synthu1,Synthu2   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
